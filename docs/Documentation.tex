%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=2,mathnumfig,mathnumsep={.}]{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}


\title{GloMarGridding}
\date{Jul 03, 2025}
\release{1.0.0\sphinxhyphen{}rc.3}
\author{NOC Surface Processes}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxstepscope


\chapter{Introduction}
\label{\detokenize{introduction:introduction}}\label{\detokenize{introduction::doc}}
\sphinxAtStartPar
Global surface temperature datasets \sphinxhyphen{} such as those used in the Intergovernmental Panel on Climate
Change (IPCC) Assessment Report \sphinxcite{index:ipcc} rely on a range of techniques to generate smoothed, infilled
gridded fields from available observations \sphinxcite{index:lenssen}, \sphinxcite{index:kadow}, \sphinxcite{index:rohdeberkeley}, \sphinxcite{index:morice-2021},
\sphinxcite{index:huang} . The construction of these datasets involves numerous processing decisions, and variations
in how each dataset represents the temperature field contribute to what is known as structural
uncertainty \sphinxcite{index:thorne}. This structural uncertainty has two primary sources: (1) differences in the
processing of the input temperature measurements, and (2) differences in the spatial interpolation
methods applied. Because these steps are often tightly integrated, it is difficult to determine
their individual contributions.

\sphinxAtStartPar
\sphinxtitleref{glomar\_gridding} is a software package developed to support the evaluation of structural
uncertainty by offering flexible tools for spatial interpolation. The package enables users to
spatially interpolate grid\sphinxhyphen{}box average observations and their associated uncertainty estimates using
Gaussian Process Regression Modelling (GPRM, often called \sphinxtitleref{Kriging}) \sphinxcite{index:rasmussen}, \sphinxcite{index:cressie} . This
technique builds on established methods for generating surface temperature fields \sphinxcite{index:karspeck},
\sphinxcite{index:morice-2012}. By decoupling interpolation from earlier processing stages \sphinxhyphen{} such as homogenization,
quality control, and aggregation to grid\sphinxhyphen{}cell averages \sphinxhyphen{} \sphinxtitleref{glomar\_gridding} allows users to create
spatially complete fields while independently assessing the effects of upstream data processing
choices.

\sphinxstepscope


\chapter{Getting Started}
\label{\detokenize{getting_started:getting-started}}\label{\detokenize{getting_started::doc}}

\section{Installation}
\label{\detokenize{getting_started:installation}}

\subsection{Via Pip}
\label{\detokenize{getting_started:via-pip}}
\sphinxAtStartPar
GloMarGridding is not available on PyPI, however it can be installed via pip with the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{pip install GloMarGridding@git+ssh://git@git.noc.ac.uk/nocsurfaceprocesses/glomar\PYGZus{}gridding.git}
\end{sphinxVerbatim}


\subsection{From Source}
\label{\detokenize{getting_started:from-source}}
\sphinxAtStartPar
Alternatively, you can clone the repository and install using pip (or conda if preferred).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+go}{git clone git@git.noc.ac.uk/nocsurfaceprocesses/glomar\PYGZus{}gridding.git}
\PYG{g+go}{cd glomar\PYGZus{}gridding}
\PYG{g+go}{python \PYGZhy{}m venv venv}
\PYG{g+go}{source venv/bin/activate}
\PYG{g+go}{pip install \PYGZhy{}e .}
\end{sphinxVerbatim}

\sphinxstepscope


\chapter{Credits}
\label{\detokenize{authors:credits}}\label{\detokenize{authors::doc}}

\section{Development Lead}
\label{\detokenize{authors:development-lead}}\begin{itemize}
\item {}
\sphinxAtStartPar
Agnieszka Faulkner \textless{}\sphinxhref{mailto:agfaul@noc.ac.uk}{agfaul@noc.ac.uk}\textgreater{} \sphinxhref{git.noc.ac.uk/agfaul}{@agfaul}

\item {}
\sphinxAtStartPar
Joseph T. Siddons \textless{}\sphinxhref{mailto:josidd@noc.ac.uk}{josidd@noc.ac.uk}\textgreater{} \sphinxhref{git.noc.ac.uk/josidd}{@josidd}

\end{itemize}


\section{Contributoring Developers}
\label{\detokenize{authors:contributoring-developers}}\begin{itemize}
\item {}
\sphinxAtStartPar
Archie Cable \textless{}\sphinxhref{mailto:acable@noc.ac.uk}{acable@noc.ac.uk}\textgreater{} \sphinxhref{git.noc.ac.uk/acable}{@acable}

\item {}
\sphinxAtStartPar
Steven Chan \textless{}\sphinxhref{mailto:stchan@noc.ac.uk}{stchan@noc.ac.uk}\textgreater{} \sphinxhref{git.noc.ac.uk/stchan}{@stchan}

\item {}
\sphinxAtStartPar
Richard C. Cornes \textless{}\sphinxhref{mailto:rcornes@noc.ac.uk}{rcornes@noc.ac.uk}\textgreater{} \sphinxhref{git.noc.ac.uk/ricorne}{@ricorne}

\item {}
\sphinxAtStartPar
Elizabeth C. Kent \textless{}\sphinxhref{mailto:eck@noc.ac.uk}{eck@noc.ac.uk}\textgreater{} \sphinxhref{git.noc.ac.uk/eck}{@eck}

\item {}
\sphinxAtStartPar
Duo Chan \textless{}\sphinxhref{mailto:Duo.Chan@soton.ac.uk}{Duo.Chan@soton.ac.uk}\textgreater{}

\end{itemize}


\section{Acknowledgements}
\label{\detokenize{authors:acknowledgements}}\begin{itemize}
\item {}
\sphinxAtStartPar
Thanks to Simon Williams for providing the original Matlab code that GloMarGridding is based upon.

\item {}
\sphinxAtStartPar
Supported by the Natural Environmental Research Council through National Capability funding
(AtlantiS: NE/Y005589/1)

\end{itemize}


\section{License}
\label{\detokenize{authors:license}}
\sphinxAtStartPar
Copyright 2025 National Oceanography Centre

\sphinxAtStartPar
Licensed under the Apache License, Version 2.0 (the “License”);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
\begin{quote}

\sphinxAtStartPar
\sphinxurl{http://www.apache.org/licenses/LICENSE-2.0}
\end{quote}

\sphinxAtStartPar
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an “AS IS” BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

\sphinxstepscope


\chapter{Example Workflow}
\label{\detokenize{workflow:example-workflow}}\label{\detokenize{workflow::doc}}
\sphinxAtStartPar
Here we present a simple example, where we use Ordinary Kriging to interpolate observational data.

\sphinxAtStartPar
A full example can be found in the notebooks directory of the repository.


\section{Load Observations}
\label{\detokenize{workflow:load-observations}}
\sphinxAtStartPar
In this hypothetical example, we are working with data from a \sphinxtitleref{csv} file. This is assumed to be
point\sphinxhyphen{}observation data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{obs} \PYG{o}{=} \PYG{n}{pl}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/obs.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Output Grid}
\label{\detokenize{workflow:output-grid}}
\sphinxAtStartPar
The first step is to create the output grid, using
{\hyperref[\detokenize{covariance:glomar_gridding.grid.grid_from_resolution}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.grid.grid\_from\_resolution()}}}}} to specify a global grid with a fixed
resolution. Here, the grid has a 5\sphinxhyphen{}degree resolution.

\sphinxAtStartPar
The grid is essentially an empty \sphinxtitleref{xarray.DataArray} with a coordinate system defined by the input
parameters. This can be used to map to the observations, and to create a covariance matrix with
consistent coordinates.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{grid} \PYG{o}{=} \PYG{n}{grid\PYGZus{}from\PYGZus{}resolution}\PYG{p}{(}
    \PYG{n}{resolution}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,}
    \PYG{n}{bounds}\PYG{o}{=}\PYG{p}{[}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{87.5}\PYG{p}{,} \PYG{l+m+mi}{90}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{177.5}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{coord\PYGZus{}names}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{latitude}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{longitude}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}
\end{sphinxVerbatim}


\section{Align Observations}
\label{\detokenize{workflow:align-observations}}
\sphinxAtStartPar
The input observations may not be located at grid\sphinxhyphen{}box locations, i.e. they may be located somewhere
between grid\sphinxhyphen{}box centres. {\hyperref[\detokenize{kriging:glomar_gridding.grid.map_to_grid}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.grid.map\_to\_grid()}}}}} can be used to map each point
observation to a grid\sphinxhyphen{}box by identifying the nearest grid\sphinxhyphen{}box position from an input grid.

\sphinxAtStartPar
This adds an index column to the observational data\sphinxhyphen{}frame, which is the 1\sphinxhyphen{}dimensional index value of
the coordinate. This allows for easy mapping to the indices of covariance matrices, etc.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{obs} \PYG{o}{=} \PYG{n}{map\PYGZus{}to\PYGZus{}grid}\PYG{p}{(}
    \PYG{n}{obs}\PYG{o}{=}\PYG{n}{obs}\PYG{p}{,}
    \PYG{n}{grid}\PYG{o}{=}\PYG{n}{grid}\PYG{p}{,}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
In this example, it is assumed that the observations are such that at most one observation is
associated with a grid\sphinxhyphen{}box. If this is not the case, the observations can be combined into a
grid\sphinxhyphen{}box \sphinxstyleemphasis{super}\sphinxhyphen{}observation with a weighting using
{\hyperref[\detokenize{kriging:glomar_gridding.kriging.prep_obs_for_kriging}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.kriging.prep\_obs\_for\_kriging()}}}}}.

\sphinxAtStartPar
Extract the observation values, and the grid\sphinxhyphen{}box index for each observation. In this example, the
observation value is stored in the \sphinxtitleref{“val”} column.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{grid\PYGZus{}obs} \PYG{o}{=} \PYG{n}{obs}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{val}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{n}{grid\PYGZus{}idx} \PYG{o}{=} \PYG{n}{obs}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grid\PYGZus{}idx}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\end{sphinxVerbatim}


\section{Create or Load Spatial Covariance}
\label{\detokenize{workflow:create-or-load-spatial-covariance}}
\sphinxAtStartPar
The grid can be converted in to a distance matrix, and finally to a covariance matrix using a
\sphinxcode{\sphinxupquote{glomar\_gridding.variogram.Variogram}} object, for example
{\hyperref[\detokenize{covariance:glomar_gridding.variogram.GaussianVariogram}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.variogram.GaussianVariogram}}}}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dist} \PYG{o}{=} \PYG{n}{grid\PYGZus{}to\PYGZus{}distance\PYGZus{}matrix}\PYG{p}{(}
    \PYG{n}{grid}\PYG{o}{=}\PYG{n}{grid}\PYG{p}{,}
    \PYG{n}{lat\PYGZus{}coord}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{latitude}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{lon\PYGZus{}coord}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{longitude}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{variogram} \PYG{o}{=} \PYG{n}{GaussianVariogram}\PYG{p}{(}
    \PYG{n+nb}{range}\PYG{o}{=}\PYG{l+m+mi}{1200}\PYG{p}{,}
    \PYG{n}{psill}\PYG{o}{=}\PYG{l+m+mf}{1.2}\PYG{p}{,}
    \PYG{n}{nugget}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,}
\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{dist}\PYG{p}{)}

\PYG{n}{covariance} \PYG{o}{=} \PYG{n}{variogram\PYGZus{}to\PYGZus{}covariance}\PYG{p}{(}\PYG{n}{variogram}\PYG{p}{,} \PYG{n}{sill}\PYG{o}{=}\PYG{l+m+mf}{1.2}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Alternatively, the covariance matrix can be loaded from disk. A non\sphinxhyphen{}stationary (varying parameter)
covariance matrix can be estimated using ellipse\sphinxhyphen{}based models. See
{\hyperref[\detokenize{ellipse:glomar_gridding.ellipse.EllipseModel}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.ellipse.EllipseModel}}}}}.


\section{Optionally Load Error Covariance}
\label{\detokenize{workflow:optionally-load-error-covariance}}
\sphinxAtStartPar
In this example an error covariance matrix is loaded from a netCDF file on disk, using
{\hyperref[\detokenize{misc:glomar_gridding.io.load_array}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.io.load\_array()}}}}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{error\PYGZus{}cov} \PYG{o}{=} \PYG{n}{load\PYGZus{}array}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/error\PYGZus{}cov.nc}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{var}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{error\PYGZus{}covariance}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Alternatively, an error covariance matrix can be computed component wise.


\section{Ordinary Kriging}
\label{\detokenize{workflow:ordinary-kriging}}
\sphinxAtStartPar
In this example, we will infill the observations using Ordinary Kriging. For this, we use
{\hyperref[\detokenize{kriging:glomar_gridding.kriging.OrdinaryKriging}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.kriging.OrdinaryKriging}}}}}, which requires a spatial covariance matrix,
observation grid indices, observation values, and (optionally) error covariance as inputs.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ok} \PYG{o}{=} \PYG{n}{OrdinaryKriging}\PYG{p}{(}
    \PYG{n}{covariance}\PYG{o}{.}\PYG{n}{values}\PYG{p}{,}
    \PYG{n}{idx}\PYG{o}{=}\PYG{n}{grid\PYGZus{}idx}\PYG{p}{,}
    \PYG{n}{obs}\PYG{o}{=}\PYG{n}{grid\PYGZus{}obs}\PYG{p}{,}
    \PYG{n}{error\PYGZus{}cov}\PYG{o}{=}\PYG{n}{error\PYGZus{}cov}\PYG{p}{,}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can now use this class\sphinxhyphen{}instance to solve the system, using the \sphinxtitleref{solve} method.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{result} \PYG{o}{=} \PYG{n}{ok}\PYG{o}{.}\PYG{n}{solve}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Finally, the output can be mapped back on to the grid using
{\hyperref[\detokenize{kriging:glomar_gridding.grid.assign_to_grid}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.grid.assign\_to\_grid()}}}}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{gridded\PYGZus{}result} \PYG{o}{=} \PYG{n}{assign\PYGZus{}to\PYGZus{}grid}\PYG{p}{(}
     \PYG{n}{values}\PYG{o}{=}\PYG{n}{result}\PYG{p}{,}
     \PYG{n}{grid\PYGZus{}idx}\PYG{o}{=}\PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{n}{grid}\PYG{o}{.}\PYG{n}{size}\PYG{p}{)}\PYG{p}{,}
     \PYG{n}{grid}\PYG{o}{=}\PYG{n}{grid}\PYG{p}{,}
\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstepscope


\chapter{Stationary Interpolation Covariance}
\label{\detokenize{covariance:stationary-interpolation-covariance}}\label{\detokenize{covariance::doc}}
\sphinxAtStartPar
Outside of the observation values and positions, the spatial covariance structure is the most
important component for Kriging. The Kriging classes in this library all require this matrix as the
input to the class. This covariance matrix can be provided as a pre\sphinxhyphen{}computed matrix, loaded into the
environment with {\hyperref[\detokenize{covariance:glomar_gridding.interpolation_covariance.load_covariance}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.interpolation\_covariance.load\_covariance()}}}}}. Alternatively
the covariance structure can be estimated using functions and classes contained within
\sphinxtitleref{glomar\_gridding}.

\sphinxAtStartPar
A commonly used approach is to compute a stationary covariance structure, using a \sphinxstyleemphasis{Variogram} with
fixed scales. The use of \sphinxstyleemphasis{stationary} here suggests that the range of covariance is constant across
all positions \sphinxhyphen{} each position has the same influence over a fixed distance.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{glomar\PYGZus{}gridding}\PYG{n+nn}{.}\PYG{n+nn}{grid}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{n}{grid\PYGZus{}from\PYGZus{}resolution}\PYG{p}{,} \PYG{n}{grid\PYGZus{}to\PYGZus{}distance\PYGZus{}matrix}
\PYG{k+kn}{from}\PYG{+w}{ }\PYG{n+nn}{glomar\PYGZus{}gridding}\PYG{n+nn}{.}\PYG{n+nn}{variogram}\PYG{+w}{ }\PYG{k+kn}{import} \PYG{n}{GaussianVariogram}\PYG{p}{,} \PYG{n}{variogram\PYGZus{}to\PYGZus{}covariance}


\PYG{c+c1}{\PYGZsh{} Initialise a grid}
\PYG{n}{grid} \PYG{o}{=} \PYG{n}{grid\PYGZus{}from\PYGZus{}resolution}\PYG{p}{(}
    \PYG{n}{resolution}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,}
    \PYG{n}{bounds}\PYG{o}{=}\PYG{p}{[}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{87.5}\PYG{p}{,} \PYG{l+m+mi}{90}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{177.5}\PYG{p}{,} \PYG{l+m+mi}{180}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{coord\PYGZus{}names}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{latitude}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{longitude}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute a distance matrix}
\PYG{n}{dist} \PYG{o}{=} \PYG{n}{grid\PYGZus{}to\PYGZus{}distance\PYGZus{}matrix}\PYG{p}{(}
    \PYG{n}{grid}\PYG{o}{=}\PYG{n}{grid}\PYG{p}{,}
    \PYG{n}{lat\PYGZus{}coord}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{latitude}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{lon\PYGZus{}coord}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{longitude}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Define and compute a Variogram}
\PYG{n}{variogram} \PYG{o}{=} \PYG{n}{GaussianVariogram}\PYG{p}{(}
    \PYG{n}{nugget}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,}
    \PYG{n}{psill}\PYG{o}{=}\PYG{l+m+mf}{1.2}\PYG{p}{,}
    \PYG{n+nb}{range}\PYG{o}{=}\PYG{l+m+mi}{1300}\PYG{p}{,}
\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{dist}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Convert to covariance}
\PYG{n}{covariance} \PYG{o}{=} \PYG{n}{variogram\PYGZus{}to\PYGZus{}covariance}\PYG{p}{(}\PYG{n}{variogram}\PYG{p}{,} \PYG{n}{sill}\PYG{o}{=}\PYG{l+m+mf}{1.2}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Grid}
\label{\detokenize{covariance:grid}}\index{grid\_from\_resolution() (in module glomar\_gridding.grid)@\spxentry{grid\_from\_resolution()}\spxextra{in module glomar\_gridding.grid}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.grid.grid_from_resolution}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.grid.}}\sphinxbfcode{\sphinxupquote{grid\_from\_resolution}}}
{\sphinxparam{\DUrole{n}{resolution}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bounds}}\sphinxparamcomma \sphinxparam{\DUrole{n}{coord\_names}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Generate a grid from a resolution value, or a list of resolutions for
given boundaries and coordinate names.

\sphinxAtStartPar
Note that all list inputs must have the same length, the ordering of values
in the lists is assumed align.

\sphinxAtStartPar
The constructed grid will be regular, in the sense that the grid spacing is
constant. However, the resolution in each direction can be different,
allowing for finer resolution in some direction.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{resolution}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Resolution of the grid. Can be a single resolution value that will be
applied to all coordinates, or a list of values mapping a resolution
value to each of the coordinates.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bounds}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A list of bounds of the form \sphinxtitleref{(lower\_bound, upper\_bound)} indicating
the bounding box of the returned grid. Typically, one would set the
lower bound to be the centre of the first grid box. The upper bound is
an open bound (similar to usage in \sphinxtitleref{range}). For example a 5 degree
resolution longitude range between \sphinxhyphen{}180, 180 could be defined with
bounds \sphinxtitleref{(\sphinxhyphen{}177.5, 180)}.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{coord\_names}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of coordinate names in the same order as the bounds and
resolution(s).

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{grid} \textendash{} The grid defined by the resolution and bounding box.

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.DataArray:

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{grid\PYGZus{}from\PYGZus{}resolution}\PYG{p}{(}
\PYG{g+go}{        resolution=5,}
\PYG{g+go}{        bounds=[(\PYGZhy{}87.5, 90), (\PYGZhy{}177.5, 180)],  \PYGZsh{} Lower bound is centre}
\PYG{g+go}{        coord\PYGZus{}names=[\PYGZdq{}lat\PYGZdq{}, \PYGZdq{}lon\PYGZdq{}]}
\PYG{g+go}{    )}
\PYG{g+go}{\PYGZlt{}xarray.DataArray (lat: 36, lon: 72)\PYGZgt{} Size: 21kB}
\PYG{g+go}{array([[nan, nan, nan, ..., nan, nan, nan],}
\PYG{g+go}{       [nan, nan, nan, ..., nan, nan, nan],}
\PYG{g+go}{       [nan, nan, nan, ..., nan, nan, nan],}
\PYG{g+go}{       ...,}
\PYG{g+go}{       [nan, nan, nan, ..., nan, nan, nan],}
\PYG{g+go}{       [nan, nan, nan, ..., nan, nan, nan],}
\PYG{g+go}{       [nan, nan, nan, ..., nan, nan, nan]], shape=(36, 72))}
\PYG{g+go}{Coordinates:}
\PYG{g+go}{  * lat      (lat) float64 288B \PYGZhy{}87.5 \PYGZhy{}82.5 \PYGZhy{}77.5 ... 77.5 82.5 87.5}
\PYG{g+go}{  * lon      (lon) float64 576B \PYGZhy{}177.5 \PYGZhy{}172.5 ... 172.5 177.5}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{grid\_to\_distance\_matrix() (in module glomar\_gridding.grid)@\spxentry{grid\_to\_distance\_matrix()}\spxextra{in module glomar\_gridding.grid}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.grid.grid_to_distance_matrix}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.grid.}}\sphinxbfcode{\sphinxupquote{grid\_to\_distance\_matrix}}}
{\sphinxparam{\DUrole{n}{grid}}\sphinxparamcomma \sphinxparam{\DUrole{n}{dist\_func=\textless{}function haversine\_distance\_from\_frame\textgreater{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lat\_coord=\textquotesingle{}lat\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lon\_coord=\textquotesingle{}lon\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{**dist\_kwargs}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate a distance matrix between all positions in a grid. Orientation of
latitude and longitude will be maintained in the returned distance matrix.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} A 2\sphinxhyphen{}d grid containing latitude and longitude indexes specified in
decimal degrees.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dist\_func}} (\sphinxstyleliteralemphasis{\sphinxupquote{Callable}}) \textendash{} Distance function to use to compute pairwise distances. See
glomar\_gridding.distances.calculate\_distance\_matrix for more
information.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lat\_coord}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the latitude coordinate in the input grid.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lon\_coord}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the longitude coordinate in the input grid.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**dist\_kwargs}} \textendash{} Keyword arguments to pass to the distance function.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{dist} \textendash{} A DataArray containing the distance matrix with coordinate system
defined with grid cell index (“index\_1” and “index\_2”). The coordinates
of the original grid are also kept as coordinates related to each
index (the coordinate names are suffixed with “\_1” or “\_2”
respectively).

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.DataArray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{grid} \PYG{o}{=} \PYG{n}{grid\PYGZus{}from\PYGZus{}resolution}\PYG{p}{(}
\PYG{g+go}{        resolution=5,}
\PYG{g+go}{        bounds=[(\PYGZhy{}87.5, 90), (\PYGZhy{}177.5, 180)],  \PYGZsh{} Lower bound is centre}
\PYG{g+go}{        coord\PYGZus{}names=[\PYGZdq{}lat\PYGZdq{}, \PYGZdq{}lon\PYGZdq{}]}
\PYG{g+go}{    )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{grid\PYGZus{}to\PYGZus{}distance\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{grid}\PYG{p}{,} \PYG{n}{lat\PYGZus{}coord}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lat}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{lon\PYGZus{}coord}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lon}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{\PYGZlt{}xarray.DataArray \PYGZsq{}dist\PYGZsq{} (index\PYGZus{}1: 2592, index\PYGZus{}2: 2592)\PYGZgt{} Size: 54MB}
\PYG{g+go}{array([[    0.        ,    24.24359308,    48.44112457, ...,}
\PYG{g+go}{        19463.87158499, 19461.22915012, 19459.64166305],}
\PYG{g+go}{       [   24.24359308,     0.        ,    24.24359308, ...,}
\PYG{g+go}{        19467.56390938, 19463.87158499, 19461.22915012],}
\PYG{g+go}{       [   48.44112457,    24.24359308,     0.        , ...,}
\PYG{g+go}{        19472.29905588, 19467.56390938, 19463.87158499],}
\PYG{g+go}{       ...,}
\PYG{g+go}{       [19463.87158499, 19467.56390938, 19472.29905588, ...,}
\PYG{g+go}{            0.        ,    24.24359308,    48.44112457],}
\PYG{g+go}{       [19461.22915012, 19463.87158499, 19467.56390938, ...,}
\PYG{g+go}{           24.24359308,     0.        ,    24.24359308],}
\PYG{g+go}{       [19459.64166305, 19461.22915012, 19463.87158499, ...,}
\PYG{g+go}{           48.44112457,    24.24359308,     0.        ]],}
\PYG{g+go}{      shape=(2592, 2592))}
\PYG{g+go}{Coordinates:}
\PYG{g+go}{  * index\PYGZus{}1  (index\PYGZus{}1) int64 21kB 0 1 2 3 4 ... 2587 2588 2589 2590 2591}
\PYG{g+go}{  * index\PYGZus{}2  (index\PYGZus{}2) int64 21kB 0 1 2 3 4 ... 2587 2588 2589 2590 2591}
\PYG{g+go}{    lat\PYGZus{}1    (index\PYGZus{}1) float64 21kB \PYGZhy{}87.5 \PYGZhy{}87.5 \PYGZhy{}87.5 ... 87.5 87.5}
\PYG{g+go}{    lon\PYGZus{}1    (index\PYGZus{}1) float64 21kB \PYGZhy{}177.5 \PYGZhy{}172.5 ... 172.5 177.5}
\PYG{g+go}{    lat\PYGZus{}2    (index\PYGZus{}2) float64 21kB \PYGZhy{}87.5 \PYGZhy{}87.5 \PYGZhy{}87.5 ... 87.5 87.5 87.5}
\PYG{g+go}{    lon\PYGZus{}2    (index\PYGZus{}2) float64 21kB \PYGZhy{}177.5 \PYGZhy{}172.5 ... 172.5 177.5}
\end{sphinxVerbatim}

\end{fulllineitems}



\section{Variograms}
\label{\detokenize{covariance:variograms}}\index{ExponentialVariogram (class in glomar\_gridding.variogram)@\spxentry{ExponentialVariogram}\spxextra{class in glomar\_gridding.variogram}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.ExponentialVariogram}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.variogram.}}\sphinxbfcode{\sphinxupquote{ExponentialVariogram}}}
{\sphinxparam{\DUrole{n}{psill}}\sphinxparamcomma \sphinxparam{\DUrole{n}{nugget}}\sphinxparamcomma \sphinxparam{\DUrole{n}{range}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{effective\_range}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Exponential Model
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{psill}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Sill of the variogram where it will flatten out. Values in the variogram
will not exceed psill + nugget. This value is the variance.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nugget}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} The value of the independent variable at distance 0

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{effective\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Effective Range, this is the distance where 95\% of the sill are
exceeded. This is not the range parameter, which is defined as r/3.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{range}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} The range parameter. One of range and effective\_range must be set. If
range is not set, it will be computed from effective\_range.

\end{itemize}

\end{description}\end{quote}
\index{fit() (glomar\_gridding.variogram.ExponentialVariogram method)@\spxentry{fit()}\spxextra{glomar\_gridding.variogram.ExponentialVariogram method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.ExponentialVariogram.fit}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{fit}}}
{\sphinxparam{\DUrole{n}{distance\_matrix}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Fit the ExponentialVariogram model to a distance matrix
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{distance\_matrix}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} The distance matrix indicating the distance between each pair of
points in the grid.

\sphinxlineitem{Returns}
\sphinxAtStartPar
A matrix containing the variogram values at each distance.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray | xarray.DataArray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ExponentialVariogram}\PYG{p}{(}\PYG{n+nb}{range}\PYG{o}{=}\PYG{l+m+mi}{1200}\PYG{p}{,} \PYG{n}{psill}\PYG{o}{=}\PYG{l+m+mf}{1.2}\PYG{p}{,} \PYG{n}{nugget}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{dist}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}

\index{SphericalVariogram (class in glomar\_gridding.variogram)@\spxentry{SphericalVariogram}\spxextra{class in glomar\_gridding.variogram}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.SphericalVariogram}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.variogram.}}\sphinxbfcode{\sphinxupquote{SphericalVariogram}}}
{\sphinxparam{\DUrole{n}{psill}}\sphinxparamcomma \sphinxparam{\DUrole{n}{nugget}}\sphinxparamcomma \sphinxparam{\DUrole{n}{effective\_range}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{range}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Spherical Model
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{psill}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Sill of the variogram where it will flatten out. Values in the variogram
will not exceed psill + nugget. This value is the variance.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nugget}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} The value of the independent variable at distance 0

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{effective\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Effective Range, this is the distance where 95\% of the sill are
exceeded. This is not the range parameter, which is equal to the
effective range in the SphericalVariogram case.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{range}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} The range parameter. One of range and effective\_range must be set. If
range is not set, it will be computed from effective\_range.

\end{itemize}

\end{description}\end{quote}
\index{fit() (glomar\_gridding.variogram.SphericalVariogram method)@\spxentry{fit()}\spxextra{glomar\_gridding.variogram.SphericalVariogram method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.SphericalVariogram.fit}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{fit}}}
{\sphinxparam{\DUrole{n}{distance\_matrix}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Fit the SphericalVariogram model to a distance matrix
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{distance\_matrix}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} The distance matrix indicating the distance between each pair of
points in the grid.

\sphinxlineitem{Returns}
\sphinxAtStartPar
A matrix containing the variogram values at each distance.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray | xarray.DataArray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{SphericalVariogram}\PYG{p}{(}\PYG{n+nb}{range}\PYG{o}{=}\PYG{l+m+mi}{1200}\PYG{p}{,} \PYG{n}{psill}\PYG{o}{=}\PYG{l+m+mf}{1.2}\PYG{p}{,} \PYG{n}{nugget}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{dist}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}

\index{GaussianVariogram (class in glomar\_gridding.variogram)@\spxentry{GaussianVariogram}\spxextra{class in glomar\_gridding.variogram}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.GaussianVariogram}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.variogram.}}\sphinxbfcode{\sphinxupquote{GaussianVariogram}}}
{\sphinxparam{\DUrole{n}{psill}}\sphinxparamcomma \sphinxparam{\DUrole{n}{nugget}}\sphinxparamcomma \sphinxparam{\DUrole{n}{effective\_range}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{range}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Gaussian Model
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{psill}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Sill of the variogram where it will flatten out. Values in the variogram
will not exceed psill + nugget. This value is the variance.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nugget}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} The value of the independent variable at distance 0

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{effective\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Effective Range, this is the distance where 95\% of the sill are
exceeded. This is not the range parameter, which is defined as r/2.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{range}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} The range parameter. One of range and effective\_range must be set. If
range is not set, it will be computed from effective\_range.

\end{itemize}

\end{description}\end{quote}
\index{fit() (glomar\_gridding.variogram.GaussianVariogram method)@\spxentry{fit()}\spxextra{glomar\_gridding.variogram.GaussianVariogram method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.GaussianVariogram.fit}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{fit}}}
{\sphinxparam{\DUrole{n}{distance\_matrix}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Fit the GaussianVariogram model to a distance matrix
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{distance\_matrix}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} The distance matrix indicating the distance between each pair of
points in the grid.

\sphinxlineitem{Returns}
\sphinxAtStartPar
A matrix containing the variogram values at each distance.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray | xarray.DataArray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{GaussianVariogram}\PYG{p}{(}\PYG{n+nb}{range}\PYG{o}{=}\PYG{l+m+mi}{1200}\PYG{p}{,} \PYG{n}{psill}\PYG{o}{=}\PYG{l+m+mf}{1.2}\PYG{p}{,} \PYG{n}{nugget}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{dist}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}

\index{MaternVariogram (class in glomar\_gridding.variogram)@\spxentry{MaternVariogram}\spxextra{class in glomar\_gridding.variogram}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.MaternVariogram}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.variogram.}}\sphinxbfcode{\sphinxupquote{MaternVariogram}}}
{\sphinxparam{\DUrole{n}{psill}}\sphinxparamcomma \sphinxparam{\DUrole{n}{nugget}}\sphinxparamcomma \sphinxparam{\DUrole{n}{effective\_range}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{range}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{nu}\DUrole{o}{=}\DUrole{default_value}{0.5}}\sphinxparamcomma \sphinxparam{\DUrole{n}{method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}sklearn\textquotesingle{}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Matern Models

\sphinxAtStartPar
Same args as the Variogram classes with additional nu (\(\nu\)), method
parameters.

\sphinxAtStartPar
Sklearn:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{)}%
\item {}
\sphinxAtStartPar
This is called “sklearn” because if d/range = 1.0 and \(\nu=0.5\), it
gives 1/e correlation…

\item {}
\sphinxAtStartPar
This is NOT the same formulation as in GSTAT nor in papers about
non\sphinxhyphen{}stationary anistropic covariance models (aka Karspeck paper).

\item {}
\sphinxAtStartPar
It is perhaps the most intitutive (because of (1)) and is used in sklearn
GP and HadCRUT5 and other UKMO dataset.

\item {}
\sphinxAtStartPar
nu defaults to 0.5 (exponential; used in HADSST4 and our kriging).
HadCRUT5 uses 1.5.

\item {}
\sphinxAtStartPar
The “2” is inside the square root for middle and right.

\end{enumerate}

\sphinxAtStartPar
GeoStatic:

\sphinxAtStartPar
Similar to Sklearn MaternVariogram model but uses the range scaling in
gstat.
Note: there are no square root 2 or nu in middle and right

\sphinxAtStartPar
Yields the same answer to sklearn MaternVariogram if \(\nu=0.5\)
but are otherwise different.

\sphinxAtStartPar
Karspeck:

\sphinxAtStartPar
Similar to Sklearn MaternVariogram model but uses the form in Karspeck paper
Note: Note the 2 is outside the square root for middle and right
e\sphinxhyphen{}folding distance is now at d/SQRT(2) for \(\nu=0.5\)
\subsubsection*{References}

\sphinxAtStartPar
see chapter 4.2 of Rasmussen, C. E., \& Williams, C. K. I. (2005).
Gaussian Processes for Machine Learning. The MIT Press.
\sphinxurl{https://doi.org/10.7551/mitpress/3206.001.0001}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{psill}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Sill of the variogram where it will flatten out. Values in the variogram
will not exceed psill + nugget. This value is the variance.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nugget}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} The value of the independent variable at distance 0

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{effective\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Effective Range, this is the lag where 95\% of the sill are exceeded.
This is not the range parameter, which is defined as r/3 if nu \textless{} 0.5 or
nu \textgreater{} 10, otherwise r/2 (where r is the effective range). One of
effective\_range and range must be set.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{range}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} The range parameter. One of range and effective\_range must be set. If
range is not set, it will be computed from effective\_range.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nu}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} \(\nu\), smoothing parameter, shapes to a smooth or rough variogram
function

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{method}} (\sphinxstyleliteralemphasis{\sphinxupquote{MaternModel}}) \textendash{}
\sphinxAtStartPar
One of “sklearn”, “gstat”, or “karspeck”:
\begin{itemize}
\item {}
\sphinxAtStartPar
sklearn: \sphinxurl{https://scikit-learn.org/stable/modules/generated/sklearn.gaussian\_process.kernels.Matern.html\#sklearn.gaussian\_process.kernels.Matern}

\item {}
\sphinxAtStartPar
gstat: \sphinxurl{https://scikit-gstat.readthedocs.io/en/latest/reference/models.html\#matern-model}

\item {}
\sphinxAtStartPar
karspeck: \sphinxurl{https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.900}

\end{itemize}


\end{itemize}

\end{description}\end{quote}
\index{fit() (glomar\_gridding.variogram.MaternVariogram method)@\spxentry{fit()}\spxextra{glomar\_gridding.variogram.MaternVariogram method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.MaternVariogram.fit}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{fit}}}
{\sphinxparam{\DUrole{n}{distance\_matrix}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Fit the MaternVariogram model to a distance matrix.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{distance\_matrix}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} The distance matrix indicating the distance between each pair of
points in the grid.

\sphinxlineitem{Returns}
\sphinxAtStartPar
A matrix containing the variogram values at each distance.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray | xarray.DataArray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{MaternVariogram}\PYG{p}{(}
\PYG{g+go}{        range=1200, psill=1.2, nugget=0.0, nu=1.5, method=\PYGZdq{}karspeck\PYGZdq{}}
\PYG{g+go}{    ).fit(dist)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}

\index{variogram\_to\_covariance() (in module glomar\_gridding.variogram)@\spxentry{variogram\_to\_covariance()}\spxextra{in module glomar\_gridding.variogram}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.variogram.variogram_to_covariance}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.variogram.}}\sphinxbfcode{\sphinxupquote{variogram\_to\_covariance}}}
{\sphinxparam{\DUrole{n}{variogram}}\sphinxparamcomma \sphinxparam{\DUrole{n}{variance}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Convert a variogram matrix to a covariance matrix.
\begin{description}
\sphinxlineitem{This is given by:}
\sphinxAtStartPar
covariance = variance \sphinxhyphen{} variogram

\end{description}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{variogram}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} The variogram matrix, output of Variogram.fit.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{variance}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The variance

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{cov} \textendash{} The covariance matrix

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray | xarray.DataArray

\end{description}\end{quote}

\end{fulllineitems}



\section{Covariance}
\label{\detokenize{covariance:module-glomar_gridding.interpolation_covariance}}\label{\detokenize{covariance:covariance}}\index{module@\spxentry{module}!glomar\_gridding.interpolation\_covariance@\spxentry{glomar\_gridding.interpolation\_covariance}}\index{glomar\_gridding.interpolation\_covariance@\spxentry{glomar\_gridding.interpolation\_covariance}!module@\spxentry{module}}
\sphinxAtStartPar
I/O functionality for loading a covariance matrix from disk.
\index{load\_covariance() (in module glomar\_gridding.interpolation\_covariance)@\spxentry{load\_covariance()}\spxextra{in module glomar\_gridding.interpolation\_covariance}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{covariance:glomar_gridding.interpolation_covariance.load_covariance}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.interpolation\_covariance.}}\sphinxbfcode{\sphinxupquote{load\_covariance}}}
{\sphinxparam{\DUrole{n}{path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{cov\_var\_name}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}covariance\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Load a covariance matrix from a netCDF file. Can input a filename or a
string to format with keyword arguments.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Full filename (including path), or filename with replacements using
str.format with named replacements. For example:
/path/to/global\_covariance\_\{month:02d\}.nc

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cov\_var\_name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the variable for the covariance matrix

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**kwargs}} \textendash{} Keywords arguments matching the replacements in the input path.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{covariance} \textendash{} A numpy matrix containing the covariance matrix loaded from the netCDF
file determined by the input arguments.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}


\sphinxstepscope


\chapter{Ellipses: Non\sphinxhyphen{}Stationary Interpolation Covariance}
\label{\detokenize{ellipse:ellipses-non-stationary-interpolation-covariance}}\label{\detokenize{ellipse::doc}}

\section{Ellipse Models}
\label{\detokenize{ellipse:ellipse-models}}\index{EllipseModel (class in glomar\_gridding.ellipse)@\spxentry{EllipseModel}\spxextra{class in glomar\_gridding.ellipse}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseModel}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.ellipse.}}\sphinxbfcode{\sphinxupquote{EllipseModel}}}
{\sphinxparam{\DUrole{n}{anisotropic}}\sphinxparamcomma \sphinxparam{\DUrole{n}{rotated}}\sphinxparamcomma \sphinxparam{\DUrole{n}{physical\_distance}}\sphinxparamcomma \sphinxparam{\DUrole{n}{v}}\sphinxparamcomma \sphinxparam{\DUrole{n}{unit\_sigma}\DUrole{o}{=}\DUrole{default_value}{False}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
The class that contains variogram/ellipse fitting methods and parameters

\sphinxAtStartPar
This class assumes your input to be a standardised correlation matrix
They are easier to handle because stdevs in the covariance function become 1
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{anisotropic}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Should the output be an ellipse? Set to False for circle.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{rotated}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Can the ellipse be rotated. If anisotropic is False this value cannot
be True.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{physical\_distance}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Use physical distances rather than lat/lon distance.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{v}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Matern Shape Parameter. Must be \textgreater{} 0.0.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{unit\_sigma=True}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{}
\sphinxAtStartPar
When MLE fitting the Matern parameters,
assuming the Matern parameters themselves
are normally distributed,
there is standard deviation within the log likelihood function.

\sphinxAtStartPar
See Wikipedia entry for Maximum Likelihood under:
\sphinxhyphen{} Continuous distribution, continuous parameter space

\sphinxAtStartPar
Its actual value is not important
to the best (MLE) estimate of the Matern parameters.
If one assumes the parameters are normally distributed,
the mean (best estimate) is independent of its variance.
In fact in Karspeck et al 2012 \sphinxcite{index:karspeck}, it is simply set to 1
Eq B1).
This value can however be computed. It serves a similar purpose as
the original standard deviation:
in this case, how the actual observed semivariance disperses
around the fitted variogram.

\sphinxAtStartPar
The choice to default to 1 follows Karspeck et al. 2012 \sphinxcite{index:karspeck}


\end{itemize}

\end{description}\end{quote}
\index{fit() (glomar\_gridding.ellipse.EllipseModel method)@\spxentry{fit()}\spxextra{glomar\_gridding.ellipse.EllipseModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseModel.fit}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{fit}}}
{\sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{guesses}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bounds}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{opt\_method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Nelder\sphinxhyphen{}Mead\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{tol}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{estimate\_SE}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}bootstrap\_parallel\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n\_sim}\DUrole{o}{=}\DUrole{default_value}{500}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n\_jobs}\DUrole{o}{=}\DUrole{default_value}{4}}\sphinxparamcomma \sphinxparam{\DUrole{n}{backend}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}loky\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{random\_seed}\DUrole{o}{=}\DUrole{default_value}{1234}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Default solver in Nelder\sphinxhyphen{}Mead as used in Karspeck et al. 2012
\sphinxcite{index:karspeck}
i.e. \sphinxurl{https://docs.scipy.org/doc/scipy/reference/optimize.minimize-neldermead.html}
default max\sphinxhyphen{}iter is 200 x (number\_of\_variables)
for 3 variables (Lx, Ly, theta) \textendash{}\textgreater{} 200x3 = 600
note: unlike variogram fitting, no nugget, no sill, and no residue
variance (normalised data but Fisher transform needed?)
can be adjusted using “maxiter” within “options” kwargs

\sphinxAtStartPar
Much of the variable names are defined the same way as earlier
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{X}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Array of displacements. Expected to be 1\sphinxhyphen{}dimensional if the ellipse
model is not anisotropic, 2\sphinxhyphen{}dimensional otherwise. In units of km if
the ellipse uses physical distances, otherwise in degrees. The
displacements are from each position within the test region to the
centre of the ellipse.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Vector of observed correlations between the centre of the ellipse
and each test point.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{guesses=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} List of initial values to scipy.optimize.minimize, default guesses
for the ellipse model are used if not set.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bounds=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Tuples/lists of bounds for fitted parameters. Default bounds for
the ellipse model are used if not set.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{opt\_method}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} scipy.optimize.minimize optimisation method. Defaults to
“Nelder\sphinxhyphen{}Mead”. See \sphinxurl{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html}
for valid values.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{tol=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} scipy.optimize.minimize convergence tolerance

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{estimate\_SE=\textquotesingle{}bootstrap\_parallel\textquotesingle{}}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} How to estimate standard error if needed. If not set no standard
error is computed.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{n\_sim=500}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of bootstrap to estimate standard error

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs=DEFAULT\_N\_JOBS}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of threads for bootstrapping if \sphinxtitleref{estimate\_SE} is set to
“bootstrap\_parallel”.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{backend=DEFAULT\_BACKEND}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} joblib backend for bootstrapping.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{random\_seed=1234}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Random seed for bootstrap

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{OptimizeResult}}, \sphinxcode{\sphinxupquote{float}} | \sphinxcode{\sphinxupquote{None}}, \sphinxcode{\sphinxupquote{list}}{[}\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{float}}, \sphinxcode{\sphinxupquote{float}}{]}{]}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{results} (\sphinxstyleemphasis{OptimizeResult}) \textendash{} Output of scipy.optimize.minimize

\item {}
\sphinxAtStartPar
\sphinxstylestrong{SE} (\sphinxstyleemphasis{float | None}) \textendash{} Standard error of the fitted parameters

\item {}
\sphinxAtStartPar
\sphinxstylestrong{bounds} (\sphinxstyleemphasis{list{[}tuple{[}float, …{]}{]}}) \textendash{} Bounds of fitted parameters

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{negative\_log\_likelihood() (glomar\_gridding.ellipse.EllipseModel method)@\spxentry{negative\_log\_likelihood()}\spxextra{glomar\_gridding.ellipse.EllipseModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseModel.negative_log_likelihood}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{negative\_log\_likelihood}}}
{\sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{params}}\sphinxparamcomma \sphinxparam{\DUrole{n}{arctanh\_transform}\DUrole{o}{=}\DUrole{default_value}{True}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the negative log\sphinxhyphen{}likelihood given observed X independent
observations (displacements) and y dependent variable (the observed
correlation), and Matern parameters params. Namely does the Matern
covariance function using params, how close it explains the observed
displacements and correlations.

\sphinxAtStartPar
log(LL) = SUM (f (y,x|params) )
params = Maximise (log(LL))
params = Minimise (\sphinxhyphen{}log(LL)) which is how usually the computer solves it
assuming errors of params are normally distributed

\sphinxAtStartPar
There is a hidden scale/standard deviation in
stats.norm.logpdf(scale, which defaults to 1)
but since we have scaled our values to covariance to correlation (and
even used Fisher transform) as part of the function, it can be dropped

\sphinxAtStartPar
Otherwise, you need to have stdev as the last value of params, and
should be set to the scale parameter
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{X}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Observed displacements to the centre of the ellipse.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Observed correlation against the centre of the ellipse.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{params}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Ellipse parameters (in the current optimize iteration) or if you
want to compute the actual negative log\sphinxhyphen{}likelihood.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{arctanh\_transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Should the Fisher (arctanh) transform be used
This is usually option, but it does make the computation
more stable if they are close to 1 (or \sphinxhyphen{}1; doesn’t apply here)

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{nLL} \textendash{} The negative log likelihood

\sphinxlineitem{Return type}
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{negative\_log\_likelihood\_function() (glomar\_gridding.ellipse.EllipseModel method)@\spxentry{negative\_log\_likelihood\_function()}\spxextra{glomar\_gridding.ellipse.EllipseModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseModel.negative_log_likelihood_function}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{negative\_log\_likelihood\_function}}}
{\sphinxparam{\DUrole{n}{X}}\sphinxparamcomma \sphinxparam{\DUrole{n}{y}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Creates a function that can be fed into scipy.optimizer.minimize
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{Callable}}{[}{[}\sphinxcode{\sphinxupquote{list}}{[}\sphinxcode{\sphinxupquote{float}}{]}{]}, \sphinxcode{\sphinxupquote{float}}{]}}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{Ellipse Parameter Estimation}
\label{\detokenize{ellipse:ellipse-parameter-estimation}}\index{EllipseBuilder (class in glomar\_gridding.ellipse)@\spxentry{EllipseBuilder}\spxextra{class in glomar\_gridding.ellipse}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseBuilder}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.ellipse.}}\sphinxbfcode{\sphinxupquote{EllipseBuilder}}}
{\sphinxparam{\DUrole{n}{data\_array}}\sphinxparamcomma \sphinxparam{\DUrole{n}{coords}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Class to build spatial covariance and correlation matrices used to estimate
ellipse parameterss using an instance of EllipseModel which sets up the
defaults for a given configuration.

\sphinxAtStartPar
To fit ellipse parameters to the correlation of the input data\_array, call
self.fit\_ellipse\_model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data\_array}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ma.MaskedArray}}) \textendash{} Training data stored within a numpy array. In general, this input should
be extracted from an xarray.DataArray, and masked appropriately.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{coords}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.Coordinates}}) \textendash{} The coordinates associated with the data\_array value. It is expected
that these are {[}“time”, “latitude”, “longitude”{]}

\end{itemize}

\end{description}\end{quote}
\index{calc\_cov() (glomar\_gridding.ellipse.EllipseBuilder method)@\spxentry{calc\_cov()}\spxextra{glomar\_gridding.ellipse.EllipseBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseBuilder.calc_cov}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{calc\_cov}}}
{\sphinxparam{\DUrole{n}{rounding}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate covariance and correlation matrices.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{rounding}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Round the values of the output.

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{compute\_params() (glomar\_gridding.ellipse.EllipseBuilder method)@\spxentry{compute\_params()}\spxextra{glomar\_gridding.ellipse.EllipseBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseBuilder.compute_params}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{compute\_params}}}
{\sphinxparam{\DUrole{n}{default\_value}}\sphinxparamcomma \sphinxparam{\DUrole{n}{matern\_ellipse}}\sphinxparamcomma \sphinxparam{\DUrole{n}{max\_distance}\DUrole{o}{=}\DUrole{default_value}{20.0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{min\_distance}\DUrole{o}{=}\DUrole{default_value}{0.3}}\sphinxparamcomma \sphinxparam{\DUrole{n}{delta\_x\_method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Modified\_Met\_Office\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{guesses}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bounds}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{opt\_method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Nelder\sphinxhyphen{}Mead\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{tol}\DUrole{o}{=}\DUrole{default_value}{0.0001}}\sphinxparamcomma \sphinxparam{\DUrole{n}{estimate\_SE}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n\_jobs}\DUrole{o}{=}\DUrole{default_value}{4}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n\_sim}\DUrole{o}{=}\DUrole{default_value}{500}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Fit ellipses/covariance models using adhoc local covariances to all
unmasked grid points

\sphinxAtStartPar
The form of the covariance model depends on the “fform” attribute of the
Ellipse model:
\begin{itemize}
\item {}
\sphinxAtStartPar
isotropic (radial distance only)

\item {}
\sphinxAtStartPar
anistropic (x and y are different, but not rotated)

\item {}
\sphinxAtStartPar
anistropic\_rotated (rotated)

\end{itemize}

\sphinxAtStartPar
If the “fform” attribute ends with \_pd then physical distances are used
instead of degrees

\sphinxAtStartPar
range is defined max\_distance (either in km and degrees)
default is in degrees, but needs to be km if fform is from \_pd series
\textless{}— likely to be wrong: max\_distance should only be in degrees

\sphinxAtStartPar
there is also a min\_distance in which values,
matern function is not defined at the origin, so the 0.0 needs to
removed

\sphinxAtStartPar
v = matern covariance function shape parameter
Karspeck et al. \sphinxcite{index:karspeck} and Paciorek \& Schervish
\sphinxcite{index:paciorekschervish}
but 0.5 and 1.5 are popular 0.5 gives an exponential decay
lim v\textendash{}\textgreater{}inf, Gaussian shape

\sphinxAtStartPar
delta\_x\_method: only meaningful for \_pd fits:
\begin{itemize}
\item {}
\sphinxAtStartPar
“Met\_Office”: Cylindrical Earth delta\_x = 6400km x delta\_lon
(in radians)

\item {}
\sphinxAtStartPar
“Modified\_Met\_Office”: uses the average zonal dist at different
lat

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{default\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Default value(s) to fill arrays where parameter estimation is not
possible (typically due to masking). Typically, one should set a
value that is appropriate to the type of the field. If a single
value is provided, this is used for all fields. If not, the length
of the list of default values must equal the number of parameters
of the \sphinxtitleref{EllipseModel}

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{matern\_ellipse}} ({\hyperref[\detokenize{ellipse:glomar_gridding.ellipse.EllipseModel}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{EllipseModel}}}}}) \textendash{} EllipseModel to use for parameter estimation

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{max\_distance}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Maximum separation in distance unit that data will be fed
into parameter fitting
Units depend on fform (it is usually either degrees or km)

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_distance}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Minimum separation in distance unit that data
will be fed into parameter fitting
Units depend on fform (it is usually either degrees or km)
Note: Due to the way we compute the Matern function,
it is undefined at dist == 0 even if the limit \sphinxhyphen{}\textgreater{} zero is obvious.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delta\_x\_method="Modified\_Met\_Office"}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{}
\sphinxAtStartPar
How to compute distances between grid points
For istropic variogram/covariances, this is a trivial problem;
you can just take the haversine or
Euclidean (“tunnel”) distance as they are non\sphinxhyphen{}directional.

\sphinxAtStartPar
But it is non trivial for anistropic cases,
you have to define a set of orthogonal space. In HadSST4,
Earth is assumed to be cylindrical “tin can” Earth,
so you can just define the orthogonal space by
lines of constant lat and lon (delta\_x\_method=”Met\_Office”).

\sphinxAtStartPar
The modified “Modified\_Met\_Office” is a variation to that,
but allow the tin can get squished at the poles.
(Sinusoidal projection). This does results in a problem:
the zonal displacement now depends in which latitude
you compute on (at the beginning latitude or at the end latitude).
Here we take the average of the two.


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{guesses=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{ of }}\sphinxstyleliteralemphasis{\sphinxupquote{floats; None uses default guess values}}) \textendash{} Initial guess values that get feeds in the optimizer for MLE.
In scipy, you are required to do so (but R often doesn’t).
You should anyway; sometimes they do funny things
if you don’t (per recommendation of David Stephenson)

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bounds=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{ of }}\sphinxstyleliteralemphasis{\sphinxupquote{floats; None uses default bounds values}}) \textendash{} This is essentially a Bayesian “uniformative prior”
that forces convergence if the optimizer hits the bound.
For lower resolution fitting, this is rarely a problem.
For higher resolution fits, this often interacts with
the limit of the data you can put into the fit the optimizer
may fail to converge if the input data is very smooth (aka ENSO
region, where anomalies are smooth over very large (\textasciitilde{}10000km)
scales).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{opt\_method=\textquotesingle{}Nelder\sphinxhyphen{}Mead\textquotesingle{}}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} scipy.optimize method. Nelder\sphinxhyphen{}Mead is the one used by \sphinxcite{index:karspeck}.
See \sphinxurl{https://docs.scipy.org/doc/scipy/tutorial/optimize.html}
for valid options

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{tol=0.001}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{}
\sphinxAtStartPar
Set convergence tolerance for scipy optimize.
See \sphinxurl{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\#scipy.optimize.minimize}

\sphinxAtStartPar
Note on new tol kwarg:
For N\sphinxhyphen{}M, this sets the value to both xatol and fatol
Default is 1E\sphinxhyphen{}4
Since it affects accuracy of all values including rotation
rotation angle 0.001 rad \textasciitilde{} 0.05 deg


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{estimate\_SE=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} The code can estimate the standard error if the Matern parameters.
This is not usually used or discussed for the purpose of kriging.
Certain opt\_method (gradient descent) can do this automatically
using Fisher Info for certain covariance function,
but is not possible for some nasty functions (aka Bessel
func) gets involved nor it is possible for some optimisers
(such as Nelder\sphinxhyphen{}Mead).
The code does it using bootstrapping.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs=DEFAULT\_N\_JOBS}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} If parallel processing, number of threads to use.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{n\_sim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of simulations to bootstrap for SE estimation.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar

\sphinxAtStartPar
\sphinxstylestrong{params} \textendash{} Containing arrays for each parameter in the ellipse model class.
Note that one array is likely to be “qc\_code”, which takes values:
\begin{itemize}
\item {}
\sphinxAtStartPar
0: success

\item {}
\sphinxAtStartPar
2: success but with one parameter reaching upper
boundaries

\item {}
\sphinxAtStartPar
3: success with multiple parameters reaching the
boundaries (aka both Lx and Ly), can be both at lower or
upper boundaries

\item {}
\sphinxAtStartPar
9: fail, probably due to running out of maxiter (see
scipy.optimize.minimize kwargs “options)”

\end{itemize}


\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.Dataset

\end{description}\end{quote}

\end{fulllineitems}

\index{find\_nearest\_xy\_index\_in\_cov\_matrix() (glomar\_gridding.ellipse.EllipseBuilder method)@\spxentry{find\_nearest\_xy\_index\_in\_cov\_matrix()}\spxextra{glomar\_gridding.ellipse.EllipseBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseBuilder.find_nearest_xy_index_in_cov_matrix}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{find\_nearest\_xy\_index\_in\_cov\_matrix}}}
{\sphinxparam{\DUrole{n}{lonlat}}\sphinxparamcomma \sphinxparam{\DUrole{n}{use\_full}\DUrole{o}{=}\DUrole{default_value}{False}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Find the nearest column/row index of the covariance
that corresponds to a specific lat lon
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{int}}, \sphinxcode{\sphinxupquote{ndarray}}{]}}

\end{description}\end{quote}

\end{fulllineitems}

\index{fit\_ellipse\_model() (glomar\_gridding.ellipse.EllipseBuilder method)@\spxentry{fit\_ellipse\_model()}\spxextra{glomar\_gridding.ellipse.EllipseBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseBuilder.fit_ellipse_model}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{fit\_ellipse\_model}}}
{\sphinxparam{\DUrole{n}{xy\_point}}\sphinxparamcomma \sphinxparam{\DUrole{n}{matern\_ellipse}}\sphinxparamcomma \sphinxparam{\DUrole{n}{max\_distance}\DUrole{o}{=}\DUrole{default_value}{20.0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{min\_distance}\DUrole{o}{=}\DUrole{default_value}{0.3}}\sphinxparamcomma \sphinxparam{\DUrole{n}{delta\_x\_method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Modified\_Met\_Office\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{guesses}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bounds}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{opt\_method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Nelder\sphinxhyphen{}Mead\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{tol}\DUrole{o}{=}\DUrole{default_value}{0.001}}\sphinxparamcomma \sphinxparam{\DUrole{n}{estimate\_SE}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n\_jobs}\DUrole{o}{=}\DUrole{default_value}{4}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n\_sim}\DUrole{o}{=}\DUrole{default_value}{500}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Fit ellipses/covariance models using adhoc local covariances

\sphinxAtStartPar
the form of the covariance model depends on the “fform” attribute of the
Ellipse model:
\begin{quote}

\sphinxAtStartPar
isotropic (radial distance only)
anistropic (x and y are different, but not rotated)
anistropic\_rotated (rotated)
\end{quote}

\sphinxAtStartPar
If the “fform” attribute ends with \_pd then physical distances are used
instead of degrees

\sphinxAtStartPar
range is defined max\_distance (either in km and degrees)
default is in degrees, but needs to be km if fform is from \_pd series
\textless{}— likely to be wrong: max\_distance should only be in degrees

\sphinxAtStartPar
there is also a min\_distance in which values,
matern function is not defined at the origin, so the 0.0 needs to
removed

\sphinxAtStartPar
v = matern covariance function shape parameter
Karspeck et al. \sphinxcite{index:karspeck} and Paciorek \& Schervish
\sphinxcite{index:paciorekschervish}
use 3 and 4 but 0.5 and 1.5 are popular. 0.5 gives an exponential decay:
lim v\textendash{}\textgreater{}inf, Gaussian shape
\begin{description}
\sphinxlineitem{delta\_x\_method: only meaningful for \_pd fits:}\begin{itemize}
\item {}
\sphinxAtStartPar
“Met\_Office”: Cylindrical Earth delta\_x = 6400km x delta\_lon
(in radians)

\item {}
\sphinxAtStartPar
“Modified\_Met\_Office”: uses the average zonal dist at different
lat

\end{itemize}

\end{description}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{xy\_point}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The index point where ellipses will be fitted to

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{max\_distance}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Maximum separation in distance unit that data will be fed
into parameter fitting
Units depend on fform (it is usually either degrees or km)

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_distance}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Minimum separation in distance unit that data
will be fed into parameter fitting
Units depend on fform (it is usually either degrees or km)
Note: Due to the way we compute the Matern function,
it is undefined at dist == 0 even if the limit \sphinxhyphen{}\textgreater{} zero is obvious.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delta\_x\_method="Modified\_Met\_Office"}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{}
\sphinxAtStartPar
How to compute distances between grid points
For istropic variogram/covariances, this is a trivial problem;
you can just take the haversine or
Euclidean (“tunnel”) distance as they are non\sphinxhyphen{}directional.

\sphinxAtStartPar
But it is non trivial for anistropic cases,
you have to define a set of orthogonal space. In HadSST4,
Earth is assumed to be cylindrical “tin can” Earth,
so you can just define the orthogonal space by
lines of constant lat and lon (delta\_x\_method=”Met\_Office”).

\sphinxAtStartPar
The modified “Modified\_Met\_Office” is a variation to that,
but allow the tin can get squished at the poles.
(Sinusoidal projection). This does results in a problem:
the zonal displacement now depends in which latitude
you compute on (at the beginning latitude or at the end latitude).
Here we take the average of the two.


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{guesses=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{ of }}\sphinxstyleliteralemphasis{\sphinxupquote{floats; None uses default guess values}}) \textendash{} Initial guess values that get feeds in the optimizer for MLE.
In scipy, you are required to do so (but R often doesn’t).
You should anyway; sometimes they do funny things
if you don’t (per recommendation of David Stephenson)

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bounds=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{ of }}\sphinxstyleliteralemphasis{\sphinxupquote{floats; None uses default bounds values}}) \textendash{} This is essentially a Bayesian “uniformative prior”
that forces convergence if the optimizer hits the bound.
For lower resolution fitting, this is rarely a problem.
For higher resolution fits, this often interacts with
the limit of the data you can put into the fit the optimizer
may fail to converge if the input data is very smooth (aka ENSO
region, where anomalies are smooth over very large (\textasciitilde{}10000km)
scales).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{opt\_method=\textquotesingle{}Nelder\sphinxhyphen{}Mead\textquotesingle{}}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} scipy.optimize method. Nelder\sphinxhyphen{}Mead is the one used by \sphinxcite{index:karspeck}.
See \sphinxurl{https://docs.scipy.org/doc/scipy/tutorial/optimize.html}
for valid options

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{tol=0.001}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{}
\sphinxAtStartPar
Set convergence tolerance for scipy optimize.
See \sphinxurl{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\#scipy.optimize.minimize}

\sphinxAtStartPar
Note on new tol kwarg:
For N\sphinxhyphen{}M, this sets the value to both xatol and fatol
Default is 1E\sphinxhyphen{}4 (?)
Since it affects accuracy of all values including rotation
rotation angle 0.001 rad \textasciitilde{} 0.05 deg


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{estimate\_SE=None}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} The code can estimate the standard error if the Matern parameters.
This is not usually used or discussed for the purpose of kriging.
Certain opt\_method (gradient descent) can do this automatically
using Fisher Info for certain covariance function,
but is not possible for some nasty functions (aka Bessel
func) gets involved nor it is possible for some optimisers
(such as Nelder\sphinxhyphen{}Mead).
The code does it using bootstrapping.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs=DEFAULT\_N\_JOBS}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} If parallel processing, number of threads to use.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{n\_sim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of simulations to bootstrap for SE estimation.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Dictionary with results of the fit and the observed correlation
matrix.

\sphinxlineitem{Return type}
\sphinxAtStartPar
dict

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{Ellipse\sphinxhyphen{}based Covariance Estimation}
\label{\detokenize{ellipse:ellipse-based-covariance-estimation}}\index{EllipseCovarianceBuilder (class in glomar\_gridding.ellipse)@\spxentry{EllipseCovarianceBuilder}\spxextra{class in glomar\_gridding.ellipse}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseCovarianceBuilder}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.ellipse.}}\sphinxbfcode{\sphinxupquote{EllipseCovarianceBuilder}}}
{\sphinxparam{\DUrole{n}{Lx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{Ly}}\sphinxparamcomma \sphinxparam{\DUrole{n}{theta}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stdev}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lats}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lons}}\sphinxparamcomma \sphinxparam{\DUrole{n}{v}}\sphinxparamcomma \sphinxparam{\DUrole{n}{delta\_x\_method=\textquotesingle{}Modified\_Met\_Office\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{max\_dist=6000.0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{precision=\textless{}class \textquotesingle{}numpy.float32\textquotesingle{}\textgreater{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{covariance\_method=\textquotesingle{}array\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{batch\_size=None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute covariance from Ellipse parameters and positions.

\sphinxAtStartPar
v = Matern covariance shape parameter

\sphinxAtStartPar
Lx \sphinxhyphen{} an numpy array of horizontal length scales (
Ly \sphinxhyphen{} an numpy array of meridonal length scales
theta \sphinxhyphen{} an numpy array of rotation angles (RADIANS ONLY)

\sphinxAtStartPar
sdev \sphinxhyphen{} standard deviation \textendash{} right now it just takes a numeric array
if you have multiple contribution to sdev (uncertainties derived from
different sources), you need to put them into one array

\sphinxAtStartPar
Rules:
Valid (ocean) point:
1) cov\_ns and cor\_ns are computed out to max\_dist; out of range = 0.0
2) Masked points are ignored

\sphinxAtStartPar
Invalid (masked) points:
1) Skipped over

\sphinxAtStartPar
max\_dist:
float (km) or (degrees if you want to work in degrees), default 6000km
if you want infinite distance, just set it to a large number, some fun
numbers to use:
\begin{itemize}
\item {}
\sphinxAtStartPar
1.5E8 (i.e. \textasciitilde{}1 astronomical unit (Earth\sphinxhyphen{}Sun distance))

\item {}
\sphinxAtStartPar
5.0E9 (average distance between Earth and not\sphinxhyphen{}a\sphinxhyphen{}planet\sphinxhyphen{}anymore Pluto)

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Lx}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Arrays with non\sphinxhyphen{}stationary parameters

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Ly}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Arrays with non\sphinxhyphen{}stationary parameters

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{theta}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Arrays with non\sphinxhyphen{}stationary parameters

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stdev}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Arrays with non\sphinxhyphen{}stationary parameters

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lats}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Arrays containing the latitude and longitude values

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lons}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Arrays containing the latitude and longitude values

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{v}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Matern shape parameter

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delta\_x\_method}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} How are displacements computed between points

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{max\_dist}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} If the Haversine distance between 2 points exceed max\_dist,
covariance is set to 0

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{precision}} (\sphinxstyleliteralemphasis{\sphinxupquote{type}}) \textendash{} Floating point precision of the output covariance numpy defaults to
np.float32.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{covariance\_method}} (\sphinxstyleliteralemphasis{\sphinxupquote{CovarianceMethod}}) \textendash{}
\sphinxAtStartPar
Set the covariance method used:
\begin{itemize}
\item {}
\sphinxAtStartPar
array (default): faster but uses significantly more memory as
more pre\sphinxhyphen{}computation is performed. Values are computed in a
vectorised method.

\item {}
\sphinxAtStartPar
loop: slower iterative process, computes each value individually

\item {}
\sphinxAtStartPar
batched: combines the above approaches.

\end{itemize}

\sphinxAtStartPar
If the number of grid\sphinxhyphen{}points exceeds 10\_000 and “array” method is used,
the method will be overwritten to “loop”.


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{batch\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Size of the batch to use for the “batched” method. Must be set if the
covariance\_method is set to “batched”.

\end{itemize}

\end{description}\end{quote}
\index{c\_ij\_anisotropic\_array() (glomar\_gridding.ellipse.EllipseCovarianceBuilder method)@\spxentry{c\_ij\_anisotropic\_array()}\spxextra{glomar\_gridding.ellipse.EllipseCovarianceBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseCovarianceBuilder.c_ij_anisotropic_array}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{c\_ij\_anisotropic\_array}}}
{\sphinxparam{\DUrole{n}{i\_s}}\sphinxparamcomma \sphinxparam{\DUrole{n}{j\_s}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the covariances between pairs of ellipses, at displacements.

\sphinxAtStartPar
Each ellipse is defined by values from Lxs, Lys, and thetas, with
standard deviation in stdevs.

\sphinxAtStartPar
The displacements between each pair of ellipses are x\_is and x\_js.

\sphinxAtStartPar
For N ellipses, the number of displacements should be 1/2 * N * (N \sphinxhyphen{} 1),
i.e. the displacement between each pair combination of ellipses. This
function will return the upper triangular values of the covariance
matrix (excluding the diagonal).

\sphinxAtStartPar
\sphinxtitleref{itertools.combinations} is used to handle ordering, so the
displacements must be ordered in the same way.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{i\_s}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The row indices for the covariance matrix.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{j\_s}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The column indices for the covariance matrix.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{c\_ij} \textendash{} A vector containing the covariance values between each pair of
ellipses. This will return the components of the upper triangle of
the covariance matrix as a vector (excluding the diagonal).

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{References}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {}
\sphinxAtStartPar
Paciorek and Schevrish 2006 \sphinxcite{index:paciorekschervish} Equation 8

\item {}
\sphinxAtStartPar
Karspeck et al. 2012 \sphinxcite{index:karspeck} Equation 17

\end{enumerate}

\end{fulllineitems}

\index{calculate\_cor() (glomar\_gridding.ellipse.EllipseCovarianceBuilder method)@\spxentry{calculate\_cor()}\spxextra{glomar\_gridding.ellipse.EllipseCovarianceBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseCovarianceBuilder.calculate_cor}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{calculate\_cor}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate correlation matrix from the covariance matrix
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{calculate\_covariance\_array() (glomar\_gridding.ellipse.EllipseCovarianceBuilder method)@\spxentry{calculate\_covariance\_array()}\spxextra{glomar\_gridding.ellipse.EllipseCovarianceBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseCovarianceBuilder.calculate_covariance_array}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{calculate\_covariance\_array}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the covariance matrix from the ellipse parameters
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{calculate\_covariance\_batched() (glomar\_gridding.ellipse.EllipseCovarianceBuilder method)@\spxentry{calculate\_covariance\_batched()}\spxextra{glomar\_gridding.ellipse.EllipseCovarianceBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseCovarianceBuilder.calculate_covariance_batched}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{calculate\_covariance\_batched}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the covariance matrix from ellipse parameters, using a batched
approach.
This approach is more memory safe and appropriate for low\sphinxhyphen{}memory
operations, but is slower than self.calculate\_covariance
which pre\sphinxhyphen{}computes values at all upper triangle points. This approach
performs pre\sphinxhyphen{}computation at all points within the current batch.

\sphinxAtStartPar
Each ellipse is defined by values from Lxs, Lys, and thetas, with
standard deviation in stdevs.

\sphinxAtStartPar
Requires a batch\_size parameter.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}
\subsubsection*{References}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {}
\sphinxAtStartPar
Paciorek and Schevrish 2006 \sphinxcite{index:paciorekschervish} Equation 8

\item {}
\sphinxAtStartPar
Karspeck et al. 2012 \sphinxcite{index:karspeck} Equation 17

\end{enumerate}

\end{fulllineitems}

\index{calculate\_covariance\_loop() (glomar\_gridding.ellipse.EllipseCovarianceBuilder method)@\spxentry{calculate\_covariance\_loop()}\spxextra{glomar\_gridding.ellipse.EllipseCovarianceBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseCovarianceBuilder.calculate_covariance_loop}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{calculate\_covariance\_loop}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the covariance matrix from ellipse parameters, using a loop.
This approach is more memory safe and appropriate for low\sphinxhyphen{}memory
operations, but is significantly slower than self.calculate\_covariance
which uses a lot of pre\sphinxhyphen{}computation and a vectorised approach.

\sphinxAtStartPar
Each ellipse is defined by values from Lxs, Lys, and thetas, with
standard deviation in stdevs.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}
\subsubsection*{References}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {}
\sphinxAtStartPar
Paciorek and Schevrish 2006 \sphinxcite{index:paciorekschervish} Equation 8

\item {}
\sphinxAtStartPar
Karspeck et al. 2012 \sphinxcite{index:karspeck} Equation 17

\end{enumerate}

\end{fulllineitems}

\index{uncompress\_cov() (glomar\_gridding.ellipse.EllipseCovarianceBuilder method)@\spxentry{uncompress\_cov()}\spxextra{glomar\_gridding.ellipse.EllipseCovarianceBuilder method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{ellipse:glomar_gridding.ellipse.EllipseCovarianceBuilder.uncompress_cov}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{uncompress\_cov}}}
{\sphinxparam{\DUrole{n}{diag\_fill\_value}\DUrole{o}{=}\DUrole{default_value}{nan}}\sphinxparamcomma \sphinxparam{\DUrole{n}{fill\_value}\DUrole{o}{=}\DUrole{default_value}{nan}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Convert the covariance matrix to full grid size.

\sphinxAtStartPar
Optionally, fill the array with along the diagonal with a
\sphinxtitleref{diag\_fill\_value} and off the diagonal with a \sphinxtitleref{fill\_value}, which both
default to \sphinxtitleref{np.nan}.

\sphinxAtStartPar
Overwrites the \sphinxtitleref{cov\_ns} attribute.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{diag\_fill\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Value to assign to diagonal masked values. Defaults to \sphinxtitleref{np.nan}

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fill\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Value to assign to off\sphinxhyphen{}diagonal masked values. Defaults to \sphinxtitleref{np.nan}

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}


\sphinxstepscope


\chapter{Error Covariance}
\label{\detokenize{error_covariance:module-glomar_gridding.error_covariance}}\label{\detokenize{error_covariance:error-covariance}}\label{\detokenize{error_covariance::doc}}\index{module@\spxentry{module}!glomar\_gridding.error\_covariance@\spxentry{glomar\_gridding.error\_covariance}}\index{glomar\_gridding.error\_covariance@\spxentry{glomar\_gridding.error\_covariance}!module@\spxentry{module}}
\sphinxAtStartPar
Functions for computing correlated and uncorrelated components of the error
covariance. These values are determined from standard deviation (sigma) values
assigned to groupings within the observational data.

\sphinxAtStartPar
The correlated components will form a matrix that is permutationally equivalent
to a block diagonal matrix (i.e. the matrix will be block diagonal if the
observational data is sorted by the group).

\sphinxAtStartPar
The uncorrelated components will form a diagonal matrix.

\sphinxAtStartPar
Further a distance\sphinxhyphen{}based component can be constructed, where distances between
records within the same grid box are evaluated.

\sphinxAtStartPar
The functions in this module are valid for observational data where there could
be more than 1 observation in a gridbox.
\index{correlated\_components() (in module glomar\_gridding.error\_covariance)@\spxentry{correlated\_components()}\spxextra{in module glomar\_gridding.error\_covariance}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{error_covariance:glomar_gridding.error_covariance.correlated_components}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.error\_covariance.}}\sphinxbfcode{\sphinxupquote{correlated\_components}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{group\_col}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bias\_sig\_col}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bias\_sig\_map}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Returns measurements covariance matrix updated by adding bias uncertainty to
the measurements based on a grouping within the observational data.

\sphinxAtStartPar
The result is equivalent to a block diagonal matrix via permutation. If the
input observational data is sorted by the group column then the resulting
matrix is block diagonal, where the blocks are the size of each grouping.
The values in each block are the square of the sigma value associated with
the grouping.

\sphinxAtStartPar
Note that in most cases the output is not a block\sphinxhyphen{}diagonal, as the input
is not usually sorted by the group column. In most processing cases, the
input dataframe will be sorted by the gridbox index.

\sphinxAtStartPar
The values can either be pre\sphinxhyphen{}defined in the observational dataframe, and
can be indicated by the “bias\_val\_col” argument. Alternatively, a mapping
can be passed, the values will be then assigned by this mapping of group to
sigma.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} Observational DataFrame including group information and bias uncertainty
values for each grouping. It is assumed that a single bias uncertainty
value applies to the whole group, and is applied as cross terms in the
covariance matrix (plus to the diagonal).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{group\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the column that can be used to partition the observational
DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bias\_sig\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Name of the column containing bias uncertainty values for each of
the groups identified by ‘group\_col’. It is assumed that a single bias
uncertainty value applies to the whole group, and is applied as cross
terms in the covariance matrix (plus to the diagonal).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bias\_sig\_map}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Mapping between values in the group\_col and bias uncertainty values,
if bias\_val\_col is not in the DataFrame.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
The correlated components of the error covariance.

\end{description}\end{quote}

\end{fulllineitems}

\index{dist\_weight() (in module glomar\_gridding.error\_covariance)@\spxentry{dist\_weight()}\spxextra{in module glomar\_gridding.error\_covariance}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{error_covariance:glomar_gridding.error_covariance.dist_weight}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.error\_covariance.}}\sphinxbfcode{\sphinxupquote{dist\_weight}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{dist\_fn}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid\_idx}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}grid\_idx\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{dist\_kwargs}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the distance and weight matrices over gridboxes for an input Frame.

\sphinxAtStartPar
This function acts as a wrapper for a distance function, allowing for
computation of the distances between positions in the same gridbox using any
distance metric.

\sphinxAtStartPar
The weightings from this function are for the gridbox mean of the
observations within a gridbox.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} The observation DataFrame, containing the columns required for
computation of the distance matrix. Contains the “grid\_idx” column which
indicates the gridbox for a given observation. The index of the
DataFrame should match the index ordering for the output distance
matrix/weights.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dist\_fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{Callable}}) \textendash{}
\sphinxAtStartPar
The function used to compute a distance matrix for all points in a given
grid\sphinxhyphen{}cell. Takes as input a polars.DataFrame as first argument. Any
other arguments should be constant over all gridboxes, or can be a
look\sphinxhyphen{}up table that can use values in the DataFrame to specify values
specific to a gridbox. The function should return a numpy matrix, which
is the distance matrix for the gridbox only. This wrapper function will
correctly apply this matrix to the larger distance matrix using the
index from the DataFrame.

\sphinxAtStartPar
If dist\_fn is None, then no distances are computed and None is returned
for the dist value.


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the column containing the grid index values

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**dist\_kwargs}} \textendash{} Arguments to be passed to dist\_fn. In general these should be constant
across all gridboxes. It is possible to pass a look\sphinxhyphen{}up table that
contains pre\sphinxhyphen{}computed values that are gridbox specific, if the keys can
be matched to a column in df.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{ndarray}}, \sphinxcode{\sphinxupquote{ndarray}}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{dist} (\sphinxstyleemphasis{numpy.matrix}) \textendash{} The distance matrix, which contains the same number of rows and columns
as rows in the input DataFrame df. The values in the matrix are 0 if the
indices of the row/column are for observations from different gridboxes,
and non\sphinxhyphen{}zero if the row/column indices fall within the same gridbox.
Consequently, with appropriate re\sphinxhyphen{}arrangement of rows and columns this
matrix can be transformed into a block\sphinxhyphen{}diagonal matrix. If the DataFrame
input is pre\sphinxhyphen{}sorted by the gridbox column, then the result is a
block\sphinxhyphen{}diagonal matrix.

\sphinxAtStartPar
If dist\_fn is None, then this value will be None.

\item {}
\sphinxAtStartPar
\sphinxstylestrong{weights} (\sphinxstyleemphasis{numpy.matrix}) \textendash{} A matrix of weights. This has dimensions n x p where n is the number of
unique gridboxes and p is the number of observations (the number of rows
in df). The values are 0 if the row and column do not correspond to the
same gridbox and equal to the inverse of the number of observations in a
gridbox if the row and column indices fall within the same gridbox. The
rows of weights are in a sorted order of the gridbox. Should this be
incorrect, one should re\sphinxhyphen{}arrange the rows after calling this function.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{get\_weights() (in module glomar\_gridding.error\_covariance)@\spxentry{get\_weights()}\spxextra{in module glomar\_gridding.error\_covariance}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{error_covariance:glomar_gridding.error_covariance.get_weights}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.error\_covariance.}}\sphinxbfcode{\sphinxupquote{get\_weights}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid\_idx}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}grid\_idx\textquotesingle{}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Get just the weight matrices over gridboxes for an input Frame.

\sphinxAtStartPar
The weightings from this function are for the gridbox mean of the
observations within a gridbox.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} The observation DataFrame, containing the columns required for
computation of the distance matrix. Contains the “grid\_idx” column which
indicates the gridbox for a given observation. The index of the
DataFrame should match the index ordering for the output weights.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the column containing the gridbox index from the output grid.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{weights} \textendash{} A matrix of weights. This has dimensions n x p where n is the number of
unique gridboxes and p is the number of observations (the number of rows
in df). The values are 0 if the row and column do not correspond to the
same gridbox and equal to the inverse of the number of observations in a
gridbox if the row and column indices fall within the same gridbox. The
rows of weights are in a sorted order of the gridbox. Should this be
incorrect, one should re\sphinxhyphen{}arrange the rows after calling this function.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.matrix

\end{description}\end{quote}

\end{fulllineitems}

\index{uncorrelated\_components() (in module glomar\_gridding.error\_covariance)@\spxentry{uncorrelated\_components()}\spxextra{in module glomar\_gridding.error\_covariance}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{error_covariance:glomar_gridding.error_covariance.uncorrelated_components}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.error\_covariance.}}\sphinxbfcode{\sphinxupquote{uncorrelated\_components}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{group\_col}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}data\_type\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs\_sig\_col}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs\_sig\_map}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculates the covariance matrix of the measurements (observations). This
is the uncorrelated component of the covariance.

\sphinxAtStartPar
The result is a diagonal matrix. The diagonal is formed by the square of the
sigma values associated with the values in the grouping.

\sphinxAtStartPar
The values can either be pre\sphinxhyphen{}defined in the observational dataframe, and
can be indicated by the “bias\_val\_col” argument. Alternatively, a mapping
can be passed, the values will be then assigned by this mapping of group to
sigma.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} The observational DataFrame containing values to group by.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{group\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the group column to use to set observational sigma values.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_sig\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Name of the column containing observational sigma values. If set and
present in the DataFrame, then this column is used as the diagonal of
the returned covariance matrix.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_sig\_map}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Mapping between group and observational sigma values used to define
the diagonal of the returned covariance matrix.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{ndarray}}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleemphasis{A diagonal matrix representing the uncorrelated components of the error}

\item {}
\sphinxAtStartPar
\sphinxstyleemphasis{covariance matrix.}

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}


\sphinxstepscope


\chapter{Kriging}
\label{\detokenize{kriging:kriging}}\label{\detokenize{kriging::doc}}
\sphinxAtStartPar
The \sphinxtitleref{glomar\_gridding.kriging} module contains classes and functions for interpolation via Kriging.
Two methods of Kriging are supported by \sphinxtitleref{glomar\_gridding}:
\begin{itemize}
\item {}
\sphinxAtStartPar
Simple Kriging

\item {}
\sphinxAtStartPar
Ordinary Kriging

\end{itemize}

\sphinxAtStartPar
For each Kriging method there is a class and a function. The recommended approach is to use the
classes, the functions will be deprecated in a future version of \sphinxtitleref{glomar\_gridding}. The classes
require the full grid spatial covariance structure, the observation values, and the grid index of
each observation, and an optional error covariance matrix as inputs. Each grid index should be a
single index value, and represents the flattened index, and connects directly to the corresponding
index of the covariance matrices. If an error covariance matrix is provided, the covariance matrix
will be automatically subset to the grid index values, if the resulting matrix contains \sphinxtitleref{nan} or \sphinxtitleref{0}
values on the diagonal, then the observation values and indices are filtered to exclude these
points, and the error covariance matrix is subset again. Just initialising the class does not solve
the system, this requires the \sphinxtitleref{solve} method to be called.


\section{Preparation}
\label{\detokenize{kriging:preparation}}
\sphinxAtStartPar
\sphinxtitleref{glomar\_gridding} provides functionality for preparing your data for the interpolation. The \sphinxtitleref{grid}
module has functionality for defining the output grid
({\hyperref[\detokenize{covariance:glomar_gridding.grid.grid_from_resolution}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.grid.grid\_from\_resolution()}}}}}) which allows the user to create a coordinate
system for the output, that can easily be mapped to a covariance matrix. The grid object is an
\sphinxtitleref{xarray.DataArray} object, with a coordinate system. Once the grid is defined, the observations can
be mapped to the grid. This creates a 1\sphinxhyphen{}dimensional index value that should match to the covariance
matrices used in the interpolation.
\index{map\_to\_grid() (in module glomar\_gridding.grid)@\spxentry{map\_to\_grid()}\spxextra{in module glomar\_gridding.grid}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.grid.map_to_grid}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.grid.}}\sphinxbfcode{\sphinxupquote{map\_to\_grid}}}
{\sphinxparam{\DUrole{n}{obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs\_coords}\DUrole{o}{=}\DUrole{default_value}{{[}\textquotesingle{}lat\textquotesingle{}, \textquotesingle{}lon\textquotesingle{}{]}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid\_coords}\DUrole{o}{=}\DUrole{default_value}{{[}\textquotesingle{}latitude\textquotesingle{}, \textquotesingle{}longitude\textquotesingle{}{]}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{sort}\DUrole{o}{=}\DUrole{default_value}{True}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bounds}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{add\_grid\_pts}\DUrole{o}{=}\DUrole{default_value}{True}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid\_prefix}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}grid\_\textquotesingle{}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Align an observation dataframe to a grid defined by an xarray DataArray.

\sphinxAtStartPar
Maps observations to the nearest grid\sphinxhyphen{}point, and sorts the data by the
1d index of the DataArray in a row\sphinxhyphen{}major format.

\sphinxAtStartPar
The grid defined by the latitude and longitude coordinates of the input
DataArray is then used as the output grid of the Gridding process.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} The observational DataFrame containing positional data with latitude,
longitude values within the \sphinxtitleref{obs\_latname} and \sphinxtitleref{obs\_lonname} columns
respectively. Observations are mapped to the nearest grid\sphinxhyphen{}point in the
grid.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} Contains the grid coordinates to map observations to.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_coords}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Names of the column containing positional values in the input
observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_coords}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Names of the coordinates in the input grid DataArray used to define the
grid.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sort}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Sort the observational DataFrame by the grid index

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bounds}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Optionally filter the grid and DataFrame to fall within spatial bounds.
This list must have the same size and ordering as \sphinxtitleref{obs\_coords} and
\sphinxtitleref{grid\_coords} arguments.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{add\_grid\_pts}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Add the grid positional information to the observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_prefix}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Prefix to use for the new grid columns in the observational DataFrame.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{obs} \textendash{} Containing additional \sphinxtitleref{grid\_*}, and \sphinxtitleref{grid\_idx} values
indicating the positions and grid index of the observation
respectively. The DataFrame is also sorted (ascendingly) by the
\sphinxtitleref{grid\_idx} columns for consistency with the gridding functions.

\sphinxlineitem{Return type}
\sphinxAtStartPar
pandas.DataFrame

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{obs} \PYG{o}{=} \PYG{n}{pl}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/path/to/obs.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{grid} \PYG{o}{=} \PYG{n}{grid\PYGZus{}from\PYGZus{}resolution}\PYG{p}{(}
\PYG{g+go}{        resolution=5,}
\PYG{g+go}{        bounds=[(\PYGZhy{}87.5, 90), (\PYGZhy{}177.5, 180)],  \PYGZsh{} Lower bound is centre}
\PYG{g+go}{        coord\PYGZus{}names=[\PYGZdq{}lat\PYGZdq{}, \PYGZdq{}lon\PYGZdq{}]}
\PYG{g+go}{    )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{obs} \PYG{o}{=} \PYG{n}{map\PYGZus{}to\PYGZus{}grid}\PYG{p}{(}\PYG{n}{obs}\PYG{p}{,} \PYG{n}{grid}\PYG{p}{,} \PYG{n}{grid\PYGZus{}coords}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lat}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lon}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\sphinxAtStartPar
For Kriging, the interpolation requires at most a single observation value in each grid box. If the
data contains multiple values in a single grid cell then these need to be combined.
\index{prep\_obs\_for\_kriging() (in module glomar\_gridding.kriging)@\spxentry{prep\_obs\_for\_kriging()}\spxextra{in module glomar\_gridding.kriging}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.prep_obs_for_kriging}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.kriging.}}\sphinxbfcode{\sphinxupquote{prep\_obs\_for\_kriging}}}
{\sphinxparam{\DUrole{n}{unmask\_idx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{unique\_obs\_idx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{weights}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{remove\_obs\_mean}\DUrole{o}{=}\DUrole{default_value}{0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs\_bias}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{error\_cov}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Prep masked observations for Kriging. Combines observations in the same
grid box to a single averaged observation using a weighted average.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{unmask\_idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Indices of all un\sphinxhyphen{}masked points for chosen date.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{unique\_obs\_idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Unique indices of all measurement points for a chosen date,
representative of the indices of gridboxes, which have =\textgreater{} 1 measurement.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{weights}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Weight matrix (inverse of counts of observations).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} All point observations/measurements for the chosen date.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{remove\_obs\_mean}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{}
\sphinxAtStartPar
Should the mean or median from obs be removed and added back onto obs?
\begin{itemize}
\item {}
\sphinxAtStartPar
0 = No (default action)

\item {}
\sphinxAtStartPar
1 = the mean is removed

\item {}
\sphinxAtStartPar
2 = the median is removed

\item {}
\sphinxAtStartPar
3 = the spatial meam os removed

\end{itemize}

\sphinxAtStartPar
Note that the mean will need to be reapplied to the Kriging result.


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_bias}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Bias of all measurement points for a chosen date (corresponds to x\_obs).

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{ndarray}}, \sphinxcode{\sphinxupquote{ndarray}}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{obs\_idx} (\sphinxstyleemphasis{numpy.ndarray{[}int{]}}) \textendash{} Subset of grid\sphinxhyphen{}box indices containing observations that are unmasked.

\item {}
\sphinxAtStartPar
\sphinxstylestrong{grid\_obs} (\sphinxstyleemphasis{numpy.ndarray{[}float{]}}) \textendash{} Unmasked and combined observations

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}



\section{Simple Kriging}
\label{\detokenize{kriging:simple-kriging}}\index{SimpleKriging (class in glomar\_gridding.kriging)@\spxentry{SimpleKriging}\spxextra{class in glomar\_gridding.kriging}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.SimpleKriging}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.kriging.}}\sphinxbfcode{\sphinxupquote{SimpleKriging}}}
{\sphinxparam{\DUrole{n}{covariance}}\sphinxparamcomma \sphinxparam{\DUrole{n}{idx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{error\_cov}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Class for SimpleKriging.

\sphinxAtStartPar
The equation for simple Kriging is:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross} \times y + \mu\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(\mu\) is a constant known mean, typically this is 0.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{covariance}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The spatial covariance matrix. This can be a pre\sphinxhyphen{}computed matrix loaded
into the environment, or computed from a Variogram class or using
Ellipse methods.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The 1d indices of observation grid points. These values should be
between 0 and (N * M) \sphinxhyphen{} 1 where N, M are the number of longitudes
and latitudes respectively. Note that these values should also be
computed using “C” ordering in numpy reshaping. They can be
computed from a grid using glomar\_gridding.grid.map\_to\_grid. Each
value should only appear once. Points that contain more than 1
observation should be averaged

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The observation values. If there are multiple observations in any
grid box then these values need to be averaged into one value per
grid box.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{error\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Optionally add error covariance values to the covariance between
observation grid points.

\end{itemize}

\end{description}\end{quote}
\index{constraint\_mask() (glomar\_gridding.kriging.SimpleKriging method)@\spxentry{constraint\_mask()}\spxextra{glomar\_gridding.kriging.SimpleKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.SimpleKriging.constraint_mask}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{constraint\_mask}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the observational constraint mask (A14 in \sphinxcite{index:morice-2021}) to
determine if a grid point should be masked/weights modified by how far
it is to its near observed point

\sphinxAtStartPar
Note: typo in Section A4 in \sphinxcite{index:morice-2021} (confirmed by authors).

\sphinxAtStartPar
Equation to use is A14 is incorrect. Easily noticeable because
dimensionally incorrect is wrong, but the correct answer is easy to
figure out.

\sphinxAtStartPar
Correct Equation (extra matrix inverse for \(C_{obs} + E\)):
\begin{equation*}
\begin{split}\frac{
    1 - diag(C - C_{cross}^T \times (C_{obs} + E)^{-1}
             \times C_{cross})
}{diag(C)} < \alpha\end{split}
\end{equation*}
\sphinxAtStartPar
This can be re\sphinxhyphen{}written as:
\begin{equation*}
\begin{split}\frac{
    diag(C_{cross}^T \times (C_{obs} + E)^{-1} \times C_{cross})
}{diag(C)} < \alpha\end{split}
\end{equation*}
\sphinxAtStartPar
\(\alpha\) is chosen to be 0.25 in the UKMO paper

\sphinxAtStartPar
Written by S. Chan, modified by J. Siddons.

\sphinxAtStartPar
This requires that the \sphinxtitleref{kriging\_weights} attribute is set.
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{constraint\_mask} \textendash{} Constraint mask values, the left\sphinxhyphen{}hand\sphinxhyphen{}side of equation A14 from
Morice et al. (2021). This is a vector of length \sphinxtitleref{k\_obs.size{[}0{]}}.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{References}

\sphinxAtStartPar
\sphinxcite{index:morice-2021}: \sphinxurl{https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019JD032361}

\end{fulllineitems}

\index{get\_kriging\_weights() (glomar\_gridding.kriging.SimpleKriging method)@\spxentry{get\_kriging\_weights()}\spxextra{glomar\_gridding.kriging.SimpleKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.SimpleKriging.get_kriging_weights}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{get\_kriging\_weights}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the Kriging weights from the flattened grid indices where
there is an observation. Optionally add an error covariance to the
covariance between observation grid points.

\sphinxAtStartPar
The Kriging weights are calculated as:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross}\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, and \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points).

\sphinxAtStartPar
Sets the \sphinxtitleref{kriging\_weights} attribute.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_uncertainty() (glomar\_gridding.kriging.SimpleKriging method)@\spxentry{get\_uncertainty()}\spxextra{glomar\_gridding.kriging.SimpleKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.SimpleKriging.get_uncertainty}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{get\_uncertainty}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the kriging uncertainty. This requires the attribute
\sphinxtitleref{kriging\_weights} to be computed.
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{uncert} \textendash{} The Kriging uncertainty.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{kriging\_weights\_from\_inverse() (glomar\_gridding.kriging.SimpleKriging method)@\spxentry{kriging\_weights\_from\_inverse()}\spxextra{glomar\_gridding.kriging.SimpleKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.SimpleKriging.kriging_weights_from_inverse}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{kriging\_weights\_from\_inverse}}}
{\sphinxparam{\DUrole{n}{inv}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the Kriging weights from the flattened grid indices where
there is an observation, using a pre\sphinxhyphen{}computed inverse of the covariance
between grid\sphinxhyphen{}points with observations.

\sphinxAtStartPar
The Kriging weights are calculated as:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross}\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, and \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points).

\sphinxAtStartPar
Sets the \sphinxtitleref{kriging\_weights} attribute.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{inv}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The pre\sphinxhyphen{}computed inverse of the covariance between grid\sphinxhyphen{}points with
observations. \((C_{obs} + E)^{-1}\)

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{solve() (glomar\_gridding.kriging.SimpleKriging method)@\spxentry{solve()}\spxextra{glomar\_gridding.kriging.SimpleKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.SimpleKriging.solve}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{solve}}}
{\sphinxparam{\DUrole{n}{mean}\DUrole{o}{=}\DUrole{default_value}{0.0}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Solves the simple Kriging problem. Computes the Kriging weights if the
\sphinxtitleref{kriging\_weights} attribute is not already set. The solution to Kriging
is:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross} \times y\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points), and \(y\) are the observation values.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mean}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Constant, known, mean value of the system. Defaults to 0.0.

\sphinxlineitem{Returns}
\sphinxAtStartPar
The solution to the simple Kriging problem (as a Vector, this may
need to be re\sphinxhyphen{}shaped appropriately as a post\sphinxhyphen{}processing step).

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{SK} \PYG{o}{=} \PYG{n}{SimpleKriging}\PYG{p}{(}\PYG{n}{interp\PYGZus{}covariance}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{SK}\PYG{o}{.}\PYG{n}{solve}\PYG{p}{(}\PYG{n}{obs}\PYG{p}{,} \PYG{n}{idx}\PYG{p}{,} \PYG{n}{error\PYGZus{}covariance}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}

\index{kriging\_simple() (in module glomar\_gridding.kriging)@\spxentry{kriging\_simple()}\spxextra{in module glomar\_gridding.kriging}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.kriging_simple}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.kriging.}}\sphinxbfcode{\sphinxupquote{kriging\_simple}}}
{\sphinxparam{\DUrole{n}{obs\_obs\_cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs\_grid\_cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid\_obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{interp\_cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mean}\DUrole{o}{=}\DUrole{default_value}{0.0}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Perform Simple Kriging assuming a constant known mean.

\sphinxAtStartPar
This function is deprecated in favour of SimpleKriging class. It will be
removed in version 1.0.0.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_obs\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Covariance between all measured grid points plus the
covariance due to measurements (i.e. measurement noise, bias noise, and
sampling noise). Can include error covariance terms.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_grid\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Covariance between the all (predicted) grid points and measured points.
Does not contain error covarance.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Gridded measurements (all measurement points averaged onto the output
gridboxes).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{interp\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} interpolation covariance of all output grid points (each point in time
and all points against each other).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mean}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The constant mean of the output field.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{ndarray}}, \sphinxcode{\sphinxupquote{ndarray}}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{z\_obs} (\sphinxstyleemphasis{np.ndarray{[}float{]}}) \textendash{} Full set of values for the whole domain derived from the observation
points using simple kriging.

\item {}
\sphinxAtStartPar
\sphinxstylestrong{dz} (\sphinxstyleemphasis{np.ndarray{[}float{]}}) \textendash{} Uncertainty associated with the simple kriging.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}



\section{Ordinary Kriging}
\label{\detokenize{kriging:ordinary-kriging}}\index{OrdinaryKriging (class in glomar\_gridding.kriging)@\spxentry{OrdinaryKriging}\spxextra{class in glomar\_gridding.kriging}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.OrdinaryKriging}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.kriging.}}\sphinxbfcode{\sphinxupquote{OrdinaryKriging}}}
{\sphinxparam{\DUrole{n}{covariance}}\sphinxparamcomma \sphinxparam{\DUrole{n}{idx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{error\_cov}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Class for OrdinaryKriging.

\sphinxAtStartPar
The equation for ordinary Kriging is:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross} \times y\end{split}
\end{equation*}
\sphinxAtStartPar
with a constant but unknown mean.

\sphinxAtStartPar
In this case, the \(C_{obs}\), \(C_{cross}\) and \(y\) values
are extended with a Lagrange multiplier term, ensuring that the Kriging
weights are constrained to sum to 1.

\sphinxAtStartPar
The matrix \(C_{obs}\) is extended by one row and one column, each
containing the value 1, except at the diagonal point, which is 0. The
\(C_{cross}\) matrix is extended by an extra row containing values of 1.
Finally, the grid observations \(y\) is extended by a single value of 0
at the end of the vector.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{covariance}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The spatial covariance matrix. This can be a pre\sphinxhyphen{}computed matrix loaded
into the environment, or computed from a Variogram class or using
Ellipse methods.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The 1d indices of observation grid points. These values should be
between 0 and (N * M) \sphinxhyphen{} 1 where N, M are the number of longitudes
and latitudes respectively. Note that these values should also be
computed using “C” ordering in numpy reshaping. They can be
computed from a grid using glomar\_gridding.grid.map\_to\_grid. Each
value should only appear once. Points that contain more than 1
observation should be averaged. Used to compute the Kriging weights.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The observation values. If there are multiple observations in any
grid box then these values need to be averaged into one value per
grid box.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{error\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Optionally add error covariance values to the covariance between
observation grid points.

\end{itemize}

\end{description}\end{quote}
\index{constraint\_mask() (glomar\_gridding.kriging.OrdinaryKriging method)@\spxentry{constraint\_mask()}\spxextra{glomar\_gridding.kriging.OrdinaryKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.OrdinaryKriging.constraint_mask}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{constraint\_mask}}}
{\sphinxparam{\DUrole{n}{simple\_kriging\_weights}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the observational constraint mask (A14 in \sphinxcite{index:morice-2021}) to
determine if a grid point should be masked/weights modified by how far
it is to its near observed point

\sphinxAtStartPar
Note: typo in Section A4 in \sphinxcite{index:morice-2021} (confirmed by authors).

\sphinxAtStartPar
Equation to use is A14 is incorrect. Easily noticeable because
dimensionally incorrect is wrong, but the correct answer is easy to
figure out.

\sphinxAtStartPar
Correct Equation (extra matrix inverse for \(C_{obs} + E\)):
\begin{equation*}
\begin{split}\frac{
    1 - diag(C - C_{cross}^T \times (C_{obs} + E)^{-1}
             \times C_{cross})
}{diag(C)} < \alpha\end{split}
\end{equation*}
\sphinxAtStartPar
This can be re\sphinxhyphen{}written as:
\begin{equation*}
\begin{split}\frac{
    diag(C_{cross}^T \times (C_{obs} + E)^{-1} \times C_{cross})
}{diag(C)} < \alpha\end{split}
\end{equation*}
\sphinxAtStartPar
\(\alpha\) is chosen to be 0.25 in the UKMO paper

\sphinxAtStartPar
Written by S. Chan, modified by J. Siddons.

\sphinxAtStartPar
This requires the Kriging weights from simple Kriging. If these are
not provided as an input, then they are calculated.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{simple\_kriging\_weights}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}) \textendash{} The Kriging weights for the equivalent simple Kriging system.
error covariance.

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{constraint\_mask} \textendash{} Constraint mask values, the left\sphinxhyphen{}hand\sphinxhyphen{}side of equation A14 from
Morice et al. (2021). This is a vector of length \sphinxtitleref{k\_obs.size{[}0{]}}.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{References}

\sphinxAtStartPar
\sphinxcite{index:morice-2021}: \sphinxurl{https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019JD032361}

\end{fulllineitems}

\index{extended\_inverse() (glomar\_gridding.kriging.OrdinaryKriging method)@\spxentry{extended\_inverse()}\spxextra{glomar\_gridding.kriging.OrdinaryKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.OrdinaryKriging.extended_inverse}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{extended\_inverse}}}
{\sphinxparam{\DUrole{n}{simple\_inv}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the inverse of a covariance matrix \(S = C_{obs} + E\), and
use that to compute the inverse of the extended version of the
covariance matrix with Lagrange multipliers, used by Ordinary Kriging.

\sphinxAtStartPar
This is useful when one needs to perform BOTH simple and ordinary
Kriging, or when one wishes to compute the constraint mask for
ordinary Kriging which requires the Kriging weights for the equivalent
simple Kriging problem.

\sphinxAtStartPar
The extended form of S is given by:
\begin{equation*}
\begin{split}\begin{pmatrix}
&   & & 1 \\
& S & & \vdots \\
&   & & 1 \\
1 & \dots & 1 & 0 \\
\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
This approach follows Guttman 1946 10.1214/aoms/1177730946
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{simple\_inv}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.matrix}}) \textendash{} Inverse of the covariance between observation grid\sphinxhyphen{}points

\sphinxlineitem{Returns}
\sphinxAtStartPar
Inverse of the extended covariance matrix between observation
grid\sphinxhyphen{}points including the Lagrange multiplier factors.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.matrix

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_kriging\_weights() (glomar\_gridding.kriging.OrdinaryKriging method)@\spxentry{get\_kriging\_weights()}\spxextra{glomar\_gridding.kriging.OrdinaryKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.OrdinaryKriging.get_kriging_weights}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{get\_kriging\_weights}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the Kriging weights from the flattened grid indices where
there is an observation. Optionally add an error covariance to the
covariance between observation grid points.

\sphinxAtStartPar
The Kriging weights are calculated as:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross}\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, and \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points).

\sphinxAtStartPar
In this case, the \(C_{obs}\), \(C_{cross}\) and are extended
with a Lagrange multiplier term, ensuring that the Kriging weights are
constrained to sum to 1.

\sphinxAtStartPar
The matrix \(C_{obs}\) is extended by one row and one column, each
containing the value 1, except at the diagonal point, which is 0. The
\(C_{cross}\) matrix is extended by an extra row containing values
of 1.

\sphinxAtStartPar
Sets the \sphinxtitleref{kriging\_weights} attribute.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_uncertainty() (glomar\_gridding.kriging.OrdinaryKriging method)@\spxentry{get\_uncertainty()}\spxextra{glomar\_gridding.kriging.OrdinaryKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.OrdinaryKriging.get_uncertainty}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{get\_uncertainty}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the kriging uncertainty. This requires the attribute
\sphinxtitleref{kriging\_weights} to be computed.
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{uncert} \textendash{} The Kriging uncertainty.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{kriging\_weights\_from\_inverse() (glomar\_gridding.kriging.OrdinaryKriging method)@\spxentry{kriging\_weights\_from\_inverse()}\spxextra{glomar\_gridding.kriging.OrdinaryKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.OrdinaryKriging.kriging_weights_from_inverse}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{kriging\_weights\_from\_inverse}}}
{\sphinxparam{\DUrole{n}{inv}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the Kriging weights from the flattened grid indices where
there is an observation, using a pre\sphinxhyphen{}computed inverse of the covariance
between grid\sphinxhyphen{}points with observations.

\sphinxAtStartPar
The Kriging weights are calculated as:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross}\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, and \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points).

\sphinxAtStartPar
In this case, the inverse matrix must be computed from the covariance
between observation grid\sphinxhyphen{}points with the Lagrange multiplier applied.

\sphinxAtStartPar
This method is appropriate if one wants to compute the constraint mask
which requires simple Kriging weights, which can be computed from the
unextended covariance inverse. The extended inverse can then be
calculated from that inverse.

\sphinxAtStartPar
Sets the \sphinxtitleref{kriging\_weights} attribute.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{inv}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The pre\sphinxhyphen{}computed inverse of the covariance between grid\sphinxhyphen{}points with
observations. \((C_{obs} + E)^{-1}\)

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{solve() (glomar\_gridding.kriging.OrdinaryKriging method)@\spxentry{solve()}\spxextra{glomar\_gridding.kriging.OrdinaryKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.OrdinaryKriging.solve}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{solve}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Solves the ordinary Kriging problem. Computes the Kriging weights if the
\sphinxtitleref{kriging\_weights} attribute is not already set. The solution to Kriging
is:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross} \times y\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points), and \(y\) are the observation values.

\sphinxAtStartPar
In this case, the \(C_{obs}\), \(C_{cross}\) and are extended
with a Lagrange multiplier term, ensuring that the Kriging weights are
constrained to sum to 1.

\sphinxAtStartPar
The matrix \(C_{obs}\) is extended by one row and one column, each
containing the value 1, except at the diagonal point, which is 0. The
\(C_{cross}\) matrix is extended by an extra row containing values
of 1.
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
The solution to the ordinary Kriging problem (as a Vector, this may
need to be re\sphinxhyphen{}shaped appropriately as a post\sphinxhyphen{}processing step).

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{OK} \PYG{o}{=} \PYG{n}{OrdinaryKriging}\PYG{p}{(}\PYG{n}{interp\PYGZus{}covariance}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{OK}\PYG{o}{.}\PYG{n}{solve}\PYG{p}{(}\PYG{n}{obs}\PYG{p}{,} \PYG{n}{idx}\PYG{p}{,} \PYG{n}{error\PYGZus{}covariance}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}

\index{kriging\_ordinary() (in module glomar\_gridding.kriging)@\spxentry{kriging\_ordinary()}\spxextra{in module glomar\_gridding.kriging}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.kriging.kriging_ordinary}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.kriging.}}\sphinxbfcode{\sphinxupquote{kriging\_ordinary}}}
{\sphinxparam{\DUrole{n}{obs\_obs\_cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs\_grid\_cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid\_obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{interp\_cov}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Perform Ordinary Kriging with unknown but constant mean.

\sphinxAtStartPar
This function is deprecated in favour of OrdinaryKriging class. It will be
removed in version 1.0.0.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_obs\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Covariance between all measured grid points plus the covariance due to
measurements (i.e. measurement noise, bias noise, and sampling noise).
Can include error covariance terms, if these are being used.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_grid\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Covariance between the all (predicted) grid points and measured points.
Does not contain error covarance.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Gridded measurements (all measurement points averaged onto the output
gridboxes).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{interp\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Interpolation covariance of all output grid points (each point in time
and all points against each other).

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{ndarray}}, \sphinxcode{\sphinxupquote{ndarray}}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{z\_obs} (\sphinxstyleemphasis{np.ndarray{[}float{]}}) \textendash{} Full set of values for the whole domain derived from the observation
points using ordinary kriging.

\item {}
\sphinxAtStartPar
\sphinxstylestrong{dz} (\sphinxstyleemphasis{np.ndarray{[}float{]}}) \textendash{} Uncertainty associated with the ordinary kriging.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}



\section{Perturbed Gridded Fields}
\label{\detokenize{kriging:perturbed-gridded-fields}}
\sphinxAtStartPar
An additional two\sphinxhyphen{}stage combined Kriging class is provided in the \sphinxtitleref{stochastic} module. In this case,
the \sphinxtitleref{solve} method has an additional optional \sphinxtitleref{simulated\_state} argument, if this is set, then the
value is used as the simulated system state used as the base of the perturbed field (from which
observations are simulated), otherwise the value is computed. This allows for pre\sphinxhyphen{}computation of a
sequence of simulated states as part of ensemble processing, for example.
\index{StochasticKriging (class in glomar\_gridding.stochastic)@\spxentry{StochasticKriging}\spxextra{class in glomar\_gridding.stochastic}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.stochastic.StochasticKriging}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.stochastic.}}\sphinxbfcode{\sphinxupquote{StochasticKriging}}}
{\sphinxparam{\DUrole{n}{covariance}}\sphinxparamcomma \sphinxparam{\DUrole{n}{idx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{error\_cov}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Class for the combined two\sphinxhyphen{}stage Kriging approach following \sphinxcite{index:morice-2021}
The first stage is to produce a gridded field from the observations using
Ordinary Kriging. The second stage is to apply a perturbation.

\sphinxAtStartPar
The perturbation is constructed by first generating a simulated state from
the covariance matrix. A set of simulated observations is drawn from the
error covariance matrix. A simulated gridded field is then computed using
Simple Kriging with the simulated observations as input. Finally, the
perturbation is then the difference between the simulated gridded field and
the simulated state. This perturbation is added to the gridded field from
the first stage.

\sphinxAtStartPar
The equation for ordinary Kriging is:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross} \times y\end{split}
\end{equation*}
\sphinxAtStartPar
with a constant but unknown mean.

\sphinxAtStartPar
In this case, the \(C_{obs}\), \(C_{cross}\) and \(y\) values
are extended with a Lagrange multiplier term for the first stage, ensuring
that the Kriging weights are constrained to sum to 1.

\sphinxAtStartPar
Additionally, the matrix \(C_{obs}\) is extended by one row and one
column, each containing the value 1, except at the diagonal point, which is
0 for the first Ordinary Kriging stage. The \(C_{cross}\) matrix is
extended by an extra row containing values of 1. Finally, the grid
observations \(y\) is extended by a single value of 0 at the end of the
vector.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{covariance}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The spatial covariance matrix. This can be a pre\sphinxhyphen{}computed matrix loaded
into the environment, or computed from a Variogram class or using
Ellipse methods.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The 1d indices of observation grid points. These values should be
between 0 and (N * M) \sphinxhyphen{} 1 where N, M are the number of longitudes
and latitudes respectively. Note that these values should also be
computed using “C” ordering in numpy reshaping. They can be
computed from a grid using glomar\_gridding.grid.map\_to\_grid. Each
value should only appear once. Points that contain more than 1
observation should be averaged. Used to compute the Kriging weights.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The observation values. If there are multiple observations in any
grid box then these values need to be averaged into one value per
grid box.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{error\_cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Error covariance values to the covariance between observation grid
points.

\end{itemize}

\end{description}\end{quote}
\index{constraint\_mask() (glomar\_gridding.stochastic.StochasticKriging method)@\spxentry{constraint\_mask()}\spxextra{glomar\_gridding.stochastic.StochasticKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.stochastic.StochasticKriging.constraint_mask}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{constraint\_mask}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the observational constraint mask (A14 in \sphinxcite{index:morice-2021}) to
determine if a grid point should be masked/weights modified by how far
it is to its near observed point

\sphinxAtStartPar
Note: typo in Section A4 in \sphinxcite{index:morice-2021} (confired by authors).

\sphinxAtStartPar
Equation to use is A14 is incorrect. Easily noticeable because
dimensionally incorrect is wrong, but the correct answer is easy to
figure out.

\sphinxAtStartPar
Correct Equation (extra matrix inverse for \(C_{obs} + E\)):
\begin{equation*}
\begin{split}\frac{
    1 - diag(C - C_{cross}^T \times (C_{obs} + E)^{-1}
             \times C_{cross})
}{diag(C)} < \alpha\end{split}
\end{equation*}
\sphinxAtStartPar
This can be re\sphinxhyphen{}written as:
\begin{equation*}
\begin{split}\frac{diag(C_{cross}^T \times (C_{obs} + E)^{-1} \times C_{cross})}
{diag(C)} < \alpha\end{split}
\end{equation*}
\sphinxAtStartPar
\(\alpha\) is chosen to be 0.25 in the UKMO paper

\sphinxAtStartPar
Written by S. Chan, modified by J. Siddons.

\sphinxAtStartPar
This requires the Kriging weights from simple Kriging, set as the
\sphinxtitleref{simple\_kriging\_weights} attribute.
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{constraint\_mask} \textendash{} Constraint mask values, the left\sphinxhyphen{}hand\sphinxhyphen{}side of equation A14 from
\sphinxcite{index:morice-2021}. This is a vector of length \sphinxtitleref{k\_obs.size{[}0{]}}.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{References}

\sphinxAtStartPar
\sphinxcite{index:morice-2021}: \sphinxurl{https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019JD032361}

\end{fulllineitems}

\index{get\_kriging\_weights() (glomar\_gridding.stochastic.StochasticKriging method)@\spxentry{get\_kriging\_weights()}\spxextra{glomar\_gridding.stochastic.StochasticKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.stochastic.StochasticKriging.get_kriging_weights}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{get\_kriging\_weights}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the Kriging weights from the flattened grid indices where
there is an observation. Optionally add an error covariance to the
covariance between observation grid points.

\sphinxAtStartPar
The Kriging weights are calculated as:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross}\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, and \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points).

\sphinxAtStartPar
In this case, the \(C_{obs}\), \(C_{cross}\) and are extended
with a Lagrange multiplier term, ensuring that the Kriging weights are
constrained to sum to 1, for the first stage of the StochasticKriging
process.

\sphinxAtStartPar
The matrix \(C_{obs}\) is extended by one row and one column, each
containing the value 1, except at the diagonal point, which is 0. The
\(C_{cross}\) matrix is extended by an extra row containing values
of 1.

\sphinxAtStartPar
Sets the \sphinxtitleref{kriging\_weights} and \sphinxtitleref{simple\_kriging\_weights} attributes.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_uncertainty() (glomar\_gridding.stochastic.StochasticKriging method)@\spxentry{get\_uncertainty()}\spxextra{glomar\_gridding.stochastic.StochasticKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.stochastic.StochasticKriging.get_uncertainty}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{get\_uncertainty}}}
{}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the kriging uncertainty. This requires the attribute
\sphinxtitleref{kriging\_weights} to be computed.
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{uncert} \textendash{} The Kriging uncertainty.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{kriging\_weights\_from\_inverse() (glomar\_gridding.stochastic.StochasticKriging method)@\spxentry{kriging\_weights\_from\_inverse()}\spxextra{glomar\_gridding.stochastic.StochasticKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.stochastic.StochasticKriging.kriging_weights_from_inverse}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{kriging\_weights\_from\_inverse}}}
{\sphinxparam{\DUrole{n}{inv}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the Kriging weights from the flattened grid indices where
there is an observation, using a pre\sphinxhyphen{}computed inverse of the covariance
between grid\sphinxhyphen{}points with observations.

\sphinxAtStartPar
The Kriging weights are calculated as:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross}\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, and \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points).

\sphinxAtStartPar
This method is appropriate if one wants to compute the constraint mask
which requires simple Kriging weights, which can be computed from the
unextended covariance inverse. The extended inverse can then be
calculated from that inverse.

\sphinxAtStartPar
The inverse matrix is used to compute the inverse of the extended
covariance matrix used for the first Ordinary Kriging stage.

\sphinxAtStartPar
Sets the \sphinxtitleref{kriging\_weights} and \sphinxtitleref{simple\_kriging\_weights} attributes.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{inv}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The pre\sphinxhyphen{}computed inverse of the covariance between grid\sphinxhyphen{}points with
observations. \((C_{obs} + E)^{-1}\)

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_simple\_kriging\_weights() (glomar\_gridding.stochastic.StochasticKriging method)@\spxentry{set\_simple\_kriging\_weights()}\spxextra{glomar\_gridding.stochastic.StochasticKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.stochastic.StochasticKriging.set_simple_kriging_weights}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{set\_simple\_kriging\_weights}}}
{\sphinxparam{\DUrole{n}{simple\_kriging\_weights}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Set Simple Kriging Weights. For use in the second Simple Kriging stage
for computing the simulated gridded field.

\sphinxAtStartPar
Sets the \sphinxtitleref{simple\_kriging\_weights} attribute.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{simple\_kriging\_weights}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The pre\sphinxhyphen{}computed simple\_kriging\_weights to use.

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{solve() (glomar\_gridding.stochastic.StochasticKriging method)@\spxentry{solve()}\spxextra{glomar\_gridding.stochastic.StochasticKriging method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.stochastic.StochasticKriging.solve}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{solve}}}
{\sphinxparam{\DUrole{n}{simulated\_state}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Solves the combined Stochastic Kriging problem. Computes the Kriging
weights if the \sphinxtitleref{kriging\_weights} attribute is not already set.

\sphinxAtStartPar
Stochastic Kriging is a combined Ordinary and Simple Kriging approach.
First a gridded field is generated for the observations using Ordinary
Kriging. Secondly, a simulated gridded field is generated using Simple
Kriging from a simulated state and simulated observations. The simulated
state can be pre\sphinxhyphen{}computed or computed by this method. The simulated
observations are drawn from the error covariance and located at the
simulated state. The difference between the simulated gridded field and
the simulated state is added to the gridded field.

\sphinxAtStartPar
The solution to Kriging is:
\begin{equation*}
\begin{split}(C_{obs} + E)^{-1} \times C_{cross} \times y\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(C_{obs}\) is the spatial covariance between grid\sphinxhyphen{}points
with observations, \(E\) is the error covariance between grid\sphinxhyphen{}points
with observations, \(C_{cross}\) is the covariance between
grid\sphinxhyphen{}points with observations and all grid\sphinxhyphen{}points (including observation
grid\sphinxhyphen{}points), and \(y\) are the observation values.

\sphinxAtStartPar
In this case, the \(C_{obs}\), \(C_{cross}\) and are extended
with a Lagrange multiplier term, ensuring that the Kriging weights are
constrained to sum to 1. For the Ordinary Kriging component.

\sphinxAtStartPar
The matrix \(C_{obs}\) is extended by one row and one column, each
containing the value 1, except at the diagonal point, which is 0. The
\(C_{cross}\) matrix is extended by an extra row containing values
of 1. For the Ordinary Kriging component.

\sphinxAtStartPar
This additionally sets the following attributes:
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxtitleref{gridded\_field} \sphinxhyphen{} The unperturbed gridded field

\item {}
\sphinxAtStartPar
\sphinxtitleref{simulated\_grid} \sphinxhyphen{} The simulated gridded field

\item {}
\sphinxAtStartPar
\sphinxtitleref{epsilon} \sphinxhyphen{} The perturbation

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{simulated\_state}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Flattened simulated state, used as the location basis for the
simulated observation draw. If this is not provided it will be
calculated. Often it is better to pre\sphinxhyphen{}compute a series of states in
advance, since this can be a time consuming step (drawing a single
state takes approximately the same time as drawing 200).

\sphinxlineitem{Returns}
\sphinxAtStartPar
The solution to the stochastic Kriging problem (as a Vector, this
may need to be re\sphinxhyphen{}shaped appropriately as a post\sphinxhyphen{}processing step).

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{SK} \PYG{o}{=} \PYG{n}{StochasticKriging}\PYG{p}{(}\PYG{n}{interp\PYGZus{}covariance}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{SK}\PYG{o}{.}\PYG{n}{solve}\PYG{p}{(}\PYG{n}{obs}\PYG{p}{,} \PYG{n}{idx}\PYG{p}{,} \PYG{n}{error\PYGZus{}covariance}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}


\end{fulllineitems}

\index{scipy\_mv\_normal\_draw() (in module glomar\_gridding.stochastic)@\spxentry{scipy\_mv\_normal\_draw()}\spxextra{in module glomar\_gridding.stochastic}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.stochastic.scipy_mv_normal_draw}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.stochastic.}}\sphinxbfcode{\sphinxupquote{scipy\_mv\_normal\_draw}}}
{\sphinxparam{\DUrole{n}{loc}}\sphinxparamcomma \sphinxparam{\DUrole{n}{cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{ndraws}\DUrole{o}{=}\DUrole{default_value}{1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{eigen\_rtol}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}06}}\sphinxparamcomma \sphinxparam{\DUrole{n}{eigen\_fudge}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}08}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Do a random multivariate normal draw using
scipy.stats.multivariate\_normal.rvs

\sphinxAtStartPar
numpy.random.multivariate\_normal can also,
but fixing seeds are more difficult using numpy

\sphinxAtStartPar
This function has similar API as GP\_draw with less kwargs.

\sphinxAtStartPar
Warning/possible future scipy version may change this:
It seems if one uses stats.Covariance, you have to have add {[}0{]} from rvs
function. The above behavior applies to scipy v1.14.0
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{loc}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the location for the normal dry

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} not a xarray/iris cube! Some of our covariances are saved in numpy
format and not netCDF files

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{n\_draws}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} number of simulations, this is usually set to 1 except during

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{testing}} (\sphinxstyleliteralemphasis{\sphinxupquote{unit}})

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{eigen\_rtol}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} relative tolerance to negative eigenvalues

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{eigen\_fudge}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} forced minimum value of eigenvalues if negative values are detected

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{draw} \textendash{} The draw(s) from the multivariate random normal distribution defined
by the loc and cov parameters. If the cov parameter is not
positive\sphinxhyphen{}definite then a new covariance will be determined by adjusting
the eigen decomposition such that the modified covariance should be
positive\sphinxhyphen{}definite.

\sphinxlineitem{Return type}
\sphinxAtStartPar
np.ndarray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{A} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{rand}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cov} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{dot}\PYG{p}{(}\PYG{n}{A}\PYG{p}{,} \PYG{n}{A}\PYG{o}{.}\PYG{n}{T}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{scipy\PYGZus{}mv\PYGZus{}normal\PYGZus{}draw}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{cov}\PYG{p}{,} \PYG{n}{ndraws}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{g+go}{array([[\PYGZhy{}0.35972806, \PYGZhy{}0.51289612,  0.85307028, \PYGZhy{}0.11580307,  0.6677707 ],}
\PYG{g+go}{       [\PYGZhy{}1.38214628, \PYGZhy{}1.29331638, \PYGZhy{}0.4879436 , \PYGZhy{}1.42310831, \PYGZhy{}0.19369562],}
\PYG{g+go}{       [\PYGZhy{}1.04502143, \PYGZhy{}1.97686163, \PYGZhy{}2.058605  , \PYGZhy{}1.97202206, \PYGZhy{}2.90116796],}
\PYG{g+go}{       [\PYGZhy{}1.97981119, \PYGZhy{}2.72330373,  0.0088662 , \PYGZhy{}2.53521893, \PYGZhy{}0.03670664],}
\PYG{g+go}{       [ 0.49948228,  0.54695988,  0.33864294,  0.53730282,  0.14743019]])}
\end{sphinxVerbatim}

\end{fulllineitems}



\section{Outputs}
\label{\detokenize{kriging:outputs}}
\sphinxAtStartPar
The outputs to the solvers, \sphinxcode{\sphinxupquote{glomar\_gridding.SimpleKriging.solve()}} for example will be
vectors, they should be re\sphinxhyphen{}shaped to the grid.

\sphinxAtStartPar
Outputs can also be re\sphinxhyphen{}mapped to the grid
\index{assign\_to\_grid() (in module glomar\_gridding.grid)@\spxentry{assign\_to\_grid()}\spxextra{in module glomar\_gridding.grid}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{kriging:glomar_gridding.grid.assign_to_grid}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.grid.}}\sphinxbfcode{\sphinxupquote{assign\_to\_grid}}}
{\sphinxparam{\DUrole{n}{values}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid\_idx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid}}\sphinxparamcomma \sphinxparam{\DUrole{n}{fill\_value}\DUrole{o}{=}\DUrole{default_value}{nan}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Assign a vector of values to a grid, using a list of grid index values.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{values}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.Series}}) \textendash{} The values to map onto the output grid.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.Series}}) \textendash{} The 1d index of the grid (assuming “C” style ravelling) for each value.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} The grid used to define the output grid.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fill\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} The value to fill unassigned grid boxes.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{out\_grid} \textendash{} A new grid containing the values mapped onto the grid.

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.DataArray

\end{description}\end{quote}

\end{fulllineitems}


\sphinxstepscope


\chapter{Miscallaneous Modules}
\label{\detokenize{misc:miscallaneous-modules}}\label{\detokenize{misc::doc}}

\section{Climatologies}
\label{\detokenize{misc:module-glomar_gridding.climatology}}\label{\detokenize{misc:climatologies}}\index{module@\spxentry{module}!glomar\_gridding.climatology@\spxentry{glomar\_gridding.climatology}}\index{glomar\_gridding.climatology@\spxentry{glomar\_gridding.climatology}!module@\spxentry{module}}
\sphinxAtStartPar
Functions for mapping climatologies and computing anomalies
\index{join\_climatology\_by\_doy() (in module glomar\_gridding.climatology)@\spxentry{join\_climatology\_by\_doy()}\spxextra{in module glomar\_gridding.climatology}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.climatology.join_climatology_by_doy}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.climatology.}}\sphinxbfcode{\sphinxupquote{join\_climatology\_by\_doy}}}
{\sphinxparam{\DUrole{n}{obs\_df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{climatology\_365}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lat\_col}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}lat\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lon\_col}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}lon\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{date\_col}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}date\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{var\_col}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}sst\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{clim\_lat}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}latitude\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{clim\_lon}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}longitude\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{clim\_doy}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}doy\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{clim\_var}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}climatology\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{temp\_from\_kelvin}\DUrole{o}{=}\DUrole{default_value}{True}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Merge a climatology from an xarray.DataArray into a polars.DataFrame using
the \sphinxstylestrong{day of year} value and position.

\sphinxAtStartPar
This function accounts for leap years by taking the average of the
climatology values for 28th Feb and 1st March for observations that were
made on the 29th of Feb.

\sphinxAtStartPar
The climatology is merged into the DataFrame and anomaly values are
computed.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} Observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{climatology\_365}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} DataArray containing daily climatology values (for 365 days).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lat\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the latitude column in the observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lon\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the longitude column in the observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{date\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the datetime column in the observational DataFrame. Day of year
values are computed from this value.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{var\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the variable column in the observational DataFrame. The merged
climatology names will have this name prefixed to “\_climatology”, the
anomaly values will have this name prefixed to “\_anomaly”.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{clim\_lat}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the latitude coordinate in the climatology DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{clim\_lon}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the longitude coordinate in the climatology DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{clim\_doy}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the day of year coordinate in the climatology DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{clim\_var}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the climatology variable in the climatology DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp\_from\_kelvin}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Optionally adjust the climatology from Kelvin to Celsius if the variable
is a temperature.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{obs\_df} \textendash{} With the climatology merged and anomaly computed. The new columns are
“\_climatology” and “\_anomaly” prefixed by the \sphinxtitleref{var\_col} value
respectively.

\sphinxlineitem{Return type}
\sphinxAtStartPar
polars.DataFrame

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_climatology() (in module glomar\_gridding.climatology)@\spxentry{read\_climatology()}\spxextra{in module glomar\_gridding.climatology}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.climatology.read_climatology}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.climatology.}}\sphinxbfcode{\sphinxupquote{read\_climatology}}}
{\sphinxparam{\DUrole{n}{clim\_path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{min\_lat}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{}90}}\sphinxparamcomma \sphinxparam{\DUrole{n}{max\_lat}\DUrole{o}{=}\DUrole{default_value}{90}}\sphinxparamcomma \sphinxparam{\DUrole{n}{min\_lon}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{}180}}\sphinxparamcomma \sphinxparam{\DUrole{n}{max\_lon}\DUrole{o}{=}\DUrole{default_value}{180}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lat\_var}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}lat\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lon\_var}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}lon\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Load a climatology dataset from a netCDF file.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{clim\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Path to the climatology file. Can contain format blocks to be replaced
by the values passed to kwargs.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_lat}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Minimum latitude to load.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{max\_lat}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Maximum latitude to load.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_lon}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Minimum longitude to load.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{max\_lon}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Maximum longitude to load.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lat\_var}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the latitude variable.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lon\_var}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the longitude variable.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**kwargs}} \textendash{} Replacement values for the climatology path.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{clim\_ds} \textendash{} Containing the climatology bounded by the min/max arguments provided.

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.Dataset

\end{description}\end{quote}

\end{fulllineitems}



\section{Masking}
\label{\detokenize{misc:module-glomar_gridding.mask}}\label{\detokenize{misc:masking}}\index{module@\spxentry{module}!glomar\_gridding.mask@\spxentry{glomar\_gridding.mask}}\index{glomar\_gridding.mask@\spxentry{glomar\_gridding.mask}!module@\spxentry{module}}
\sphinxAtStartPar
Functions for applying masks to grids and DataFrames
\index{get\_mask\_idx() (in module glomar\_gridding.mask)@\spxentry{get\_mask\_idx()}\spxextra{in module glomar\_gridding.mask}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.mask.get_mask_idx}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.mask.}}\sphinxbfcode{\sphinxupquote{get\_mask\_idx}}}
{\sphinxparam{\DUrole{n}{mask}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask\_val}\DUrole{o}{=}\DUrole{default_value}{nan}}\sphinxparamcomma \sphinxparam{\DUrole{n}{masked}\DUrole{o}{=}\DUrole{default_value}{True}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Get the 1d indices of masked values from a mask array.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} The mask array, containing values indicated a masked value.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} The value that indicates the position should be masked.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{masked}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Return indices where values in the mask array equal this value. If set
to False it will return indices where values are not equal to the mask
value. Can be used to get unmasked indices if this value is set to
False.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
An array of integers indicating the indices which are masked.

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{rand}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data}\PYG{p}{[}\PYG{n}{data} \PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{0.65}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{nan}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{mask} \PYG{o}{=} \PYG{n}{xr}\PYG{o}{.}\PYG{n}{DataArray}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{get\PYGZus{}mask\PYGZus{}idx}\PYG{p}{(}\PYG{n}{mask}\PYG{p}{)}
\PYG{g+go}{array([[1],}
\PYG{g+go}{       [3],}
\PYG{g+go}{       [4],}
\PYG{g+go}{       [5],}
\PYG{g+go}{       [8]])}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{mask\_array() (in module glomar\_gridding.mask)@\spxentry{mask\_array()}\spxextra{in module glomar\_gridding.mask}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.mask.mask_array}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.mask.}}\sphinxbfcode{\sphinxupquote{mask\_array}}}
{\sphinxparam{\DUrole{n}{grid}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask}}\sphinxparamcomma \sphinxparam{\DUrole{n}{masked\_value}\DUrole{o}{=}\DUrole{default_value}{nan}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask\_value}\DUrole{o}{=}\DUrole{default_value}{True}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Apply a mask to a DataArray.

\sphinxAtStartPar
The grid and mask must already align for this function to work. An error
will be raised if the coordinate systems cannot be aligned.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} Observational DataArray to be masked by positions in the mask
DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} Array containing values used to mask the observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{masked\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Value indicating masked values in the DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Value to set masked values to in the observational DataFrame.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{grid} \textendash{} Input xarray.DataArray with the variable masked by the mask DataArray.

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.DataArray

\end{description}\end{quote}

\end{fulllineitems}

\index{mask\_dataset() (in module glomar\_gridding.mask)@\spxentry{mask\_dataset()}\spxextra{in module glomar\_gridding.mask}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.mask.mask_dataset}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.mask.}}\sphinxbfcode{\sphinxupquote{mask\_dataset}}}
{\sphinxparam{\DUrole{n}{dataset}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask}}\sphinxparamcomma \sphinxparam{\DUrole{n}{varnames}}\sphinxparamcomma \sphinxparam{\DUrole{n}{masked\_value}\DUrole{o}{=}\DUrole{default_value}{nan}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask\_value}\DUrole{o}{=}\DUrole{default_value}{True}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Apply a mask to a DataSet.

\sphinxAtStartPar
The grid and mask must already align for this function to work. An error
will be raised if the coordinate systems cannot be aligned.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dataset}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.Dataset}}) \textendash{} Observational Dataset to be masked by positions in the mask
DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} Array containing values used to mask the observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{varnames}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A list containing the names of  variables in the observational Dataser
to apply the mask to.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{masked\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Value indicating masked values in the DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Value to set masked values to in the observational DataFrame.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{grid} \textendash{} Input xarray.Dataset with the variables masked by the mask DataArray.

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.Dataset

\end{description}\end{quote}

\end{fulllineitems}

\index{mask\_from\_obs\_array() (in module glomar\_gridding.mask)@\spxentry{mask\_from\_obs\_array()}\spxextra{in module glomar\_gridding.mask}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.mask.mask_from_obs_array}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.mask.}}\sphinxbfcode{\sphinxupquote{mask\_from\_obs\_array}}}
{\sphinxparam{\DUrole{n}{obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{datetime\_idx}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Infer a mask from an input array. Mask values are those where all values
are NaN along the time dimension.

\sphinxAtStartPar
An example use\sphinxhyphen{}case would be to infer land\sphinxhyphen{}points from a SST data array.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Array containing the observation values. Records that are numpy.nan
will count towards the mask, if all values in the datetime dimension
are numpy.nan.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{datetime\_idx}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The index of the datetime, or grouping, dimension. If all records at
a point along this dimension are NaN then this point will be masked.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{mask} \textendash{} A boolean array with dimension reduced along the datetime dimension.
A True value indicates that all values along the datetime dimension
for this index are numpy.nan and are masked.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray | xarray.DataArray

\end{description}\end{quote}

\end{fulllineitems}

\index{mask\_from\_obs\_frame() (in module glomar\_gridding.mask)@\spxentry{mask\_from\_obs\_frame()}\spxextra{in module glomar\_gridding.mask}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.mask.mask_from_obs_frame}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.mask.}}\sphinxbfcode{\sphinxupquote{mask\_from\_obs\_frame}}}
{\sphinxparam{\DUrole{n}{obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{coords}}\sphinxparamcomma \sphinxparam{\DUrole{n}{value\_col}}\sphinxparamcomma \sphinxparam{\DUrole{n}{datetime\_col}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{grid\_coords}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute a mask from observations and an optional output grid..

\sphinxAtStartPar
Positions defined by the “coords” values that do not have any observations,
at any datetime value in the “datetime\_col”, for the “value\_col” field are
masked.

\sphinxAtStartPar
An example use\sphinxhyphen{}case would be to identify land positions from sst records.

\sphinxAtStartPar
If a grid is supplied, the observations are mapped to the grid and any
positions from the grid that do not contain observations.

\sphinxAtStartPar
If no grid is supplied, then it is assumed that the observation frame
represents the full grid, and any positions without observations are
included with null values in the value\_col.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} DataFrame containing observations over space and time. The values in
the “value\_col” field will be used to define the mask.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{coords}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A list of columns containing the coordinates used to define the mask.
For example {[}“lat”, “lon”{]}.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{value\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the column containing values from which the mask will be
defined.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{datetime\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Name of the datetime column. Any positions that contain no records at
any datetime value are masked.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Optional grid, used to map observations so that empty positions can be
identified. If not supplied, it is assumed that the observations frame
contains the full grid, and includes nulls in empty positions.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_coords}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Optional grid coordinate names. Must be set if grid is set.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{DataFrame}}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleemphasis{polars.DataFrame containing coordinate columns and a Boolean “mask” column}

\item {}
\sphinxAtStartPar
\sphinxstyleemphasis{indicating positions that contain no observations and would be a mask value.}

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{mask\_observations() (in module glomar\_gridding.mask)@\spxentry{mask\_observations()}\spxextra{in module glomar\_gridding.mask}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.mask.mask_observations}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.mask.}}\sphinxbfcode{\sphinxupquote{mask\_observations}}}
{\sphinxparam{\DUrole{n}{obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask}}\sphinxparamcomma \sphinxparam{\DUrole{n}{varnames}}\sphinxparamcomma \sphinxparam{\DUrole{n}{masked\_value}\DUrole{o}{=}\DUrole{default_value}{nan}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask\_value}\DUrole{o}{=}\DUrole{default_value}{True}}\sphinxparamcomma \sphinxparam{\DUrole{n}{obs\_coords}\DUrole{o}{=}\DUrole{default_value}{{[}\textquotesingle{}lat\textquotesingle{}, \textquotesingle{}lon\textquotesingle{}{]}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask\_coords}\DUrole{o}{=}\DUrole{default_value}{{[}\textquotesingle{}latitude\textquotesingle{}, \textquotesingle{}longitude\textquotesingle{}{]}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{align\_to\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{drop}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask\_grid\_prefix}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\_mask\_grid\_\textquotesingle{}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Mask observations in a DataFrame subject to a mask DataArray.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} Observational DataFrame to be masked by positions in the mask
DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}) \textendash{} Array containing values used to mask the observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{varnames}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Columns in the observational DataFrame to apply the mask to.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{masked\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Value indicating masked values in the DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} Value to set masked values to in the observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs\_coords}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A list of coordinate names in the observational DataFrame. Used to map
the mask DataArray to the observational DataFrame. The order must align
with the coordinates of the mask DataArray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_coords}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A list of coordinate names in the mask DataArray. These coordinates are
mapped onto the observational DataFrame in order to apply the mask. The
ordering of the coordinate names in this list must match those in the
obs\_coords list.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{align\_to\_mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Optionally align the observational DataFrame to the mask DataArray.
This essentially sets the mask’s grid as the output grid for
interpolation.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{drop}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Drop masked values in the observational DataFrame.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_grid\_prefix}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Prefix to use for the mask gridbox index column in the observational
DataFrame.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{obs} \textendash{} Input polars.DataFrame containing additional column named by the
mask\_varname argument, indicating records that are masked. Masked values
are dropped if the drop argument is set to True.

\sphinxlineitem{Return type}
\sphinxAtStartPar
polars.DataFrame

\end{description}\end{quote}

\end{fulllineitems}



\section{Distances and Distance Matrices}
\label{\detokenize{misc:module-glomar_gridding.distances}}\label{\detokenize{misc:distances-and-distance-matrices}}\index{module@\spxentry{module}!glomar\_gridding.distances@\spxentry{glomar\_gridding.distances}}\index{glomar\_gridding.distances@\spxentry{glomar\_gridding.distances}!module@\spxentry{module}}
\sphinxAtStartPar
Functions for calculating distances or distance\sphinxhyphen{}based covariance components.

\sphinxAtStartPar
Some functions can be used for computing pairwise\sphinxhyphen{}distances, for example via
squareform. Some functions can be used as a distance function for
glomar\_gridding.error\_covariance.dist\_weights, accounting for the distance
component to an error covariance matrix.

\sphinxAtStartPar
Functions for computing covariance using Matern Tau by Steven Chan (@stchan).
\index{calculate\_distance\_matrix() (in module glomar\_gridding.distances)@\spxentry{calculate\_distance\_matrix()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.calculate_distance_matrix}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{calculate\_distance\_matrix}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{dist\_func=\textless{}function haversine\_distance\_from\_frame\textgreater{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lat\_col=\textquotesingle{}lat\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lon\_col=\textquotesingle{}lon\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{**dist\_kwargs}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Create a distance matrix from a DataFrame containing positional information,
typically latitude and longitude, using a distance function.

\sphinxAtStartPar
Available functions are \sphinxtitleref{haversine\_distance}, \sphinxtitleref{euclidean\_distance}. A
custom function can be used, requiring that the function takes the form:
(tuple{[}float, float{]}, tuple{[}float, float{]}) \sphinxhyphen{}\textgreater{} float
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} DataFrame containing latitude and longitude columns indicating the
positions between which distances are computed to form the distance
matrix

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dist\_func}} (\sphinxstyleliteralemphasis{\sphinxupquote{Callable}}) \textendash{} The function used to calculate the pairwise distances. Functions
available for this function are \sphinxtitleref{haversine\_distance} and
\sphinxtitleref{euclidean\_distance}.
A custom function can be based, that takes as input two tuples of
positions (computing a single distance value between the pair of
positions). (tuple{[}float, float{]}, tuple{[}float, float{]}) \sphinxhyphen{}\textgreater{} float

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lat\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the column in the input DataFrame containing latitude values.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lon\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the column in the input DataFrame containing longitude values.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**dist\_kwargs}} \textendash{} Keyword arguments to pass to the distance function.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{dist} \textendash{} A matrix of pairwise distances.

\sphinxlineitem{Return type}
\sphinxAtStartPar
np.ndarray{[}float{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{displacements() (in module glomar\_gridding.distances)@\spxentry{displacements()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.displacements}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{displacements}}}
{\sphinxparam{\DUrole{n}{lats}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lons}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lats2}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lons2}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{delta\_x\_method}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate east\sphinxhyphen{}west and north\sphinxhyphen{}south displacement matrices for all pairs
of input positions.

\sphinxAtStartPar
The results are not scaled by any radius, this should be performed outside
of this function.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lats}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The latitudes of the positions, should be provided in degrees.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lons}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The longitudes of the positions, should be provided in degrees.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lats2}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The latitudes of the optional second positions, should be provided in
degrees.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lons2}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The longitudes of the optional second positions, should be provided in
degrees.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delta\_x\_method}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} One of “Met\_Office” or “Modified\_Met\_Office”. If set to None, the
displacements will be returned in degrees, rather than actual distance
values. Set to “Met\_Office” to use a cylindrical approximation, set
to “Modified\_Met\_Office” to use an approximation that uses the average
of the latitudes to set the horizontal displacement scale.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{ndarray}}, \sphinxcode{\sphinxupquote{ndarray}}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{disp\_y} (\sphinxstyleemphasis{numpy.ndarray}) \textendash{} The north\sphinxhyphen{}south displacements.

\item {}
\sphinxAtStartPar
\sphinxstylestrong{disp\_x} (\sphinxstyleemphasis{numpy.ndarray}) \textendash{} The east\sphinxhyphen{}west displacements.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{euclidean\_distance() (in module glomar\_gridding.distances)@\spxentry{euclidean\_distance()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.euclidean_distance}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{euclidean\_distance}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{radius}\DUrole{o}{=}\DUrole{default_value}{6371.0}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the Euclidean distance in kilometers between pairs of lat, lon
points on the earth (specified in decimal degrees).
\begin{equation*}
\begin{split}d = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}\end{split}
\end{equation*}
\sphinxAtStartPar
where
\begin{equation*}
\begin{split}(x_n, y_n, z_n) = (R\cos(lat)\cos(lon), R\cos(lat)\sin(lon), R\sin(lat))\end{split}
\end{equation*}\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} DataFrame containing latitude and longitude columns indicating the
positions between which distances are computed to form the distance
matrix

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{radius}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The radius of the sphere used for the calculation. Defaults to the
radius of the earth in km (6371.0 km).

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{dist} \textendash{} The direct pairwise distance between the positions in the input
DataFrame through the sphere defined by the radius parameter.

\sphinxlineitem{Return type}
\sphinxAtStartPar
float

\end{description}\end{quote}
\subsubsection*{References}

\sphinxAtStartPar
\sphinxurl{https://math.stackexchange.com/questions/29157/how-do-i-convert-the-distance-between-two-lat-long-points-into-feet-meters}
\sphinxurl{https://cesar.esa.int/upload/201709/Earth\_Coordinates\_Booklet.pdf}

\end{fulllineitems}

\index{haversine\_distance\_from\_frame() (in module glomar\_gridding.distances)@\spxentry{haversine\_distance\_from\_frame()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.haversine_distance_from_frame}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{haversine\_distance\_from\_frame}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{radius}\DUrole{o}{=}\DUrole{default_value}{6371}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate the great circle distance in kilometers between pairs of lat, lon
points on the earth (specified in decimal degrees).
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} DataFrame containing latitude and longitude columns indicating the
positions between which distances are computed to form the distance
matrix

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{radius}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The radius of the sphere used for the calculation. Defaults to the
radius of the earth in km (6371.0 km).

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{dist} \textendash{} The pairwise haversine distances between the inputs in the DataFrame,
on the sphere defined by the radius parameter.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{haversine\_gaussian() (in module glomar\_gridding.distances)@\spxentry{haversine\_gaussian()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.haversine_gaussian}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{haversine\_gaussian}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{R}\DUrole{o}{=}\DUrole{default_value}{6371.0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{r}\DUrole{o}{=}\DUrole{default_value}{40}}\sphinxparamcomma \sphinxparam{\DUrole{n}{s}\DUrole{o}{=}\DUrole{default_value}{0.6}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Gaussian Haversine Model
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} Observations, required columns are “lat” and “lon” representing
latitude and longitude respectively.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{R}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Radius of the sphere on which Haversine distance is computed. Defaults
to radius of earth in km.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{r}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Gaussian model range parameter

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{s}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Gaussian model scale parameter

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{C} \textendash{} Distance matrix for the input positions. Result has been modified using
the Gaussian model.

\sphinxlineitem{Return type}
\sphinxAtStartPar
np.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{inv\_2d() (in module glomar\_gridding.distances)@\spxentry{inv\_2d()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.inv_2d}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{inv\_2d}}}
{\sphinxparam{\DUrole{n}{mat}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the inverse of a 2 x 2 matrix
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{ndarray}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{mahal\_dist\_func() (in module glomar\_gridding.distances)@\spxentry{mahal\_dist\_func()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.mahal_dist_func}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{mahal\_dist\_func}}}
{\sphinxparam{\DUrole{n}{delta\_x}}\sphinxparamcomma \sphinxparam{\DUrole{n}{delta\_y}}\sphinxparamcomma \sphinxparam{\DUrole{n}{Lx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{Ly}}\sphinxparamcomma \sphinxparam{\DUrole{n}{theta}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate tau from displacements, Lx, Ly, and theta (if it is known). For
an array of displacements, for a set of scalar ellipse parameters, Lx, Ly,
and theta.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delta\_x}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} displacement to remote point as in: (delta\_x) i + (delta\_y) j in old
school vector notation

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delta\_y}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} displacement to remote point as in: (delta\_x) i + (delta\_y) j in old
school vector notation

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Lx}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Lx, Ly scale (km or degrees)

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Ly}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Lx, Ly scale (km or degrees)

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{theta}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} rotation angle in radians

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{tau} \textendash{} Mahalanobis distance

\sphinxlineitem{Return type}
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{radial\_dist() (in module glomar\_gridding.distances)@\spxentry{radial\_dist()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.radial_dist}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{radial\_dist}}}
{\sphinxparam{\DUrole{n}{lat1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lon1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lat2}}\sphinxparamcomma \sphinxparam{\DUrole{n}{lon2}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Computes a distance matrix of the coordinates using a spherical metric.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lat1}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} latitude of point A

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lon1}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} longitude of point A

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lat2}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} latitude of point B

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lon2}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} longitude of point B

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
Radial distance between point A and point B

\end{description}\end{quote}

\end{fulllineitems}

\index{rot\_mat() (in module glomar\_gridding.distances)@\spxentry{rot\_mat()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.rot_mat}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{rot\_mat}}}
{\sphinxparam{\DUrole{n}{angle}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute a 2d rotation matrix from an angle.

\sphinxAtStartPar
The input angle must be in radians
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{ndarray}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{sigma\_rot\_func() (in module glomar\_gridding.distances)@\spxentry{sigma\_rot\_func()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.sigma_rot_func}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{sigma\_rot\_func}}}
{\sphinxparam{\DUrole{n}{Lx}}\sphinxparamcomma \sphinxparam{\DUrole{n}{Ly}}\sphinxparamcomma \sphinxparam{\DUrole{n}{theta}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Equation 15 in Karspeck el al 2011 and Equation 6
in Paciorek and Schervish 2006,
assuming Sigma(Lx, Ly, theta) locally/moving\sphinxhyphen{}window invariant or
we have already taken the mean (Sigma overbar, PP06 3.1.1)

\sphinxAtStartPar
Lx, Ly \sphinxhyphen{} anistropic variogram length scales
theta \sphinxhyphen{} angle relative to lines of constant latitude
theta should be radians, and the fitting code outputs radians by default
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{sigma} \textendash{} 2 x 2 matrix

\sphinxlineitem{Return type}
\sphinxAtStartPar
np.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{tau\_dist() (in module glomar\_gridding.distances)@\spxentry{tau\_dist()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.tau_dist}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{tau\_dist}}}
{\sphinxparam{\DUrole{n}{dE}}\sphinxparamcomma \sphinxparam{\DUrole{n}{dN}}\sphinxparamcomma \sphinxparam{\DUrole{n}{sigma}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Eq.15 in Karspeck paper
but it is standard formulation to the
Mahalanobis distance
\sphinxurl{https://en.wikipedia.org/wiki/Mahalanobis\_distance}
10.1002/qj.900
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{ndarray}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{tau\_dist\_from\_frame() (in module glomar\_gridding.distances)@\spxentry{tau\_dist\_from\_frame()}\spxextra{in module glomar\_gridding.distances}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.distances.tau_dist_from_frame}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.distances.}}\sphinxbfcode{\sphinxupquote{tau\_dist\_from\_frame}}}
{\sphinxparam{\DUrole{n}{df}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the tau/Mahalanobis matrix for all records within a gridbox

\sphinxAtStartPar
Can be used as an input function for observations.dist\_weight.

\sphinxAtStartPar
Eq.15 in Karspeck paper
but it is standard formulation to the
Mahalanobis distance
\sphinxurl{https://en.wikipedia.org/wiki/Mahalanobis\_distance}
10.1002/qj.900

\sphinxAtStartPar
By Steven Chan \sphinxhyphen{} @stchan
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} The observational DataFrame, containing positional information for each
observation (“lat”, “lon”), gridbox specific positional information
(“grid\_lat”, “grid\_lon”), and ellipse length\sphinxhyphen{}scale parameters used for
computation of \sphinxtitleref{sigma} (“grid\_lx”, “grid\_ly”, “grid\_theta”).

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{tau} \textendash{} A matrix of dimension n x n where n is the number of rows in \sphinxtitleref{df} and
is the tau/Mahalanobis distance.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.matrix

\end{description}\end{quote}

\end{fulllineitems}



\section{Covariance Tools and Eigenvalue Clipping}
\label{\detokenize{misc:module-glomar_gridding.covariance_tools}}\label{\detokenize{misc:covariance-tools-and-eigenvalue-clipping}}\index{module@\spxentry{module}!glomar\_gridding.covariance\_tools@\spxentry{glomar\_gridding.covariance\_tools}}\index{glomar\_gridding.covariance\_tools@\spxentry{glomar\_gridding.covariance\_tools}!module@\spxentry{module}}
\sphinxAtStartPar
When estimating covariance matrices, using ellipse\sphinxhyphen{}based methods for example,
the results may not be positive\sphinxhyphen{}definite. This can be problematic, for instance
the Kriging equations may not be solvable as the inverse matrix cannot be
computed, or simulated states cannot be constructed using
{\hyperref[\detokenize{kriging:glomar_gridding.stochastic.scipy_mv_normal_draw}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.stochastic.scipy\_mv\_normal\_draw()}}}}}. To account for this,
\sphinxtitleref{glomar\_gridding} includes a few tools for \sphinxstyleemphasis{fixing} these covariance matrices.
In general, these methods attempt to coerce the input matrix to be
positive\sphinxhyphen{}definite by updating the eigenvalues and re\sphinxhyphen{}computing the matrix from
these updated eigenvalues and the original eigenvectors. The indicators of an
invalid covariance matrix include
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {}
\sphinxAtStartPar
Un\sphinxhyphen{}invertible covariance matrices with 0 eigenvalues

\item {}
\sphinxAtStartPar
Covariance matrices with eigenvalues less than zero

\end{enumerate}

\sphinxAtStartPar
This can typically be a consequence of
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {}
\sphinxAtStartPar
Multicollinearity:
but nearly all very large cov matrices will have rounding errors to have
this occur

\item {}
\sphinxAtStartPar
Number of spatial points \textgreater{}\textgreater{} length of time series
(for ESA monthly pentads: this ratio is about 150)

\item {}
\sphinxAtStartPar
Covariance is estimated using partial data

\end{enumerate}

\sphinxAtStartPar
In most cases, the most likely causes are 2 and 3.

\sphinxAtStartPar
There are a number of methods included in this module. In general, the approach
is to adjust the eigenvalues to ensure small or negative eigenvalues are
increased to some minimum threshold. The covariance matrix is then re\sphinxhyphen{}calculated
using these modified eigenvalues and the original eigenvectors.

\sphinxAtStartPar
In general, the recommended approach is Original Clipping, see
{\hyperref[\detokenize{misc:glomar_gridding.covariance_tools.eigenvalue_clip}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.eigenvalue\_clip()}}}}}.

\sphinxAtStartPar
Fixes:
\begin{quote}

\sphinxAtStartPar
1. Simple clipping \sphinxhyphen{}
{\hyperref[\detokenize{misc:glomar_gridding.covariance_tools.simple_clipping}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.simple\_clipping()}}}}}:
\begin{quote}

\sphinxAtStartPar
Cut off the negative, zero, and small positive eigenvalues; this is
method used in statsmodels.stats.correlation\_tools but the version here
has better thresholds based on the accuracy of the eigenvalues, plus a
iterative version which is slower but more stable with big matrices. The
iterative version is recommended for SST/MAT covariances.

\sphinxAtStartPar
This is used for SST covariance matrices which have less dominant modes
than MAT; it also preserves more noise.

\sphinxAtStartPar
Trace (aka total variance) of the covariance matrix is not conserved,
but it is less disruptive than EOF chop off (method 3).

\sphinxAtStartPar
It is more difficult to use for covariance matrices with one large
dominant mode because that raises the bar of accuracy of the
eigenvalues, which requires clipping off a lot more eigenvectors.

\sphinxAtStartPar
Note, this will adjust all negative eigenvalues to be positive.
\end{quote}

\sphinxAtStartPar
2. Original clipping \sphinxhyphen{}
{\hyperref[\detokenize{misc:glomar_gridding.covariance_tools.eigenvalue_clip}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.eigenvalue\_clip()}}}}}:
\begin{quote}

\sphinxAtStartPar
Determine a noise eigenvalue threshold and replace all eigenvalues below
using the average of them, preserving the original trace (aka total
variance) of the covariance matrix, but this will require a full
computation of all eigenvectors, which may be slow and cause memory
problems

\sphinxAtStartPar
Note, this will adjust all negative eigenvalues to be positive.
\end{quote}

\sphinxAtStartPar
3. EOF chop\sphinxhyphen{}off \sphinxhyphen{}
\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.eof\_chop()}}:
\begin{quote}

\sphinxAtStartPar
Set a target explained variance (say 95\%) for the empirical orthogonal
functions, compute the eigenvalues and eigenvectors up to that explained
variance. Reconstruct the covariance keeping only EOFs up to the target.
This is very close to 2, but it reduces the total variance of the
covariance matrix. The original method requires solving for ALL
eigenvectors which may not be possible for massive matrices
(40000x40000 square matrices). This is currently done for the MAT
covariance matrices which have very large dominant modes.

\sphinxAtStartPar
Note, this may not adjust negative eigenvalues to be positive.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {}
\sphinxAtStartPar
Other methods not implemented here
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumii}{enumiii}{}{.}%
\item {} \begin{description}
\sphinxlineitem{shrinkage methods}
\sphinxAtStartPar
\sphinxurl{https://scikit-learn.org/stable/modules/covariance.html}

\end{description}

\item {} \begin{description}
\sphinxlineitem{reprojection (aka Higham’s method) \sphinxcite{index:higham}}
\sphinxAtStartPar
\sphinxurl{https://github.com/mikecroucher/nearest\_correlation}

\sphinxAtStartPar
\sphinxurl{https://nhigham.com/2013/02/13/the-nearest-correlation-matrix/}

\end{description}

\end{enumerate}

\end{enumerate}
\end{quote}

\sphinxAtStartPar
Author S Chan.

\sphinxAtStartPar
Modified by J. Siddons.
\index{check\_symmetric() (in module glomar\_gridding.covariance\_tools)@\spxentry{check\_symmetric()}\spxextra{in module glomar\_gridding.covariance\_tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.covariance_tools.check_symmetric}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.}}\sphinxbfcode{\sphinxupquote{check\_symmetric}}}
{\sphinxparam{\DUrole{n}{a}}\sphinxparamcomma \sphinxparam{\DUrole{n}{rtol}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}05}}\sphinxparamcomma \sphinxparam{\DUrole{n}{atol}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}08}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Helper function for perturb\_sym\_matrix\_2\_positive\_definite
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{bool}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{clean\_small() (in module glomar\_gridding.covariance\_tools)@\spxentry{clean\_small()}\spxextra{in module glomar\_gridding.covariance\_tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.covariance_tools.clean_small}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.}}\sphinxbfcode{\sphinxupquote{clean\_small}}}
{\sphinxparam{\DUrole{n}{matrix}}\sphinxparamcomma \sphinxparam{\DUrole{n}{atol}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}05}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Set small values (abs(x) \textless{} atol) in an matrix to 0
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{ndarray}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{csum\_up\_to\_val() (in module glomar\_gridding.covariance\_tools)@\spxentry{csum\_up\_to\_val()}\spxextra{in module glomar\_gridding.covariance\_tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.covariance_tools.csum_up_to_val}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.}}\sphinxbfcode{\sphinxupquote{csum\_up\_to\_val}}}
{\sphinxparam{\DUrole{n}{vals}}\sphinxparamcomma \sphinxparam{\DUrole{n}{target}}\sphinxparamcomma \sphinxparam{\DUrole{n}{reverse}\DUrole{o}{=}\DUrole{default_value}{True}}\sphinxparamcomma \sphinxparam{\DUrole{n}{niter}\DUrole{o}{=}\DUrole{default_value}{0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{csum}\DUrole{o}{=}\DUrole{default_value}{0.0}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Find csum and sample index that target is surpassed. Displays a warning if
the target is not exceeded or the input \sphinxtitleref{vals} is empty.

\sphinxAtStartPar
Can provide an initial \sphinxtitleref{niter} and/or \sphinxtitleref{csum} value(s), if working with
multiple arrays in an iterative process.

\sphinxAtStartPar
If \sphinxtitleref{reverse} is set, the returned index will be negative and will correspond
to the index required for the non\sphinxhyphen{}reversed array. Reverse is the default.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{vals}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Vector of values to sum cumulatively.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{target}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Value for which the cumulative sum must exceed.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{reverse}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Reverse the array. The index will be negative.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{niter}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Initial number of iterations.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{csum}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Initial cumulative sum value.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{float}}, \sphinxcode{\sphinxupquote{int}}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{csum} (\sphinxstyleemphasis{float}) \textendash{} The cumulative sum at the index when the target has been exceeded.

\item {}
\sphinxAtStartPar
\sphinxstylestrong{niter} (\sphinxstyleemphasis{int}) \textendash{} The index of the value that results in the cumulative sum exceeding
the target.

\end{itemize}


\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
It is actually faster to compute a full cumulative sum with \sphinxtitleref{np.cumsum} and
then look for the value that exceeds the target. This is not performed in
this function.
\end{sphinxadmonition}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{vals} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{rand}\PYG{p}{(}\PYG{l+m+mi}{1000}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{target} \PYG{o}{=} \PYG{l+m+mf}{301.1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{csum\PYGZus{}up\PYGZus{}to\PYGZus{}val}\PYG{p}{(}\PYG{n}{vals}\PYG{p}{,} \PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{eigenvalue\_clip() (in module glomar\_gridding.covariance\_tools)@\spxentry{eigenvalue\_clip()}\spxextra{in module glomar\_gridding.covariance\_tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.covariance_tools.eigenvalue_clip}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.}}\sphinxbfcode{\sphinxupquote{eigenvalue\_clip}}}
{\sphinxparam{\DUrole{n}{cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}explained\_variance\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Denoise symmetric damaged covariance/correlation matrix cov by clipping
eigenvalues

\sphinxAtStartPar
Explained variance or aspect ratio based threshold
Aspect ratios is based on dimensionless parameters
(number of independent variable and observation size)
\begin{equation*}
\begin{split}q = N/T = (num of independent variable)
/ (num of observation per independent variable)\end{split}
\end{equation*}
\sphinxAtStartPar
Does not give the same results as in eig\_clip

\sphinxAtStartPar
explained\_variance here does not have the same meaning.
The trace of a correlation, by definition, equals the number of diagonal
elements, which isn’t intituatively linked to actual explained variance
in climate science sense

\sphinxAtStartPar
This is done by KEEPING the largest explained variance
in which (number of basis vectors to be kept) \textgreater{}\textgreater{} (number of rows)
In ESA data, keeping 95\% variance means keeping top \textasciitilde{}15\% of the
eigenvalues
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Input covariance matrix to be adjusted to positive definite.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{method}} (\sphinxstyleliteralemphasis{\sphinxupquote{"explained\_variance"}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{"Laloux\_2000"}}) \textendash{} Method used to identify the index of the eigenvalues to clip. If set to
“explained\_variance” then the sorted eigenvalues below the target
variance are \sphinxstyleemphasis{clipped}. If “Laloux\_2000” is set, then the method of
\sphinxcite{index:laloux} is used.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**kwargs}}

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Adjusted covariance matrix.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}


\begin{sphinxseealso}{See also:}
\begin{description}
\sphinxlineitem{\sphinxcode{\sphinxupquote{\sphinxhyphen{}}}}
\sphinxAtStartPar
py:func:\sphinxtitleref{glomar\_gridding.covariance\_tools.explained\_variance\_clip}.

\sphinxlineitem{\sphinxcode{\sphinxupquote{\sphinxhyphen{}}}}
\sphinxAtStartPar
py:func:\sphinxtitleref{glomar\_gridding.covariance\_tools.laloux\_clip}.

\end{description}


\end{sphinxseealso}


\end{fulllineitems}

\index{explained\_variance\_clip() (in module glomar\_gridding.covariance\_tools)@\spxentry{explained\_variance\_clip()}\spxextra{in module glomar\_gridding.covariance\_tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.covariance_tools.explained_variance_clip}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.}}\sphinxbfcode{\sphinxupquote{explained\_variance\_clip}}}
{\sphinxparam{\DUrole{n}{cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{target\_variance\_fraction}\DUrole{o}{=}\DUrole{default_value}{0.95}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Clip all EOFs beyond a certain level of explained variance
Starting from the EOF with the largest eigenvalue (explained variance)
descending down the eigenvalues until the cumulative sum of the
eigenvalues just goes beyond ( Trace(cov) x target\_variance\_fraction )

\sphinxAtStartPar
All the larger eigenvalues up to the above thresholds are left unchanged.

\sphinxAtStartPar
Eigenvalues beyond (smaller positive and negative ones) are clipped instead.
If n is the first eigenvalue to be clipped, and there are N eigenvalues,
sorted in descending order:
\begin{equation*}
\begin{split}(\lambda)_{clipped} = (\lambda_{n}, \lambda_{n+1}, ..., \lambda_{N)}\end{split}
\end{equation*}
\sphinxAtStartPar
They now get a revised eigenvalue of E(lambda\_clipped).
Checks are in place within \_eigenvalue\_clip to ensure the
threshold is suitable.

\sphinxAtStartPar
The threshold itself is subjective, but they are based on
on making intelligent guesses where noise EOF begins.

\sphinxAtStartPar
The automatic method (laloux\_clip) (sort\sphinxhyphen{}of) does it for you,
but it only works after the covariance is standardised (or the
diagonal of the covariance matrix is constant).
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxcite{index:jolliffe} recommends 70\sphinxhyphen{}90\% for truncation

\item {}
\sphinxAtStartPar
Graphical guidances (“spectrum of eigenvalues”) are helpful (\sphinxcite{index:wilks},
\sphinxcite{index:laloux})

\end{itemize}

\sphinxAtStartPar
Noting that \sphinxcite{index:wilks} and \sphinxcite{index:jolliffe} mostly concern with TRUNCATION not
clipping. However, clipping is essentially a modified version of
truncation but with the explained variance fully conserved, nor
we cannot use covariances based on truncated EOFs; it will have 0
eigenvalues, many of them will become negative after floating point
errors.

\sphinxAtStartPar
95\% is somewhat higher than \sphinxcite{index:jolliffe} 70\sphinxhyphen{}90\% guidance. Operational
experience with 5x5 monthly data indicates even at 95\%, you are
only retaining 200\sphinxhyphen{}400 eigenvalues out of 36 x 72 = 2592 possible
eigenvalues (if data is global). There are only \textasciitilde{}10\sphinxhyphen{}20 negative eigenvalues
plus the 2000\sphinxhyphen{}ish eigenvalues that sits out of 95\% threshold. The magitude
of the negative values are 2\sphinxhyphen{}plus order of mangitude smaller than the
largest positive eigenvalues.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Input covariance matrix to be adjusted to positive definite.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{target\_variance\_fraction}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Starting from the largest eigenvalue and descending, all eigenvalues
larger than (the trace of cov x target\_variance\_fraction) are left
unmodified. Eigenvalues beyond are modified.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Adjusted covariance matrix.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{References}
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxcite{index:laloux}

\item {}
\sphinxAtStartPar
\sphinxcite{index:jolliffe}

\item {}
\sphinxAtStartPar
\sphinxcite{index:wilks}

\end{itemize}


\begin{sphinxseealso}{See also:}

\sphinxAtStartPar
{\hyperref[\detokenize{misc:glomar_gridding.covariance_tools.laloux_clip}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.laloux\_clip()}}}}}


\end{sphinxseealso}


\end{fulllineitems}

\index{laloux\_clip() (in module glomar\_gridding.covariance\_tools)@\spxentry{laloux\_clip()}\spxextra{in module glomar\_gridding.covariance\_tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.covariance_tools.laloux_clip}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.}}\sphinxbfcode{\sphinxupquote{laloux\_clip}}}
{\sphinxparam{\DUrole{n}{cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_grid\_pts}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num\_time\_pts}\DUrole{o}{=}\DUrole{default_value}{40}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Estimate the largest eigenvalue that one will get from covariance or
correlation matrices that are generated by random uncorrelated matrices.

\sphinxAtStartPar
Eq 0.3 in \sphinxcite{index:laloux} says eigenvalues of covariances generated by
uncorrelated random vectors have a min and max of:

\sphinxAtStartPar
lambda\_min = sigma**2 (1 + Q \sphinxhyphen{} 2 SQRT(Q))
lambda\_max = sigma**2 (1 + Q + 2 SQRT(Q))

\sphinxAtStartPar
in which:

\sphinxAtStartPar
Q = num\_of\_features / length\_of\_each\_feature

\sphinxAtStartPar
One can make a simple Monte\sphinxhyphen{}Carlo simulation to check that.

\sphinxAtStartPar
Hence lambda\_max can be thought of a floor for non\sphinxhyphen{}noise EOFs,
as this is the largest eigenvalue that can be generated by random
uncorrelated data, and is only a function of Q (aka aspect ratio
of the number of features with the length of each feature vector).

\sphinxAtStartPar
Any eigenvalues smaller than lambda\_max (including negative ones) are
essentially noise and can be trimmed.

\sphinxAtStartPar
Above requires q and sigma be the same for all features/independent
variables. A way to get to around that is standardise the covariance into
correlation and to apply the trimming to the correlation. The trimmed
correlation can then converted back to the covariance by putting the
correct standard deviations back into the diagonal.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Input covariance matrix to be adjusted to positive definite.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_grid\_pts}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Number of spatial grid points for covariance, this should usually be the
shape of the covariance matrix. If unset, this will default to the size
of the input covariance matrix (\sphinxtitleref{cov.shape{[}0{]}}).

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_time\_pts}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Length of the time series that is behind the covariance generation
Default 40 (aka 40 Jans from 1981\sphinxhyphen{}2020), since this is what used
originally when covariances are generated for modern satellite era
data (early 1980\sphinxhyphen{}ish to 2020\sphinxhyphen{}ish). It is important this value to
be set correctly.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Adjusted covariance matrix.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{References}
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxcite{index:laloux}

\item {}
\sphinxAtStartPar
\sphinxcite{index:bun}

\end{itemize}


\begin{sphinxseealso}{See also:}

\sphinxAtStartPar
{\hyperref[\detokenize{misc:glomar_gridding.covariance_tools.explained_variance_clip}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.explained\_variance\_clip()}}}}}


\end{sphinxseealso}


\end{fulllineitems}

\index{perturb\_cov\_to\_positive\_definite() (in module glomar\_gridding.covariance\_tools)@\spxentry{perturb\_cov\_to\_positive\_definite()}\spxextra{in module glomar\_gridding.covariance\_tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.covariance_tools.perturb_cov_to_positive_definite}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.}}\sphinxbfcode{\sphinxupquote{perturb\_cov\_to\_positive\_definite}}}
{\sphinxparam{\DUrole{n}{cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{threshold}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}15}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Force an estimated covariance matrix to be positive definite using the
eigenvalue clipping with statsmodels.stats.correlation\_tools.cov\_nearest
function.

\sphinxAtStartPar
Deprecated in favour of
{\hyperref[\detokenize{misc:glomar_gridding.covariance_tools.simple_clipping}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.simple\_clipping()}}}}}.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The estimated covariance matrix that is not positive definite.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{threshold}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{\textquotesingle{}auto\textquotesingle{}}}) \textendash{} Eigenvalues below this value are set to 0. If the input is ‘auto’ then
the value is determined using the floating\sphinxhyphen{}point precision and magnitude
of the largest eigenvalues.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{cov\_adj} \textendash{} Adjusted covariance matrix

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}


\begin{sphinxseealso}{See also:}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tool.simple\_clipping()}}


\end{sphinxseealso}

\subsubsection*{Notes}

\sphinxAtStartPar
Other methods:
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxurl{https://nhigham.com/2021/02/16/diagonally-perturbing-a-symmetric-matrix-to-make-it-positive-definite/}

\item {}
\sphinxAtStartPar
\sphinxurl{https://nhigham.com/2013/02/13/the-nearest-correlation-matrix/}

\item {}
\sphinxAtStartPar
\sphinxurl{https://academic.oup.com/imajna/article/22/3/329/708688}

\end{itemize}

\end{fulllineitems}

\index{simple\_clipping() (in module glomar\_gridding.covariance\_tools)@\spxentry{simple\_clipping()}\spxextra{in module glomar\_gridding.covariance\_tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.covariance_tools.simple_clipping}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.covariance\_tools.}}\sphinxbfcode{\sphinxupquote{simple\_clipping}}}
{\sphinxparam{\DUrole{n}{cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{threshold}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}auto\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}iterative\textquotesingle{}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
A modified version of:
\sphinxurl{https://www.statsmodels.org/dev/generated/statsmodels.stats.correlation\_tools.corr\_nearest.html}

\sphinxAtStartPar
Force an estimated covariance matrix to be positive definite using the
eigenvalue clipping with statsmodels.stats.correlation\_tools.cov\_nearest
function.

\sphinxAtStartPar
This is appropriate for covariance matrices which have less dominant modes;
it also preserves more noise.

\sphinxAtStartPar
Trace (aka total variance) of the covariance matrix is not conserved,
but it is less disruptive than EOF chop off.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The estimated covariance matrix that is not positive definite.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{threshold}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{\textquotesingle{}auto\textquotesingle{}}}) \textendash{} Eigenvalues below this value are set to 0. If the input is ‘auto’ then
the value is determined using the floating\sphinxhyphen{}point precision and magnitude
of the largest eigenvalues.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{ndarray}}, \sphinxcode{\sphinxupquote{dict}}{[}\sphinxcode{\sphinxupquote{str}}, \sphinxcode{\sphinxupquote{Any}}{]}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{cov\_adj} (\sphinxstyleemphasis{numpy.ndarray}) \textendash{} Adjusted covariance matrix

\item {}
\sphinxAtStartPar
\sphinxstylestrong{summary\_dict} (\sphinxstyleemphasis{dict{[}str, Any{]}}) \textendash{} A dictionary containing a summary of the input and results with the
following keys:
\begin{itemize}
\item {}
\sphinxAtStartPar
”threshold”

\item {}
\sphinxAtStartPar
”smallest\_eigv”

\item {}
\sphinxAtStartPar
”determinant”

\item {}
\sphinxAtStartPar
”total\_variance”

\end{itemize}

\end{itemize}


\end{description}\end{quote}


\begin{sphinxseealso}{See also:}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{statsmodels.stats.correlation\_tools.cov\_nearest()}}


\end{sphinxseealso}

\subsubsection*{Notes}

\sphinxAtStartPar
Other methods:
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxurl{https://nhigham.com/2021/02/16/diagonally-perturbing-a-symmetric-matrix-to-make-it-positive-definite/}

\item {}
\sphinxAtStartPar
\sphinxurl{https://nhigham.com/2013/02/13/the-nearest-correlation-matrix/}

\item {}
\sphinxAtStartPar
\sphinxurl{https://academic.oup.com/imajna/article/22/3/329/708688}

\end{itemize}

\end{fulllineitems}



\section{IO}
\label{\detokenize{misc:module-glomar_gridding.io}}\label{\detokenize{misc:io}}\index{module@\spxentry{module}!glomar\_gridding.io@\spxentry{glomar\_gridding.io}}\index{glomar\_gridding.io@\spxentry{glomar\_gridding.io}!module@\spxentry{module}}
\sphinxAtStartPar
\sphinxtitleref{glomar\_gridding} includes functionality for loading datasets or arrays from
\sphinxtitleref{netCDF} files using python format strings. This can be useful for loading
pre\sphinxhyphen{}computed inputs for the Kriging process, for example covariance matrices or
observations. The allowance for passing a string containing format components
(e.g. python t\sphinxhyphen{}string) allows for dynamic configuration if processing a series
of monthly inputs for example.

\sphinxAtStartPar
Also included is a function for recursively getting sub\sphinxhyphen{}keys from a python
\sphinxtitleref{dict} style object. This can be useful for working with \sphinxtitleref{yaml} formatting
configuration files for instance.
\index{get\_recurse() (in module glomar\_gridding.io)@\spxentry{get\_recurse()}\spxextra{in module glomar\_gridding.io}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.io.get_recurse}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.io.}}\sphinxbfcode{\sphinxupquote{get\_recurse}}}
{\sphinxparam{\DUrole{n}{config}}\sphinxparamcomma \sphinxparam{\DUrole{o}{*}\DUrole{n}{keys}}\sphinxparamcomma \sphinxparam{\DUrole{n}{default}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Recursively get sub keys from a python dict object.

\sphinxAtStartPar
If a dictionary object contains keys whose values are themselves
dictionaries, get a value from a sub dictionary by specifying the key\sphinxhyphen{}path
to get to the desired value.

\sphinxAtStartPar
Equivalent to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{config}\PYG{p}{[}\PYG{n}{keys}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{[}\PYG{n}{keys}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{[}\PYG{n}{keys}\PYG{p}{[}\PYG{n}{n}\PYG{p}{]}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Or:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{config}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{n}{keys}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{n}{keys}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{n}{keys}\PYG{p}{[}\PYG{n}{n}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{config}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} The layered dictionary containing sub dictionaries.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{*keys}} \textendash{} The sequence of keys to recurse through to get the final value. If any
key in the sequence is not found, or is not a dictionary (and is not
the final key), then the default value is returned.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{default}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} The default value, returned if the sequence of keys cannot be completed
or the final key is not present.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{Any}}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleemphasis{The value associated with the final key, or the default value if the final}

\item {}
\sphinxAtStartPar
\sphinxstyleemphasis{key cannot be reached.}

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{load\_array() (in module glomar\_gridding.io)@\spxentry{load\_array()}\spxextra{in module glomar\_gridding.io}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.io.load_array}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.io.}}\sphinxbfcode{\sphinxupquote{load\_array}}}
{\sphinxparam{\DUrole{n}{path}}\sphinxparamcomma \sphinxparam{\DUrole{n}{var}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}covariance\textquotesingle{}}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Load an xarray.DataArray from a netCDF file. Can input a filename or a
string to format with keyword arguments.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{}
\sphinxAtStartPar
Full filename (including path), or filename with replacements using
str.format with named replacements. For example:
\begin{quote}

\sphinxAtStartPar
/path/to/global\_covariance\_\{month:02d\}.nc
\end{quote}


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{var}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the variable to select from the input file

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**kwargs}} \textendash{} Keywords arguments matching the replacements in the input path.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{arr} \textendash{} An array containing the values of the variable specified by var

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.DataArray

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_dataset() (in module glomar\_gridding.io)@\spxentry{load\_dataset()}\spxextra{in module glomar\_gridding.io}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.io.load_dataset}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.io.}}\sphinxbfcode{\sphinxupquote{load\_dataset}}}
{\sphinxparam{\DUrole{n}{path}}\sphinxparamcomma \sphinxparam{\DUrole{o}{**}\DUrole{n}{kwargs}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Load an xarray.Dataset from a netCDF file. Can input a filename or a
string to format with keyword arguments.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{}
\sphinxAtStartPar
Full filename (including path), or filename with replacements using
str.format with named replacements. For example:
\begin{quote}

\sphinxAtStartPar
/path/to/global\_covariance\_\{month:02d\}.nc
\end{quote}


\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{**kwargs}} \textendash{} Keywords arguments matching the replacements in the input path.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{arr} \textendash{} The netcdf dataset as an xarray.Dataset.

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.Dataset

\end{description}\end{quote}

\end{fulllineitems}



\section{Utilities}
\label{\detokenize{misc:module-glomar_gridding.utils}}\label{\detokenize{misc:utilities}}\index{module@\spxentry{module}!glomar\_gridding.utils@\spxentry{glomar\_gridding.utils}}\index{glomar\_gridding.utils@\spxentry{glomar\_gridding.utils}!module@\spxentry{module}}
\sphinxAtStartPar
Utility functions for \sphinxtitleref{glomar\_gridding}
\index{ColumnNotFoundError@\spxentry{ColumnNotFoundError}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.ColumnNotFoundError}}
\pysigstartsignatures
\pysigline
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{exception}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{ColumnNotFoundError}}}
\pysigstopsignatures
\sphinxAtStartPar
Error class for Column Not Being Found

\end{fulllineitems}

\index{MonthName (class in glomar\_gridding.utils)@\spxentry{MonthName}\spxextra{class in glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.MonthName}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxbfcode{\sphinxupquote{\DUrole{k}{class}\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{MonthName}}}
{\sphinxparam{\DUrole{o}{*}\DUrole{n}{values}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Name of month from int

\end{fulllineitems}

\index{add\_empty\_layers() (in module glomar\_gridding.utils)@\spxentry{add\_empty\_layers()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.add_empty_layers}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{add\_empty\_layers}}}
{\sphinxparam{\DUrole{n}{nc\_variables}}\sphinxparamcomma \sphinxparam{\DUrole{n}{timestamps}}\sphinxparamcomma \sphinxparam{\DUrole{n}{shape}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Add empty layers to a netcdf file. This adds a layer of zeros to the netCDF
file.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nc\_variables}} (\sphinxstyleliteralemphasis{\sphinxupquote{Iterable}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{netcdf.Variable}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{netcdf.Variable}}) \textendash{} Name(s) of the variables to add empty layers to

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{timestamps}} (\sphinxstyleliteralemphasis{\sphinxupquote{Iterable}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Indices to add empty layers

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{shape}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Shape of the layer to add

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{adjust\_small\_negative() (in module glomar\_gridding.utils)@\spxentry{adjust\_small\_negative()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.adjust_small_negative}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{adjust\_small\_negative}}}
{\sphinxparam{\DUrole{n}{mat}}\sphinxparamcomma \sphinxparam{\DUrole{n}{atol}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}08}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Adjusts small negative values below an absolute tolerance value in a matrix
to 0.

\sphinxAtStartPar
Raises a warning if any small negative values are detected.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mat}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Squared uncertainty associated with chosen kriging method
Derived from the diagonal of the matrix

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{atol}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 1e\sphinxhyphen{}8}}) \textendash{} Absolute tolerance value.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
With negatice values below an absolute tolerance replaced with 0.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{arr} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1e\PYGZhy{}10}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1e\PYGZhy{}10}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{adjust\PYGZus{}small\PYGZus{}negative}\PYG{p}{(}\PYG{n}{arr}\PYG{p}{,} \PYG{n}{atol}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}8}\PYG{p}{)}
\PYG{g+go}{array([[1., 0.],}
\PYG{g+go}{       [0., 1.]])}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{batched() (in module glomar\_gridding.utils)@\spxentry{batched()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.batched}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{batched}}}
{\sphinxparam{\DUrole{n}{iterable}}\sphinxparamcomma \sphinxparam{\DUrole{n}{n}}\sphinxparamcomma \sphinxparam{\DUrole{keyword-only-separator}{\DUrole{o}{\sphinxstyleabbreviation{*} (Keyword\sphinxhyphen{}only parameters separator (PEP 3102))}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{strict}\DUrole{o}{=}\DUrole{default_value}{False}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Implementation of itertools.batched for use if python version is \textless{} 3.12.
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{batched}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ABCDEFG}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[(\PYGZdq{}A\PYGZdq{}, \PYGZdq{}B\PYGZdq{}, \PYGZdq{}C\PYGZdq{}), (\PYGZdq{}D\PYGZdq{}, \PYGZdq{}E\PYGZdq{}, \PYGZdq{}F\PYGZdq{}), (\PYGZdq{}G\PYGZdq{}, )]}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{check\_cols() (in module glomar\_gridding.utils)@\spxentry{check\_cols()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.check_cols}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{check\_cols}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{cols}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Check that all columns in a list of columns are in a DataFrame.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}})

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cols}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of columns to check for in \sphinxtitleref{df}

\end{itemize}

\sphinxlineitem{Raises}
\sphinxAtStartPar
{\hyperref[\detokenize{misc:glomar_gridding.utils.ColumnNotFoundError}]{\sphinxcrossref{\sphinxstyleliteralstrong{\sphinxupquote{ColumnNotFoundError}}}}} \textendash{} If any columns in \sphinxtitleref{cols} are not present in \sphinxtitleref{df}. The missing columns
    are displayed in the error message.

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{cor\_2\_cov() (in module glomar\_gridding.utils)@\spxentry{cor\_2\_cov()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.cor_2_cov}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{cor\_2\_cov}}}
{\sphinxparam{\DUrole{n}{cor}}\sphinxparamcomma \sphinxparam{\DUrole{n}{variances}}\sphinxparamcomma \sphinxparam{\DUrole{n}{rounding}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute covariance matrix from correlation matrix and variances
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cor}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Correlation Matrix

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{variances}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Variances to scale the correlation matrix.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{rounding}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} round the values of the output

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{ndarray}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{cov\_2\_cor() (in module glomar\_gridding.utils)@\spxentry{cov\_2\_cor()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.cov_2_cor}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{cov\_2\_cor}}}
{\sphinxparam{\DUrole{n}{cov}}\sphinxparamcomma \sphinxparam{\DUrole{n}{rounding}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Normalises the covariance matrices within the class instance
and return correlation matrices
\sphinxurl{https://gist.github.com/wiso/ce2a9919ded228838703c1c7c7dad13b}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cov}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Covariance matrix

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{rounding}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} round the values of the output

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{ndarray}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{days\_since\_by\_month() (in module glomar\_gridding.utils)@\spxentry{days\_since\_by\_month()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.days_since_by_month}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{days\_since\_by\_month}}}
{\sphinxparam{\DUrole{n}{year}}\sphinxparamcomma \sphinxparam{\DUrole{n}{day}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Get the number of days since \sphinxtitleref{year}\sphinxhyphen{}01\sphinxhyphen{}\sphinxtitleref{day} for each month. This is used
to set the time values in a netCDF file where temporal resolution is monthly
and the units are days since some date.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{year}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Get a value for each month in this year.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{day}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Day of month for each returned datetime value in the sequence.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Containing 12 values, one for each month in the year containing the
number of days since \sphinxtitleref{year}\sphinxhyphen{}01\sphinxhyphen{}\sphinxtitleref{day}.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{days\PYGZus{}since\PYGZus{}by\PYGZus{}month}\PYG{p}{(}\PYG{l+m+mi}{1988}\PYG{p}{,} \PYG{l+m+mi}{14}\PYG{p}{)}
\PYG{g+go}{array([  0,  31,  60,  91, 121, 152, 182, 213, 244, 274, 305, 335])}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{deg\_to\_km() (in module glomar\_gridding.utils)@\spxentry{deg\_to\_km()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.deg_to_km}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{deg\_to\_km}}}
{\sphinxparam{\DUrole{n}{deg}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Convert degree latitude change to km
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{deg}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The difference in latitude in degrees

\sphinxlineitem{Returns}
\sphinxAtStartPar
The latitude difference in kilometers

\sphinxlineitem{Return type}
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{deg\_to\_nm() (in module glomar\_gridding.utils)@\spxentry{deg\_to\_nm()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.deg_to_nm}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{deg\_to\_nm}}}
{\sphinxparam{\DUrole{n}{deg}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Convert degree latitude change to nautical miles
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{deg}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The difference in latitude in degrees

\sphinxlineitem{Returns}
\sphinxAtStartPar
The latitude difference in nautical miles

\sphinxlineitem{Return type}
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{filter\_bounds() (in module glomar\_gridding.utils)@\spxentry{filter\_bounds()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.filter_bounds}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{filter\_bounds}}}
{\sphinxparam{\DUrole{n}{df}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bounds}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bound\_cols}}\sphinxparamcomma \sphinxparam{\DUrole{n}{closed}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}left\textquotesingle{}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Filter a polars DataFrame based on a set of lower and upper bounds.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{df}} (\sphinxstyleliteralemphasis{\sphinxupquote{polars.DataFrame}}) \textendash{} The data to be filtered by the bounds

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bounds}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A list of tuples containing lower and upper bounds for a column

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bound\_cols}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A list of column names to be filtered by the bounds, the length of
the bounds list must equal the length of the bound\_cols list.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{closed}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} One of “both”, “left”, “right”, “none” indicating the closedness of
the bounds. If the input is a single instance then all bounds will have
that closedness. If it is a list of closed values then its length must
match the length of the bounds list.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
DataFrame filtered by the positional bounds

\sphinxlineitem{Return type}
\sphinxAtStartPar
polars.DataFrame

\end{description}\end{quote}

\end{fulllineitems}

\index{find\_nearest() (in module glomar\_gridding.utils)@\spxentry{find\_nearest()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.find_nearest}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{find\_nearest}}}
{\sphinxparam{\DUrole{n}{array}}\sphinxparamcomma \sphinxparam{\DUrole{n}{values}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Get the indices and values from an array that are closest to the input
values.

\sphinxAtStartPar
A single index, value pair is returned for each look\sphinxhyphen{}up value in the values
list.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{array}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The array to search for nearest values.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{values}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The values to look\sphinxhyphen{}up in the array.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{list}}{[}\sphinxcode{\sphinxupquote{int}}{]}, \sphinxcode{\sphinxupquote{ndarray}}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{idx\_list} (\sphinxstyleemphasis{list{[}int{]}}) \textendash{} The indices of nearest values

\item {}
\sphinxAtStartPar
\sphinxstylestrong{array\_values\_list} (\sphinxstyleemphasis{list}) \textendash{} The list of values in array that are closest to the input values.

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{array} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mf}{1.0}\PYG{p}{,} \PYG{l+m+mf}{2.5}\PYG{p}{,} \PYG{l+m+mf}{2.7}\PYG{p}{,} \PYG{l+m+mf}{2.1}\PYG{p}{,} \PYG{l+m+mf}{4.5}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{tests} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mf}{1.1}\PYG{p}{,} \PYG{l+m+mf}{4.4}\PYG{p}{,} \PYG{l+m+mf}{2.2}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{find\PYGZus{}nearest}\PYG{p}{(}\PYG{n}{array}\PYG{p}{,} \PYG{n}{tests}\PYG{p}{)}
\PYG{g+go}{([np.int64(0), np.int64(4), np.int64(3)], array([1. , 4.5, 2.1]))}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{get\_date\_index() (in module glomar\_gridding.utils)@\spxentry{get\_date\_index()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.get_date_index}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{get\_date\_index}}}
{\sphinxparam{\DUrole{n}{year}}\sphinxparamcomma \sphinxparam{\DUrole{n}{month}}\sphinxparamcomma \sphinxparam{\DUrole{n}{start\_year}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Get the index of a given year\sphinxhyphen{}month in a monthly sequence of dates
starting from month 1 in a specific start year
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{year}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The year for the date to find the index of.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{month}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The month for the date to find the index of.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{start\_year}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The start year of the date series, the result assumes that the date
time series starts in the first month of this year.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{index} \textendash{} The index of the input date in the monthly datetime series starting from
the first month of year \sphinxtitleref{start\_year}.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{get\PYGZus{}date\PYGZus{}index}\PYG{p}{(}\PYG{l+m+mi}{2009}\PYG{p}{,} \PYG{l+m+mi}{14}\PYG{p}{,} \PYG{n}{start\PYGZus{}year}\PYG{o}{=}\PYG{l+m+mi}{1988}\PYG{p}{)}
\PYG{g+go}{265}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{get\_month\_midpoint() (in module glomar\_gridding.utils)@\spxentry{get\_month\_midpoint()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.get_month_midpoint}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{get\_month\_midpoint}}}
{\sphinxparam{\DUrole{n}{dates}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Get the month midpoint for a series of datetimes.

\sphinxAtStartPar
The midpoint of a month is the exact half\sphinxhyphen{}way point between the start and
end of the month.

\sphinxAtStartPar
For example, the midpoint of January 1990 is 1990\sphinxhyphen{}01\sphinxhyphen{}16 12:00.
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{Series}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_pentad\_range() (in module glomar\_gridding.utils)@\spxentry{get\_pentad\_range()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.get_pentad_range}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{get\_pentad\_range}}}
{\sphinxparam{\DUrole{n}{centre\_date}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Get the start and date of a pentad centred at a centre date. If the
pentad includes the leap date of 29th Feb then the pentad will include
6 days. This follows the \sphinxstylestrong{*} pentad convention.

\sphinxAtStartPar
The start and end date are first calculated from a non\sphinxhyphen{}leap year.

\sphinxAtStartPar
If the centre date value is 29th Feb then the pentad will be a pentad
starting on 27th Feb and ending on 2nd March.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{centre\_date}} (\sphinxstyleliteralemphasis{\sphinxupquote{datetime.date}}) \textendash{} The centre date of the pentad. The start date will be 2 days before this
date, and the end date will be 2 days after.

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{tuple}}{[}\sphinxcode{\sphinxupquote{date}}, \sphinxcode{\sphinxupquote{date}}{]}}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstylestrong{start\_date} (\sphinxstyleemphasis{datetime.date}) \textendash{} Two days before centre\_date

\item {}
\sphinxAtStartPar
\sphinxstylestrong{end\_date} (\sphinxstyleemphasis{datetime.date}) \textendash{} Two days after centre\_date

\end{itemize}


\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{get\PYGZus{}pentad\PYGZus{}range}\PYG{p}{(}\PYG{n}{date}\PYG{p}{(}\PYG{l+m+mi}{2008}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{29}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{(datetime.date(2008, 2, 27), datetime.date(2008, 3, 2))}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{get\_spatial\_mean() (in module glomar\_gridding.utils)@\spxentry{get\_spatial\_mean()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.get_spatial_mean}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{get\_spatial\_mean}}}
{\sphinxparam{\DUrole{n}{grid\_obs}}\sphinxparamcomma \sphinxparam{\DUrole{n}{covx}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Compute the spatial mean accounting for auto\sphinxhyphen{}correlation. See \sphinxcite{index:cornell}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{grid\_obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Vector containing observations

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{covx}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} Observation covariance matrix

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{spatial\_mean} \textendash{} The spatial mean defined as (1\textasciicircum{}T x C\textasciicircum{}\{\sphinxhyphen{}1\} x 1)\textasciicircum{}\{\sphinxhyphen{}1\} * (1\textasciicircum{}T x C\textasciicircum{}\{\sphinxhyphen{}1\} x z)

\sphinxlineitem{Return type}
\sphinxAtStartPar
float

\end{description}\end{quote}
\subsubsection*{References}

\sphinxAtStartPar
\sphinxcite{index:cornell} \sphinxurl{https://www.css.cornell.edu/faculty/dgr2/\_static/files/distance\_ed\_geostats/ov5.pdf}

\end{fulllineitems}

\index{init\_logging() (in module glomar\_gridding.utils)@\spxentry{init\_logging()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.init_logging}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{init\_logging}}}
{\sphinxparam{\DUrole{n}{file}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{level}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}DEBUG\textquotesingle{}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Initialise the logger
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{file}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} File to send log messages to. If set to None (default) then print log
messages to STDout

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{level}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Level of logging, one of: “debug”, “info”, “warn”, “error”, “critical”.

\end{itemize}

\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{None}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{intersect\_mtlb() (in module glomar\_gridding.utils)@\spxentry{intersect\_mtlb()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.intersect_mtlb}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{intersect\_mtlb}}}
{\sphinxparam{\DUrole{n}{a}}\sphinxparamcomma \sphinxparam{\DUrole{n}{b}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Returns data common between two arrays, a and b, in a sorted order and index
vectors for a and b arrays Reproduces behaviour of Matlab’s intersect
function.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{a}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}})

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{b}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}})

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {}
\sphinxAtStartPar
Intersection

\item {}
\sphinxAtStartPar
List of indices, where the common values are located, for array a

\item {}
\sphinxAtStartPar
List of indices, where the common values are located, for array b

\end{itemize}


\sphinxlineitem{Return type}
\sphinxAtStartPar
tuple{[}numpy.ndarray{]}

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{a} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{intersect\PYGZus{}mtlb}\PYG{p}{(}\PYG{n}{a}\PYG{p}{,} \PYG{n}{b}\PYG{p}{)}
\PYG{g+go}{(array([1, 2]), array([0, 1]), array([0, 2]))}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{is\_iter() (in module glomar\_gridding.utils)@\spxentry{is\_iter()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.is_iter}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{is\_iter}}}
{\sphinxparam{\DUrole{n}{val}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Determine if a value is an iterable
\begin{quote}\begin{description}
\sphinxlineitem{Return type}
\sphinxAtStartPar
\DUrole{sphinx_autodoc_typehints-type}{\sphinxcode{\sphinxupquote{bool}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{km\_to\_deg() (in module glomar\_gridding.utils)@\spxentry{km\_to\_deg()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.km_to_deg}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{km\_to\_deg}}}
{\sphinxparam{\DUrole{n}{km}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Convert meridonal km change to degree latitude
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{km}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The meridonal difference in kilometers

\sphinxlineitem{Returns}
\sphinxAtStartPar
The meridonal difference in degrees

\sphinxlineitem{Return type}
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{mask\_array() (in module glomar\_gridding.utils)@\spxentry{mask\_array()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.mask_array}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{mask\_array}}}
{\sphinxparam{\DUrole{n}{arr}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Forces numpy array to be an instance of np.ma.MaskedArray
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{arr}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Can be masked or not masked

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{arr} \textendash{} array is now an instance of np.ma.MaskedArray

\sphinxlineitem{Return type}
\sphinxAtStartPar
np.ndarray

\end{description}\end{quote}

\end{fulllineitems}

\index{select\_bounds() (in module glomar\_gridding.utils)@\spxentry{select\_bounds()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.select_bounds}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{select\_bounds}}}
{\sphinxparam{\DUrole{n}{x}}\sphinxparamcomma \sphinxparam{\DUrole{n}{bounds}\DUrole{o}{=}\DUrole{default_value}{{[}(\sphinxhyphen{}90, 90), (\sphinxhyphen{}180, 180){]}}}\sphinxparamcomma \sphinxparam{\DUrole{n}{variables}\DUrole{o}{=}\DUrole{default_value}{{[}\textquotesingle{}lat\textquotesingle{}, \textquotesingle{}lon\textquotesingle{}{]}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Filter an xarray.DataArray or xarray.Dataset by a set of bounds.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x}} (\sphinxstyleliteralemphasis{\sphinxupquote{xarray.DataArray}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{xarray.Dataset}}) \textendash{} The data to filter

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bounds}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A list of tuples containing the lower and upper bounds for each
dimension.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{variables}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Names of the dimensions (the order must match the bounds).

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{x} \textendash{} The input data filtered by the bounds.

\sphinxlineitem{Return type}
\sphinxAtStartPar
xarray.DataArray | xarray.Dataset

\end{description}\end{quote}

\end{fulllineitems}

\index{sizeof\_fmt() (in module glomar\_gridding.utils)@\spxentry{sizeof\_fmt()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.sizeof_fmt}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{sizeof\_fmt}}}
{\sphinxparam{\DUrole{n}{num}}\sphinxparamcomma \sphinxparam{\DUrole{n}{suffix}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}B\textquotesingle{}}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Convert numbers to kilo/mega… bytes, for interactive printing of code
progress.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The number (typically of bytes) to format

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{suffix}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}})

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The formatted number using power of 1024 base.

\sphinxlineitem{Return type}
\sphinxAtStartPar
str

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{sizeof\PYGZus{}fmt}\PYG{p}{(}\PYG{l+m+mi}{123456789}\PYG{p}{)}
\PYG{g+go}{\PYGZsq{}117.7MiB\PYGZsq{}}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{uncompress\_masked() (in module glomar\_gridding.utils)@\spxentry{uncompress\_masked()}\spxextra{in module glomar\_gridding.utils}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{misc:glomar_gridding.utils.uncompress_masked}}
\pysigstartsignatures
\pysiglinewithargsret
{\sphinxcode{\sphinxupquote{glomar\_gridding.utils.}}\sphinxbfcode{\sphinxupquote{uncompress\_masked}}}
{\sphinxparam{\DUrole{n}{compressed\_array}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mask}}\sphinxparamcomma \sphinxparam{\DUrole{n}{fill\_value}\DUrole{o}{=}\DUrole{default_value}{0.0}}\sphinxparamcomma \sphinxparam{\DUrole{n}{apply\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}\sphinxparamcomma \sphinxparam{\DUrole{n}{dtype}\DUrole{o}{=}\DUrole{default_value}{None}}}
{}
\pysigstopsignatures
\sphinxAtStartPar
Un\sphinxhyphen{}compress a compressed array using a mask.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{compressed\_array}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The compressed array, originally compressed by the mask

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) \textendash{} The mask \sphinxhyphen{} a boolean numpy array

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fill\_value}} (\sphinxstyleliteralemphasis{\sphinxupquote{Any}}) \textendash{} The value to fill masked points. If \sphinxtitleref{apply\_mask} is set, then this will
be removed in the output.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{apply\_mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Apply the mask to the result, returning a MaskedArray rather than a
ndarray.

\item {}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dtype}} (\sphinxstyleliteralemphasis{\sphinxupquote{type}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}) \textendash{} Optionally set a dtype for the returned array, if not set then the
dtype of the compressed\_array is used.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{uncompressed} \textendash{} The uncompressed array, masked points are filled with the fill\_value if
apply\_mask is False. If apply\_mask is True, then the result is an
instance of numpy.ma.MaskedArray with the mask applied to the
uncompressed result.

\sphinxlineitem{Return type}
\sphinxAtStartPar
numpy.ndarray | numpy.ma.MaskedArray

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{arr} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{rand}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{mask} \PYG{o}{=} \PYG{n}{arr} \PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{0.65}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{arr} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ma}\PYG{o}{.}\PYG{n}{masked\PYGZus{}where}\PYG{p}{(}\PYG{n}{mask}\PYG{p}{,} \PYG{n}{arr}\PYG{p}{)}\PYG{o}{.}\PYG{n}{compressed}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{uncompress\PYGZus{}masked}\PYG{p}{(}\PYG{n}{arr}\PYG{p}{,} \PYG{n}{mask}\PYG{p}{,} \PYG{n}{fill\PYGZus{}value}\PYG{o}{=}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{999.0}\PYG{p}{)}
\PYG{g+go}{array([ 2.79245414e\PYGZhy{}01, \PYGZhy{}9.99000000e+02,  3.93541024e\PYGZhy{}01, \PYGZhy{}9.99000000e+02,}
\PYG{g+go}{        8.07814120e\PYGZhy{}03,  3.34164220e\PYGZhy{}01, \PYGZhy{}9.99000000e+02,  2.08200564e\PYGZhy{}01,}
\PYG{g+go}{        3.32044850e\PYGZhy{}01,  1.83166093e\PYGZhy{}01, \PYGZhy{}9.99000000e+02,  2.57339943e\PYGZhy{}02,}
\PYG{g+go}{        1.76017461e\PYGZhy{}01,  3.56673893e\PYGZhy{}01,  1.59393168e\PYGZhy{}01,  2.17047382e\PYGZhy{}01])}
\end{sphinxVerbatim}

\end{fulllineitems}


\begin{sphinxthebibliography}{Paciorek}
\bibitem[Bun]{index:bun}
\sphinxAtStartPar
Bun, J., Bouchaud, J.\sphinxhyphen{}P., and Potters, M: Cleaning large correlation matrices: Tools from Random Matrix Theory, Physics Reports, Volume 666, 2017, Pages 1\sphinxhyphen{}109, ISSN 0370\sphinxhyphen{}1573, \sphinxurl{https://doi.org/10.1016/j.physrep.2016.10.005}.
\bibitem[Cornell]{index:cornell}
\sphinxAtStartPar
\sphinxurl{https://www.css.cornell.edu/faculty/dgr2/\_static/files/distance\_ed\_geostats/ov5.pdf}
\bibitem[Cressie]{index:cressie}
\sphinxAtStartPar
Cressie, N. A. C.: Statistics for Spatial Data, Wiley Series in Probability and Statistics, Wiley, 1 edn., ISBN 978\sphinxhyphen{}0\sphinxhyphen{}471\sphinxhyphen{}00255\sphinxhyphen{}0 978\sphinxhyphen{}1\sphinxhyphen{}119\sphinxhyphen{}11515\sphinxhyphen{}1, \sphinxurl{https://doi.org/10.1002/9781119115151}, 1993.
\bibitem[Higham]{index:higham}
\sphinxAtStartPar
Higham, N. J., Strabi´c, N., and Šego, V.: Restoring Definiteness via Shrinking, with an Application to Correlation Matrices with a Fixed255 Block, SIAM Review, 58, 245\textendash{}263, \sphinxurl{https://www.jstor.org/stable/24778894}, 2016.
\bibitem[Huang]{index:huang}
\sphinxAtStartPar
Huang, B., Yin, X., Menne, M. J., Vose, R., and Zhang, H.\sphinxhyphen{}M.: Improvements to the Land Surface Air Temperature Reconstruction in NOAAGlobalTemp: An Artificial Neural Network Approach, Artificial Intelligence for the Earth Systems, 1, e220 032, \sphinxurl{https://doi.org/10.1175/AIES-D-22-0032.1}, 2022.
\bibitem[IPCC]{index:ipcc}
\sphinxAtStartPar
Intergovernmental Panel On Climate Change: Climate Change 2021 \textendash{} The Physical Science Basis: Working Group I Contribution to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change, Cambridge University Press, 1 edn., ISBN 978\sphinxhyphen{}1\sphinxhyphen{}00\sphinxhyphen{}915789\sphinxhyphen{}6, \sphinxurl{https://doi.org/10.1017/9781009157896}, 2021.
\bibitem[Jolliffe]{index:jolliffe}
\sphinxAtStartPar
Jolliffe, I. T., Principal Component Analysis, pp 487, Springer, 2002
\bibitem[Kadow]{index:kadow}
\sphinxAtStartPar
Kadow, C., Hall, D. M., and Ulbrich, U.: Artificial intelligence reconstructs missing climate information, Nature Geoscience, 13, 408\textendash{}413, \sphinxurl{https://doi.org/10.1038/s41561-020-0582-5}, 2020
\bibitem[Karspeck]{index:karspeck}
\sphinxAtStartPar
Karspeck, A. R., Kaplan, A., and Sain, S. R.: Bayesian modelling and ensemble reconstruction of mid\sphinxhyphen{}scale spatial variability in North Atlantic sea\sphinxhyphen{}surface temperatures for 1850\sphinxhyphen{}2008, Quarterly Journal of the Royal Meteorological Society, 138, 234\textendash{}248, \sphinxurl{https://doi.org/10.1002/qj.900}, 2012.
\bibitem[Laloux]{index:laloux}
\sphinxAtStartPar
Laloux, L., Cizeau, P., Potters, M. and Bouchaud, J.P.: Random matrix theory and financial correlations. International Journal of Theoretical and Applied Finance, 3(03), 391\sphinxhyphen{}397. \sphinxurl{https://www.worldscientific.com/doi/abs/10.1142/S0219024900000255}, 2000
\bibitem[Lenssen]{index:lenssen}
\sphinxAtStartPar
Lenssen, N. J. L., Schmidt, G. A., Hansen, J. E., Menne, M. J., Persin, A., Ruedy, R., and Zyss, D.: Improvements in the GISTEMP Uncertainty Model, Journal of Geophysical Research: Atmospheres, 124, 6307\textendash{}6326, \sphinxurl{https://doi.org/10.1029/2018JD029522}, 2019.
\bibitem[Morice\_2012]{index:morice-2012}
\sphinxAtStartPar
Morice, C. P., Kennedy, J. J., Rayner, N. A., and Jones, P. D.: Quantifying uncertainties in global and regional temperature change using an ensemble of observational estimates: The HadCRUT4 data set: THE HADCRUT4 DATASET, Journal of Geophysical Research: Atmospheres, 117, n/a\textendash{}n/a, \sphinxurl{https://doi.org/10.1029/2011JD017187}, 2012
\bibitem[Morice\_2021]{index:morice-2021}
\sphinxAtStartPar
Morice, C. P., Kennedy, J. J., Rayner, N. A., Winn, J. P., Hogan, E., Killick, R. E., Dunn, R. J. H., Osborn, T. J., Jones, P. D., and Simpson, 285 I. R.: An Updated Assessment of Near\sphinxhyphen{}Surface Temperature Change From 1850: The HadCRUT5 Data Set, Journal of Geophysical Research: Atmospheres, 126, e2019JD032 361, \sphinxurl{https://doi.org/10.1029/2019JD032361}, 2021.
\bibitem[PaciorekSchervish]{index:paciorekschervish}
\sphinxAtStartPar
Paciorek, C. J. and Schervish, M. J.: Spatial modelling using a new class of nonstationary covariance functions, Environmetrics, 17, 483\textendash{}506, \sphinxurl{https://doi.org/10.1002/env.785}, 2006
\bibitem[Rasmussen]{index:rasmussen}
\sphinxAtStartPar
Rasmussen, C. E. and Williams, C. K. I.: Gaussian Processes for Machine Learning, The MIT Press, ISBN 978\sphinxhyphen{}0\sphinxhyphen{}262\sphinxhyphen{}25683\sphinxhyphen{}4, \sphinxurl{https://doi.org/10.7551/mitpress/3206.001.0001}, 2005.
\bibitem[RohdeBerkeley]{index:rohdeberkeley}
\sphinxAtStartPar
Rohde, R. A. and Hausfather, Z.: The Berkeley Earth Land/Ocean Temperature Record, Earth System Science Data, 12, 3469\textendash{}3479, \sphinxurl{https://doi.org/10.5194/essd-12-3469-2020}, 2020
\bibitem[Thorne]{index:thorne}
\sphinxAtStartPar
Thorne, P. W., D. E. Parker, J. R. Christy, and C. A. Mears: Uncertainties in climate trends: Lessons from upper\sphinxhyphen{}air temperature records, Bull. Am. Meteorol. Soc., 86, 1437\textendash{}1442, \sphinxurl{https://doi.org/10.1175/BAMS-86-10-1437}, 2005
\bibitem[Wilks]{index:wilks}
\sphinxAtStartPar
Wilks, D.: Statistical Methods in Atmospheric Sciences, 2nd Edition, Elsevier, 2006
\end{sphinxthebibliography}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{g}
\item\relax\sphinxstyleindexentry{glomar\_gridding.climatology}\sphinxstyleindexpageref{misc:\detokenize{module-glomar_gridding.climatology}}
\item\relax\sphinxstyleindexentry{glomar\_gridding.covariance\_tools}\sphinxstyleindexpageref{misc:\detokenize{module-glomar_gridding.covariance_tools}}
\item\relax\sphinxstyleindexentry{glomar\_gridding.distances}\sphinxstyleindexpageref{misc:\detokenize{module-glomar_gridding.distances}}
\item\relax\sphinxstyleindexentry{glomar\_gridding.error\_covariance}\sphinxstyleindexpageref{error_covariance:\detokenize{module-glomar_gridding.error_covariance}}
\item\relax\sphinxstyleindexentry{glomar\_gridding.interpolation\_covariance}\sphinxstyleindexpageref{covariance:\detokenize{module-glomar_gridding.interpolation_covariance}}
\item\relax\sphinxstyleindexentry{glomar\_gridding.io}\sphinxstyleindexpageref{misc:\detokenize{module-glomar_gridding.io}}
\item\relax\sphinxstyleindexentry{glomar\_gridding.mask}\sphinxstyleindexpageref{misc:\detokenize{module-glomar_gridding.mask}}
\item\relax\sphinxstyleindexentry{glomar\_gridding.utils}\sphinxstyleindexpageref{misc:\detokenize{module-glomar_gridding.utils}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
